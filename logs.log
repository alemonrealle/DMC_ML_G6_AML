2025-05-13 16:03:39,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 16:03:39,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 16:03:39,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 16:03:39,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-13 16:11:38,747:INFO:PyCaret RegressionExperiment
2025-05-13 16:11:38,747:INFO:Logging name: reg-default-name
2025-05-13 16:11:38,747:INFO:ML Usecase: MLUsecase.REGRESSION
2025-05-13 16:11:38,747:INFO:version 3.3.2
2025-05-13 16:11:38,747:INFO:Initializing setup()
2025-05-13 16:11:38,747:INFO:self.USI: 085e
2025-05-13 16:11:38,747:INFO:self._variable_keys: {'memory', 'html_param', 'log_plots_param', 'n_jobs_param', 'seed', 'X', 'gpu_n_jobs_param', 'fold_groups_param', 'X_train', 'gpu_param', 'y_train', 'y_test', 'data', 'X_test', 'pipeline', '_available_plots', 'logging_param', 'target_param', 'USI', 'exp_name_log', 'y', 'fold_shuffle_param', 'idx', 'fold_generator', 'exp_id', '_ml_usecase', 'transform_target_param'}
2025-05-13 16:11:38,747:INFO:Checking environment
2025-05-13 16:11:38,747:INFO:python_version: 3.11.9
2025-05-13 16:11:38,747:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-05-13 16:11:38,747:INFO:machine: AMD64
2025-05-13 16:11:38,747:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-13 16:11:38,759:INFO:Memory: svmem(total=33554628608, available=15760769024, percent=53.0, used=17793859584, free=15760769024)
2025-05-13 16:11:38,759:INFO:Physical Core: 6
2025-05-13 16:11:38,759:INFO:Logical Core: 12
2025-05-13 16:11:38,759:INFO:Checking libraries
2025-05-13 16:11:38,759:INFO:System:
2025-05-13 16:11:38,759:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-05-13 16:11:38,759:INFO:executable: C:\Users\amonreal\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-05-13 16:11:38,759:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-13 16:11:38,759:INFO:PyCaret required dependencies:
2025-05-13 16:11:38,956:INFO:                 pip: 24.0
2025-05-13 16:11:38,956:INFO:          setuptools: 65.5.0
2025-05-13 16:11:38,956:INFO:             pycaret: 3.3.2
2025-05-13 16:11:38,956:INFO:             IPython: 9.2.0
2025-05-13 16:11:38,956:INFO:          ipywidgets: 8.1.7
2025-05-13 16:11:38,956:INFO:                tqdm: 4.67.1
2025-05-13 16:11:38,956:INFO:               numpy: 1.26.4
2025-05-13 16:11:38,956:INFO:              pandas: 2.1.4
2025-05-13 16:11:38,956:INFO:              jinja2: 3.1.6
2025-05-13 16:11:38,956:INFO:               scipy: 1.11.4
2025-05-13 16:11:38,956:INFO:              joblib: 1.3.2
2025-05-13 16:11:38,956:INFO:             sklearn: 1.4.2
2025-05-13 16:11:38,956:INFO:                pyod: 2.0.5
2025-05-13 16:11:38,956:INFO:            imblearn: 0.13.0
2025-05-13 16:11:38,956:INFO:   category_encoders: 2.7.0
2025-05-13 16:11:38,956:INFO:            lightgbm: 4.6.0
2025-05-13 16:11:38,956:INFO:               numba: 0.61.2
2025-05-13 16:11:38,956:INFO:            requests: 2.32.3
2025-05-13 16:11:38,956:INFO:          matplotlib: 3.7.5
2025-05-13 16:11:38,956:INFO:          scikitplot: 0.3.7
2025-05-13 16:11:38,956:INFO:         yellowbrick: 1.5
2025-05-13 16:11:38,956:INFO:              plotly: 5.24.1
2025-05-13 16:11:38,956:INFO:    plotly-resampler: Not installed
2025-05-13 16:11:38,956:INFO:             kaleido: 0.2.1
2025-05-13 16:11:38,956:INFO:           schemdraw: 0.15
2025-05-13 16:11:38,956:INFO:         statsmodels: 0.14.4
2025-05-13 16:11:38,956:INFO:              sktime: 0.26.0
2025-05-13 16:11:38,956:INFO:               tbats: 1.1.3
2025-05-13 16:11:38,956:INFO:            pmdarima: 2.0.4
2025-05-13 16:11:38,956:INFO:              psutil: 7.0.0
2025-05-13 16:11:38,956:INFO:          markupsafe: 3.0.2
2025-05-13 16:11:38,956:INFO:             pickle5: Not installed
2025-05-13 16:11:38,956:INFO:         cloudpickle: 3.1.1
2025-05-13 16:11:38,956:INFO:         deprecation: 2.1.0
2025-05-13 16:11:38,956:INFO:              xxhash: 3.5.0
2025-05-13 16:11:38,956:INFO:           wurlitzer: Not installed
2025-05-13 16:11:38,956:INFO:PyCaret optional dependencies:
2025-05-13 16:11:38,973:INFO:                shap: Not installed
2025-05-13 16:11:38,973:INFO:           interpret: Not installed
2025-05-13 16:11:38,973:INFO:                umap: Not installed
2025-05-13 16:11:38,973:INFO:     ydata_profiling: Not installed
2025-05-13 16:11:38,973:INFO:  explainerdashboard: Not installed
2025-05-13 16:11:38,973:INFO:             autoviz: Not installed
2025-05-13 16:11:38,973:INFO:           fairlearn: Not installed
2025-05-13 16:11:38,973:INFO:          deepchecks: Not installed
2025-05-13 16:11:38,973:INFO:             xgboost: Not installed
2025-05-13 16:11:38,973:INFO:            catboost: Not installed
2025-05-13 16:11:38,973:INFO:              kmodes: Not installed
2025-05-13 16:11:38,973:INFO:             mlxtend: Not installed
2025-05-13 16:11:38,973:INFO:       statsforecast: Not installed
2025-05-13 16:11:38,973:INFO:        tune_sklearn: Not installed
2025-05-13 16:11:38,973:INFO:                 ray: Not installed
2025-05-13 16:11:38,973:INFO:            hyperopt: Not installed
2025-05-13 16:11:38,973:INFO:              optuna: Not installed
2025-05-13 16:11:38,973:INFO:               skopt: Not installed
2025-05-13 16:11:38,973:INFO:              mlflow: Not installed
2025-05-13 16:11:38,973:INFO:              gradio: Not installed
2025-05-13 16:11:38,973:INFO:             fastapi: Not installed
2025-05-13 16:11:38,973:INFO:             uvicorn: Not installed
2025-05-13 16:11:38,973:INFO:              m2cgen: Not installed
2025-05-13 16:11:38,973:INFO:           evidently: Not installed
2025-05-13 16:11:38,973:INFO:               fugue: Not installed
2025-05-13 16:11:38,973:INFO:           streamlit: Not installed
2025-05-13 16:11:38,973:INFO:             prophet: Not installed
2025-05-13 16:11:38,973:INFO:None
2025-05-13 16:11:38,973:INFO:Set up data.
2025-05-13 16:11:38,973:INFO:Set up folding strategy.
2025-05-13 16:11:38,973:INFO:Set up train/test split.
2025-05-13 16:11:39,037:INFO:Set up index.
2025-05-13 16:11:39,037:INFO:Assigning column types.
2025-05-13 16:11:39,037:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-13 16:11:39,037:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,037:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,037:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,113:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,150:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,151:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,151:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,155:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,158:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,205:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,243:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,243:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-05-13 16:11:39,243:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,254:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,300:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,340:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,343:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,391:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,424:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,424:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,424:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-05-13 16:11:39,424:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,524:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,525:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,623:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,652:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,652:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-05-13 16:11:39,709:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,827:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,873:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-13 16:11:39,941:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-13 16:11:39,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:39,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-05-13 16:11:40,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,046:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-05-13 16:11:40,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,201:INFO:Preparing preprocessing pipeline...
2025-05-13 16:11:40,201:INFO:Set up simple imputation.
2025-05-13 16:11:40,201:INFO:Set up encoding of categorical features.
2025-05-13 16:11:40,201:INFO:Set up feature normalization.
2025-05-13 16:11:40,308:INFO:Finished creating preprocessing pipeline.
2025-05-13 16:11:40,344:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area_m2', 'num_habitaciones',
                                             'num_banos', 'antiguedad_anos',
                                             'vista_mar'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['distrito'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['distrito'],
                                    transformer=OneHotEncoder(cols=['distrito'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2025-05-13 16:11:40,344:INFO:Creating final display dataframe.
2025-05-13 16:11:40,478:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            precio
2                   Target type        Regression
3           Original data shape          (100, 7)
4        Transformed data shape         (100, 10)
5   Transformed train set shape          (70, 10)
6    Transformed test set shape          (30, 10)
7              Numeric features                 5
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                    Normalize              True
16             Normalize method            zscore
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              085e
2025-05-13 16:11:40,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-13 16:11:40,710:INFO:setup() successfully completed in 1.97s...............
2025-05-13 16:11:54,587:INFO:Initializing compare_models()
2025-05-13 16:11:54,587:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-05-13 16:11:54,588:INFO:Checking exceptions
2025-05-13 16:11:54,590:INFO:Preparing display monitor
2025-05-13 16:11:54,621:INFO:Initializing Linear Regression
2025-05-13 16:11:54,621:INFO:Total runtime is 1.6717116038004556e-05 minutes
2025-05-13 16:11:54,626:INFO:SubProcess create_model() called ==================================
2025-05-13 16:11:54,627:INFO:Initializing create_model()
2025-05-13 16:11:54,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:11:54,627:INFO:Checking exceptions
2025-05-13 16:11:54,627:INFO:Importing libraries
2025-05-13 16:11:54,627:INFO:Copying training dataset
2025-05-13 16:11:54,630:INFO:Defining folds
2025-05-13 16:11:54,630:INFO:Declaring metric variables
2025-05-13 16:11:54,633:INFO:Importing untrained model
2025-05-13 16:11:54,637:INFO:Linear Regression Imported successfully
2025-05-13 16:11:54,646:INFO:Starting cross validation
2025-05-13 16:11:54,698:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:11:59,334:INFO:Calculating mean and std
2025-05-13 16:11:59,335:INFO:Creating metrics dataframe
2025-05-13 16:11:59,338:INFO:Uploading results into container
2025-05-13 16:11:59,339:INFO:Uploading model into container now
2025-05-13 16:11:59,340:INFO:_master_model_container: 1
2025-05-13 16:11:59,340:INFO:_display_container: 2
2025-05-13 16:11:59,340:INFO:LinearRegression(n_jobs=-1)
2025-05-13 16:11:59,341:INFO:create_model() successfully completed......................................
2025-05-13 16:11:59,452:INFO:SubProcess create_model() end ==================================
2025-05-13 16:11:59,452:INFO:Creating metrics dataframe
2025-05-13 16:11:59,468:INFO:Initializing Lasso Regression
2025-05-13 16:11:59,468:INFO:Total runtime is 0.0807937741279602 minutes
2025-05-13 16:11:59,470:INFO:SubProcess create_model() called ==================================
2025-05-13 16:11:59,470:INFO:Initializing create_model()
2025-05-13 16:11:59,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:11:59,470:INFO:Checking exceptions
2025-05-13 16:11:59,470:INFO:Importing libraries
2025-05-13 16:11:59,470:INFO:Copying training dataset
2025-05-13 16:11:59,479:INFO:Defining folds
2025-05-13 16:11:59,480:INFO:Declaring metric variables
2025-05-13 16:11:59,489:INFO:Importing untrained model
2025-05-13 16:11:59,497:INFO:Lasso Regression Imported successfully
2025-05-13 16:11:59,507:INFO:Starting cross validation
2025-05-13 16:11:59,509:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:01,496:INFO:Calculating mean and std
2025-05-13 16:12:01,497:INFO:Creating metrics dataframe
2025-05-13 16:12:01,499:INFO:Uploading results into container
2025-05-13 16:12:01,500:INFO:Uploading model into container now
2025-05-13 16:12:01,500:INFO:_master_model_container: 2
2025-05-13 16:12:01,500:INFO:_display_container: 2
2025-05-13 16:12:01,501:INFO:Lasso(random_state=123)
2025-05-13 16:12:01,501:INFO:create_model() successfully completed......................................
2025-05-13 16:12:01,624:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:01,624:INFO:Creating metrics dataframe
2025-05-13 16:12:01,637:INFO:Initializing Ridge Regression
2025-05-13 16:12:01,637:INFO:Total runtime is 0.11694057782491046 minutes
2025-05-13 16:12:01,641:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:01,641:INFO:Initializing create_model()
2025-05-13 16:12:01,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:01,641:INFO:Checking exceptions
2025-05-13 16:12:01,641:INFO:Importing libraries
2025-05-13 16:12:01,641:INFO:Copying training dataset
2025-05-13 16:12:01,643:INFO:Defining folds
2025-05-13 16:12:01,643:INFO:Declaring metric variables
2025-05-13 16:12:01,643:INFO:Importing untrained model
2025-05-13 16:12:01,643:INFO:Ridge Regression Imported successfully
2025-05-13 16:12:01,658:INFO:Starting cross validation
2025-05-13 16:12:01,661:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:01,768:INFO:Calculating mean and std
2025-05-13 16:12:01,770:INFO:Creating metrics dataframe
2025-05-13 16:12:01,771:INFO:Uploading results into container
2025-05-13 16:12:01,772:INFO:Uploading model into container now
2025-05-13 16:12:01,772:INFO:_master_model_container: 3
2025-05-13 16:12:01,773:INFO:_display_container: 2
2025-05-13 16:12:01,773:INFO:Ridge(random_state=123)
2025-05-13 16:12:01,773:INFO:create_model() successfully completed......................................
2025-05-13 16:12:01,877:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:01,877:INFO:Creating metrics dataframe
2025-05-13 16:12:01,877:INFO:Initializing Elastic Net
2025-05-13 16:12:01,877:INFO:Total runtime is 0.12095081408818562 minutes
2025-05-13 16:12:01,893:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:01,893:INFO:Initializing create_model()
2025-05-13 16:12:01,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:01,893:INFO:Checking exceptions
2025-05-13 16:12:01,893:INFO:Importing libraries
2025-05-13 16:12:01,893:INFO:Copying training dataset
2025-05-13 16:12:01,893:INFO:Defining folds
2025-05-13 16:12:01,893:INFO:Declaring metric variables
2025-05-13 16:12:01,904:INFO:Importing untrained model
2025-05-13 16:12:01,910:INFO:Elastic Net Imported successfully
2025-05-13 16:12:01,914:INFO:Starting cross validation
2025-05-13 16:12:01,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:02,001:INFO:Calculating mean and std
2025-05-13 16:12:02,001:INFO:Creating metrics dataframe
2025-05-13 16:12:02,004:INFO:Uploading results into container
2025-05-13 16:12:02,004:INFO:Uploading model into container now
2025-05-13 16:12:02,005:INFO:_master_model_container: 4
2025-05-13 16:12:02,005:INFO:_display_container: 2
2025-05-13 16:12:02,006:INFO:ElasticNet(random_state=123)
2025-05-13 16:12:02,006:INFO:create_model() successfully completed......................................
2025-05-13 16:12:02,104:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:02,104:INFO:Creating metrics dataframe
2025-05-13 16:12:02,121:INFO:Initializing Least Angle Regression
2025-05-13 16:12:02,121:INFO:Total runtime is 0.12501175006230672 minutes
2025-05-13 16:12:02,121:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:02,121:INFO:Initializing create_model()
2025-05-13 16:12:02,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:02,121:INFO:Checking exceptions
2025-05-13 16:12:02,121:INFO:Importing libraries
2025-05-13 16:12:02,121:INFO:Copying training dataset
2025-05-13 16:12:02,138:INFO:Defining folds
2025-05-13 16:12:02,138:INFO:Declaring metric variables
2025-05-13 16:12:02,142:INFO:Importing untrained model
2025-05-13 16:12:02,144:INFO:Least Angle Regression Imported successfully
2025-05-13 16:12:02,153:INFO:Starting cross validation
2025-05-13 16:12:02,155:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:02,238:INFO:Calculating mean and std
2025-05-13 16:12:02,240:INFO:Creating metrics dataframe
2025-05-13 16:12:02,241:INFO:Uploading results into container
2025-05-13 16:12:02,243:INFO:Uploading model into container now
2025-05-13 16:12:02,243:INFO:_master_model_container: 5
2025-05-13 16:12:02,243:INFO:_display_container: 2
2025-05-13 16:12:02,243:INFO:Lars(random_state=123)
2025-05-13 16:12:02,243:INFO:create_model() successfully completed......................................
2025-05-13 16:12:02,352:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:02,352:INFO:Creating metrics dataframe
2025-05-13 16:12:02,358:INFO:Initializing Lasso Least Angle Regression
2025-05-13 16:12:02,358:INFO:Total runtime is 0.12896978855133057 minutes
2025-05-13 16:12:02,362:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:02,363:INFO:Initializing create_model()
2025-05-13 16:12:02,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:02,363:INFO:Checking exceptions
2025-05-13 16:12:02,363:INFO:Importing libraries
2025-05-13 16:12:02,363:INFO:Copying training dataset
2025-05-13 16:12:02,366:INFO:Defining folds
2025-05-13 16:12:02,366:INFO:Declaring metric variables
2025-05-13 16:12:02,371:INFO:Importing untrained model
2025-05-13 16:12:02,375:INFO:Lasso Least Angle Regression Imported successfully
2025-05-13 16:12:02,380:INFO:Starting cross validation
2025-05-13 16:12:02,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:02,489:INFO:Calculating mean and std
2025-05-13 16:12:02,489:INFO:Creating metrics dataframe
2025-05-13 16:12:02,489:INFO:Uploading results into container
2025-05-13 16:12:02,489:INFO:Uploading model into container now
2025-05-13 16:12:02,489:INFO:_master_model_container: 6
2025-05-13 16:12:02,489:INFO:_display_container: 2
2025-05-13 16:12:02,489:INFO:LassoLars(random_state=123)
2025-05-13 16:12:02,489:INFO:create_model() successfully completed......................................
2025-05-13 16:12:02,605:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:02,605:INFO:Creating metrics dataframe
2025-05-13 16:12:02,609:INFO:Initializing Orthogonal Matching Pursuit
2025-05-13 16:12:02,620:INFO:Total runtime is 0.13333499431610107 minutes
2025-05-13 16:12:02,625:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:02,626:INFO:Initializing create_model()
2025-05-13 16:12:02,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:02,626:INFO:Checking exceptions
2025-05-13 16:12:02,626:INFO:Importing libraries
2025-05-13 16:12:02,626:INFO:Copying training dataset
2025-05-13 16:12:02,626:INFO:Defining folds
2025-05-13 16:12:02,626:INFO:Declaring metric variables
2025-05-13 16:12:02,635:INFO:Importing untrained model
2025-05-13 16:12:02,640:INFO:Orthogonal Matching Pursuit Imported successfully
2025-05-13 16:12:02,646:INFO:Starting cross validation
2025-05-13 16:12:02,647:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:02,755:INFO:Calculating mean and std
2025-05-13 16:12:02,756:INFO:Creating metrics dataframe
2025-05-13 16:12:02,758:INFO:Uploading results into container
2025-05-13 16:12:02,758:INFO:Uploading model into container now
2025-05-13 16:12:02,759:INFO:_master_model_container: 7
2025-05-13 16:12:02,759:INFO:_display_container: 2
2025-05-13 16:12:02,759:INFO:OrthogonalMatchingPursuit()
2025-05-13 16:12:02,759:INFO:create_model() successfully completed......................................
2025-05-13 16:12:02,868:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:02,868:INFO:Creating metrics dataframe
2025-05-13 16:12:02,876:INFO:Initializing Bayesian Ridge
2025-05-13 16:12:02,876:INFO:Total runtime is 0.1375944455464681 minutes
2025-05-13 16:12:02,880:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:02,881:INFO:Initializing create_model()
2025-05-13 16:12:02,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:02,881:INFO:Checking exceptions
2025-05-13 16:12:02,881:INFO:Importing libraries
2025-05-13 16:12:02,881:INFO:Copying training dataset
2025-05-13 16:12:02,885:INFO:Defining folds
2025-05-13 16:12:02,885:INFO:Declaring metric variables
2025-05-13 16:12:02,889:INFO:Importing untrained model
2025-05-13 16:12:02,892:INFO:Bayesian Ridge Imported successfully
2025-05-13 16:12:02,898:INFO:Starting cross validation
2025-05-13 16:12:02,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:02,987:INFO:Calculating mean and std
2025-05-13 16:12:02,988:INFO:Creating metrics dataframe
2025-05-13 16:12:02,990:INFO:Uploading results into container
2025-05-13 16:12:02,991:INFO:Uploading model into container now
2025-05-13 16:12:02,991:INFO:_master_model_container: 8
2025-05-13 16:12:02,991:INFO:_display_container: 2
2025-05-13 16:12:02,991:INFO:BayesianRidge()
2025-05-13 16:12:02,991:INFO:create_model() successfully completed......................................
2025-05-13 16:12:03,087:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:03,087:INFO:Creating metrics dataframe
2025-05-13 16:12:03,102:INFO:Initializing Passive Aggressive Regressor
2025-05-13 16:12:03,102:INFO:Total runtime is 0.1413674553235372 minutes
2025-05-13 16:12:03,102:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:03,102:INFO:Initializing create_model()
2025-05-13 16:12:03,102:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:03,102:INFO:Checking exceptions
2025-05-13 16:12:03,102:INFO:Importing libraries
2025-05-13 16:12:03,102:INFO:Copying training dataset
2025-05-13 16:12:03,120:INFO:Defining folds
2025-05-13 16:12:03,120:INFO:Declaring metric variables
2025-05-13 16:12:03,130:INFO:Importing untrained model
2025-05-13 16:12:03,137:INFO:Passive Aggressive Regressor Imported successfully
2025-05-13 16:12:03,146:INFO:Starting cross validation
2025-05-13 16:12:03,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:03,234:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-13 16:12:03,234:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-13 16:12:03,234:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-13 16:12:03,238:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-13 16:12:03,242:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-13 16:12:03,248:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-13 16:12:03,250:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-13 16:12:03,256:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_stochastic_gradient.py:1575: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  warnings.warn(

2025-05-13 16:12:03,273:INFO:Calculating mean and std
2025-05-13 16:12:03,275:INFO:Creating metrics dataframe
2025-05-13 16:12:03,276:INFO:Uploading results into container
2025-05-13 16:12:03,277:INFO:Uploading model into container now
2025-05-13 16:12:03,277:INFO:_master_model_container: 9
2025-05-13 16:12:03,277:INFO:_display_container: 2
2025-05-13 16:12:03,278:INFO:PassiveAggressiveRegressor(random_state=123)
2025-05-13 16:12:03,278:INFO:create_model() successfully completed......................................
2025-05-13 16:12:03,377:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:03,377:INFO:Creating metrics dataframe
2025-05-13 16:12:03,393:INFO:Initializing Huber Regressor
2025-05-13 16:12:03,393:INFO:Total runtime is 0.14620632727940877 minutes
2025-05-13 16:12:03,393:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:03,393:INFO:Initializing create_model()
2025-05-13 16:12:03,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:03,393:INFO:Checking exceptions
2025-05-13 16:12:03,393:INFO:Importing libraries
2025-05-13 16:12:03,393:INFO:Copying training dataset
2025-05-13 16:12:03,407:INFO:Defining folds
2025-05-13 16:12:03,408:INFO:Declaring metric variables
2025-05-13 16:12:03,412:INFO:Importing untrained model
2025-05-13 16:12:03,415:INFO:Huber Regressor Imported successfully
2025-05-13 16:12:03,421:INFO:Starting cross validation
2025-05-13 16:12:03,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:03,514:INFO:Calculating mean and std
2025-05-13 16:12:03,514:INFO:Creating metrics dataframe
2025-05-13 16:12:03,514:INFO:Uploading results into container
2025-05-13 16:12:03,514:INFO:Uploading model into container now
2025-05-13 16:12:03,514:INFO:_master_model_container: 10
2025-05-13 16:12:03,514:INFO:_display_container: 2
2025-05-13 16:12:03,514:INFO:HuberRegressor()
2025-05-13 16:12:03,514:INFO:create_model() successfully completed......................................
2025-05-13 16:12:03,621:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:03,621:INFO:Creating metrics dataframe
2025-05-13 16:12:03,626:INFO:Initializing K Neighbors Regressor
2025-05-13 16:12:03,626:INFO:Total runtime is 0.15009694099426268 minutes
2025-05-13 16:12:03,637:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:03,639:INFO:Initializing create_model()
2025-05-13 16:12:03,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:03,639:INFO:Checking exceptions
2025-05-13 16:12:03,640:INFO:Importing libraries
2025-05-13 16:12:03,640:INFO:Copying training dataset
2025-05-13 16:12:03,643:INFO:Defining folds
2025-05-13 16:12:03,643:INFO:Declaring metric variables
2025-05-13 16:12:03,651:INFO:Importing untrained model
2025-05-13 16:12:03,659:INFO:K Neighbors Regressor Imported successfully
2025-05-13 16:12:03,659:INFO:Starting cross validation
2025-05-13 16:12:03,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:03,777:INFO:Calculating mean and std
2025-05-13 16:12:03,777:INFO:Creating metrics dataframe
2025-05-13 16:12:03,777:INFO:Uploading results into container
2025-05-13 16:12:03,777:INFO:Uploading model into container now
2025-05-13 16:12:03,777:INFO:_master_model_container: 11
2025-05-13 16:12:03,777:INFO:_display_container: 2
2025-05-13 16:12:03,777:INFO:KNeighborsRegressor(n_jobs=-1)
2025-05-13 16:12:03,777:INFO:create_model() successfully completed......................................
2025-05-13 16:12:03,890:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:03,890:INFO:Creating metrics dataframe
2025-05-13 16:12:03,893:INFO:Initializing Decision Tree Regressor
2025-05-13 16:12:03,893:INFO:Total runtime is 0.15454953908920288 minutes
2025-05-13 16:12:03,910:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:03,910:INFO:Initializing create_model()
2025-05-13 16:12:03,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:03,910:INFO:Checking exceptions
2025-05-13 16:12:03,910:INFO:Importing libraries
2025-05-13 16:12:03,910:INFO:Copying training dataset
2025-05-13 16:12:03,923:INFO:Defining folds
2025-05-13 16:12:03,924:INFO:Declaring metric variables
2025-05-13 16:12:03,928:INFO:Importing untrained model
2025-05-13 16:12:03,928:INFO:Decision Tree Regressor Imported successfully
2025-05-13 16:12:03,942:INFO:Starting cross validation
2025-05-13 16:12:03,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:04,039:INFO:Calculating mean and std
2025-05-13 16:12:04,040:INFO:Creating metrics dataframe
2025-05-13 16:12:04,042:INFO:Uploading results into container
2025-05-13 16:12:04,042:INFO:Uploading model into container now
2025-05-13 16:12:04,042:INFO:_master_model_container: 12
2025-05-13 16:12:04,043:INFO:_display_container: 2
2025-05-13 16:12:04,043:INFO:DecisionTreeRegressor(random_state=123)
2025-05-13 16:12:04,043:INFO:create_model() successfully completed......................................
2025-05-13 16:12:04,143:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:04,143:INFO:Creating metrics dataframe
2025-05-13 16:12:04,158:INFO:Initializing Random Forest Regressor
2025-05-13 16:12:04,159:INFO:Total runtime is 0.15898115237553914 minutes
2025-05-13 16:12:04,159:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:04,159:INFO:Initializing create_model()
2025-05-13 16:12:04,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:04,159:INFO:Checking exceptions
2025-05-13 16:12:04,159:INFO:Importing libraries
2025-05-13 16:12:04,159:INFO:Copying training dataset
2025-05-13 16:12:04,177:INFO:Defining folds
2025-05-13 16:12:04,177:INFO:Declaring metric variables
2025-05-13 16:12:04,186:INFO:Importing untrained model
2025-05-13 16:12:04,194:INFO:Random Forest Regressor Imported successfully
2025-05-13 16:12:04,207:INFO:Starting cross validation
2025-05-13 16:12:04,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:04,471:INFO:Calculating mean and std
2025-05-13 16:12:04,472:INFO:Creating metrics dataframe
2025-05-13 16:12:04,474:INFO:Uploading results into container
2025-05-13 16:12:04,474:INFO:Uploading model into container now
2025-05-13 16:12:04,475:INFO:_master_model_container: 13
2025-05-13 16:12:04,475:INFO:_display_container: 2
2025-05-13 16:12:04,476:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-05-13 16:12:04,476:INFO:create_model() successfully completed......................................
2025-05-13 16:12:04,577:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:04,577:INFO:Creating metrics dataframe
2025-05-13 16:12:04,589:INFO:Initializing Extra Trees Regressor
2025-05-13 16:12:04,590:INFO:Total runtime is 0.16616408030192056 minutes
2025-05-13 16:12:04,593:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:04,593:INFO:Initializing create_model()
2025-05-13 16:12:04,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:04,593:INFO:Checking exceptions
2025-05-13 16:12:04,593:INFO:Importing libraries
2025-05-13 16:12:04,593:INFO:Copying training dataset
2025-05-13 16:12:04,606:INFO:Defining folds
2025-05-13 16:12:04,607:INFO:Declaring metric variables
2025-05-13 16:12:04,614:INFO:Importing untrained model
2025-05-13 16:12:04,620:INFO:Extra Trees Regressor Imported successfully
2025-05-13 16:12:04,626:INFO:Starting cross validation
2025-05-13 16:12:04,626:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:04,872:INFO:Calculating mean and std
2025-05-13 16:12:04,873:INFO:Creating metrics dataframe
2025-05-13 16:12:04,875:INFO:Uploading results into container
2025-05-13 16:12:04,875:INFO:Uploading model into container now
2025-05-13 16:12:04,876:INFO:_master_model_container: 14
2025-05-13 16:12:04,876:INFO:_display_container: 2
2025-05-13 16:12:04,876:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-05-13 16:12:04,876:INFO:create_model() successfully completed......................................
2025-05-13 16:12:04,987:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:04,988:INFO:Creating metrics dataframe
2025-05-13 16:12:04,993:INFO:Initializing AdaBoost Regressor
2025-05-13 16:12:04,993:INFO:Total runtime is 0.1728727102279663 minutes
2025-05-13 16:12:05,004:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:05,005:INFO:Initializing create_model()
2025-05-13 16:12:05,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:05,006:INFO:Checking exceptions
2025-05-13 16:12:05,006:INFO:Importing libraries
2025-05-13 16:12:05,006:INFO:Copying training dataset
2025-05-13 16:12:05,010:INFO:Defining folds
2025-05-13 16:12:05,010:INFO:Declaring metric variables
2025-05-13 16:12:05,010:INFO:Importing untrained model
2025-05-13 16:12:05,024:INFO:AdaBoost Regressor Imported successfully
2025-05-13 16:12:05,026:INFO:Starting cross validation
2025-05-13 16:12:05,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:05,192:INFO:Calculating mean and std
2025-05-13 16:12:05,193:INFO:Creating metrics dataframe
2025-05-13 16:12:05,194:INFO:Uploading results into container
2025-05-13 16:12:05,194:INFO:Uploading model into container now
2025-05-13 16:12:05,194:INFO:_master_model_container: 15
2025-05-13 16:12:05,194:INFO:_display_container: 2
2025-05-13 16:12:05,194:INFO:AdaBoostRegressor(random_state=123)
2025-05-13 16:12:05,194:INFO:create_model() successfully completed......................................
2025-05-13 16:12:05,294:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:05,294:INFO:Creating metrics dataframe
2025-05-13 16:12:05,325:INFO:Initializing Gradient Boosting Regressor
2025-05-13 16:12:05,326:INFO:Total runtime is 0.178419562180837 minutes
2025-05-13 16:12:05,330:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:05,330:INFO:Initializing create_model()
2025-05-13 16:12:05,330:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:05,330:INFO:Checking exceptions
2025-05-13 16:12:05,330:INFO:Importing libraries
2025-05-13 16:12:05,330:INFO:Copying training dataset
2025-05-13 16:12:05,339:INFO:Defining folds
2025-05-13 16:12:05,340:INFO:Declaring metric variables
2025-05-13 16:12:05,346:INFO:Importing untrained model
2025-05-13 16:12:05,354:INFO:Gradient Boosting Regressor Imported successfully
2025-05-13 16:12:05,359:INFO:Starting cross validation
2025-05-13 16:12:05,365:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:05,530:INFO:Calculating mean and std
2025-05-13 16:12:05,531:INFO:Creating metrics dataframe
2025-05-13 16:12:05,533:INFO:Uploading results into container
2025-05-13 16:12:05,533:INFO:Uploading model into container now
2025-05-13 16:12:05,533:INFO:_master_model_container: 16
2025-05-13 16:12:05,534:INFO:_display_container: 2
2025-05-13 16:12:05,534:INFO:GradientBoostingRegressor(random_state=123)
2025-05-13 16:12:05,534:INFO:create_model() successfully completed......................................
2025-05-13 16:12:05,642:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:05,643:INFO:Creating metrics dataframe
2025-05-13 16:12:05,655:INFO:Initializing Light Gradient Boosting Machine
2025-05-13 16:12:05,655:INFO:Total runtime is 0.18390869696935017 minutes
2025-05-13 16:12:05,655:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:05,655:INFO:Initializing create_model()
2025-05-13 16:12:05,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:05,655:INFO:Checking exceptions
2025-05-13 16:12:05,655:INFO:Importing libraries
2025-05-13 16:12:05,655:INFO:Copying training dataset
2025-05-13 16:12:05,672:INFO:Defining folds
2025-05-13 16:12:05,672:INFO:Declaring metric variables
2025-05-13 16:12:05,676:INFO:Importing untrained model
2025-05-13 16:12:05,682:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-13 16:12:05,693:INFO:Starting cross validation
2025-05-13 16:12:05,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:05,932:INFO:Calculating mean and std
2025-05-13 16:12:05,932:INFO:Creating metrics dataframe
2025-05-13 16:12:05,935:INFO:Uploading results into container
2025-05-13 16:12:05,935:INFO:Uploading model into container now
2025-05-13 16:12:05,937:INFO:_master_model_container: 17
2025-05-13 16:12:05,937:INFO:_display_container: 2
2025-05-13 16:12:05,937:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-05-13 16:12:05,937:INFO:create_model() successfully completed......................................
2025-05-13 16:12:06,053:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:06,053:INFO:Creating metrics dataframe
2025-05-13 16:12:06,071:INFO:Initializing Dummy Regressor
2025-05-13 16:12:06,072:INFO:Total runtime is 0.19085416396458943 minutes
2025-05-13 16:12:06,073:INFO:SubProcess create_model() called ==================================
2025-05-13 16:12:06,073:INFO:Initializing create_model()
2025-05-13 16:12:06,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D09BD48E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:06,073:INFO:Checking exceptions
2025-05-13 16:12:06,073:INFO:Importing libraries
2025-05-13 16:12:06,073:INFO:Copying training dataset
2025-05-13 16:12:06,076:INFO:Defining folds
2025-05-13 16:12:06,076:INFO:Declaring metric variables
2025-05-13 16:12:06,076:INFO:Importing untrained model
2025-05-13 16:12:06,083:INFO:Dummy Regressor Imported successfully
2025-05-13 16:12:06,088:INFO:Starting cross validation
2025-05-13 16:12:06,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:06,173:INFO:Calculating mean and std
2025-05-13 16:12:06,173:INFO:Creating metrics dataframe
2025-05-13 16:12:06,173:INFO:Uploading results into container
2025-05-13 16:12:06,173:INFO:Uploading model into container now
2025-05-13 16:12:06,173:INFO:_master_model_container: 18
2025-05-13 16:12:06,173:INFO:_display_container: 2
2025-05-13 16:12:06,173:INFO:DummyRegressor()
2025-05-13 16:12:06,173:INFO:create_model() successfully completed......................................
2025-05-13 16:12:06,285:INFO:SubProcess create_model() end ==================================
2025-05-13 16:12:06,285:INFO:Creating metrics dataframe
2025-05-13 16:12:06,301:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-13 16:12:06,313:INFO:Initializing create_model()
2025-05-13 16:12:06,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:06,314:INFO:Checking exceptions
2025-05-13 16:12:06,315:INFO:Importing libraries
2025-05-13 16:12:06,315:INFO:Copying training dataset
2025-05-13 16:12:06,317:INFO:Defining folds
2025-05-13 16:12:06,318:INFO:Declaring metric variables
2025-05-13 16:12:06,318:INFO:Importing untrained model
2025-05-13 16:12:06,318:INFO:Declaring custom model
2025-05-13 16:12:06,318:INFO:Linear Regression Imported successfully
2025-05-13 16:12:06,318:INFO:Cross validation set to False
2025-05-13 16:12:06,318:INFO:Fitting Model
2025-05-13 16:12:06,354:INFO:LinearRegression(n_jobs=-1)
2025-05-13 16:12:06,354:INFO:create_model() successfully completed......................................
2025-05-13 16:12:06,514:INFO:_master_model_container: 18
2025-05-13 16:12:06,515:INFO:_display_container: 2
2025-05-13 16:12:06,515:INFO:LinearRegression(n_jobs=-1)
2025-05-13 16:12:06,515:INFO:compare_models() successfully completed......................................
2025-05-13 16:12:10,699:INFO:Initializing create_model()
2025-05-13 16:12:10,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001D098FC3ED0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-13 16:12:10,699:INFO:Checking exceptions
2025-05-13 16:12:10,713:INFO:Importing libraries
2025-05-13 16:12:10,713:INFO:Copying training dataset
2025-05-13 16:12:10,716:INFO:Defining folds
2025-05-13 16:12:10,716:INFO:Declaring metric variables
2025-05-13 16:12:10,720:INFO:Importing untrained model
2025-05-13 16:12:10,725:INFO:Linear Regression Imported successfully
2025-05-13 16:12:10,732:INFO:Starting cross validation
2025-05-13 16:12:10,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-13 16:12:10,847:INFO:Calculating mean and std
2025-05-13 16:12:10,848:INFO:Creating metrics dataframe
2025-05-13 16:12:10,852:INFO:Finalizing model
2025-05-13 16:12:10,886:INFO:Uploading results into container
2025-05-13 16:12:10,887:INFO:Uploading model into container now
2025-05-13 16:12:10,895:INFO:_master_model_container: 19
2025-05-13 16:12:10,895:INFO:_display_container: 3
2025-05-13 16:12:10,895:INFO:LinearRegression(n_jobs=-1)
2025-05-13 16:12:10,895:INFO:create_model() successfully completed......................................
2025-05-19 18:49:56,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 18:49:56,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 18:49:56,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 18:49:56,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 19:05:00,002:INFO:PyCaret ClassificationExperiment
2025-05-19 19:05:00,003:INFO:Logging name: clf-default-name
2025-05-19 19:05:00,003:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-19 19:05:00,003:INFO:version 3.3.2
2025-05-19 19:05:00,003:INFO:Initializing setup()
2025-05-19 19:05:00,003:INFO:self.USI: 6c64
2025-05-19 19:05:00,003:INFO:self._variable_keys: {'fix_imbalance', 'USI', 'exp_name_log', 'fold_groups_param', '_ml_usecase', 'html_param', 'target_param', 'fold_generator', 'exp_id', 'y_train', 'idx', 'data', 'is_multiclass', 'pipeline', 'seed', 'y', 'y_test', 'memory', 'gpu_n_jobs_param', 'fold_shuffle_param', 'log_plots_param', 'X', 'X_test', 'n_jobs_param', 'X_train', 'gpu_param', '_available_plots', 'logging_param'}
2025-05-19 19:05:00,003:INFO:Checking environment
2025-05-19 19:05:00,003:INFO:python_version: 3.11.9
2025-05-19 19:05:00,003:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-05-19 19:05:00,003:INFO:machine: AMD64
2025-05-19 19:05:00,003:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-19 19:05:00,023:INFO:Memory: svmem(total=33554628608, available=15830056960, percent=52.8, used=17724571648, free=15830056960)
2025-05-19 19:05:00,023:INFO:Physical Core: 6
2025-05-19 19:05:00,023:INFO:Logical Core: 12
2025-05-19 19:05:00,023:INFO:Checking libraries
2025-05-19 19:05:00,024:INFO:System:
2025-05-19 19:05:00,024:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-05-19 19:05:00,024:INFO:executable: C:\Users\amonreal\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-05-19 19:05:00,024:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-19 19:05:00,024:INFO:PyCaret required dependencies:
2025-05-19 19:05:00,130:INFO:                 pip: 24.0
2025-05-19 19:05:00,130:INFO:          setuptools: 65.5.0
2025-05-19 19:05:00,130:INFO:             pycaret: 3.3.2
2025-05-19 19:05:00,130:INFO:             IPython: 9.2.0
2025-05-19 19:05:00,130:INFO:          ipywidgets: 8.1.7
2025-05-19 19:05:00,130:INFO:                tqdm: 4.67.1
2025-05-19 19:05:00,130:INFO:               numpy: 1.26.4
2025-05-19 19:05:00,130:INFO:              pandas: 2.1.4
2025-05-19 19:05:00,130:INFO:              jinja2: 3.1.6
2025-05-19 19:05:00,130:INFO:               scipy: 1.11.4
2025-05-19 19:05:00,130:INFO:              joblib: 1.3.2
2025-05-19 19:05:00,130:INFO:             sklearn: 1.4.2
2025-05-19 19:05:00,130:INFO:                pyod: 2.0.5
2025-05-19 19:05:00,130:INFO:            imblearn: 0.13.0
2025-05-19 19:05:00,130:INFO:   category_encoders: 2.7.0
2025-05-19 19:05:00,130:INFO:            lightgbm: 4.6.0
2025-05-19 19:05:00,130:INFO:               numba: 0.61.2
2025-05-19 19:05:00,130:INFO:            requests: 2.32.3
2025-05-19 19:05:00,130:INFO:          matplotlib: 3.7.5
2025-05-19 19:05:00,130:INFO:          scikitplot: 0.3.7
2025-05-19 19:05:00,130:INFO:         yellowbrick: 1.5
2025-05-19 19:05:00,130:INFO:              plotly: 5.24.1
2025-05-19 19:05:00,130:INFO:    plotly-resampler: Not installed
2025-05-19 19:05:00,130:INFO:             kaleido: 0.2.1
2025-05-19 19:05:00,130:INFO:           schemdraw: 0.15
2025-05-19 19:05:00,130:INFO:         statsmodels: 0.14.4
2025-05-19 19:05:00,130:INFO:              sktime: 0.26.0
2025-05-19 19:05:00,130:INFO:               tbats: 1.1.3
2025-05-19 19:05:00,130:INFO:            pmdarima: 2.0.4
2025-05-19 19:05:00,130:INFO:              psutil: 7.0.0
2025-05-19 19:05:00,130:INFO:          markupsafe: 3.0.2
2025-05-19 19:05:00,130:INFO:             pickle5: Not installed
2025-05-19 19:05:00,130:INFO:         cloudpickle: 3.1.1
2025-05-19 19:05:00,130:INFO:         deprecation: 2.1.0
2025-05-19 19:05:00,130:INFO:              xxhash: 3.5.0
2025-05-19 19:05:00,130:INFO:           wurlitzer: Not installed
2025-05-19 19:05:00,130:INFO:PyCaret optional dependencies:
2025-05-19 19:05:00,148:INFO:                shap: Not installed
2025-05-19 19:05:00,148:INFO:           interpret: Not installed
2025-05-19 19:05:00,148:INFO:                umap: Not installed
2025-05-19 19:05:00,148:INFO:     ydata_profiling: Not installed
2025-05-19 19:05:00,148:INFO:  explainerdashboard: Not installed
2025-05-19 19:05:00,148:INFO:             autoviz: Not installed
2025-05-19 19:05:00,148:INFO:           fairlearn: Not installed
2025-05-19 19:05:00,148:INFO:          deepchecks: Not installed
2025-05-19 19:05:00,148:INFO:             xgboost: Not installed
2025-05-19 19:05:00,148:INFO:            catboost: Not installed
2025-05-19 19:05:00,148:INFO:              kmodes: Not installed
2025-05-19 19:05:00,149:INFO:             mlxtend: Not installed
2025-05-19 19:05:00,149:INFO:       statsforecast: Not installed
2025-05-19 19:05:00,149:INFO:        tune_sklearn: Not installed
2025-05-19 19:05:00,149:INFO:                 ray: Not installed
2025-05-19 19:05:00,149:INFO:            hyperopt: Not installed
2025-05-19 19:05:00,149:INFO:              optuna: Not installed
2025-05-19 19:05:00,149:INFO:               skopt: Not installed
2025-05-19 19:05:00,149:INFO:              mlflow: Not installed
2025-05-19 19:05:00,149:INFO:              gradio: Not installed
2025-05-19 19:05:00,149:INFO:             fastapi: Not installed
2025-05-19 19:05:00,149:INFO:             uvicorn: Not installed
2025-05-19 19:05:00,149:INFO:              m2cgen: Not installed
2025-05-19 19:05:00,149:INFO:           evidently: Not installed
2025-05-19 19:05:00,149:INFO:               fugue: Not installed
2025-05-19 19:05:00,149:INFO:           streamlit: Not installed
2025-05-19 19:05:00,149:INFO:             prophet: Not installed
2025-05-19 19:05:00,149:INFO:None
2025-05-19 19:05:00,149:INFO:Set up data.
2025-05-19 19:05:00,158:INFO:Set up folding strategy.
2025-05-19 19:05:00,158:INFO:Set up train/test split.
2025-05-19 19:05:00,173:INFO:Set up index.
2025-05-19 19:05:00,173:INFO:Assigning column types.
2025-05-19 19:05:00,176:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-19 19:05:00,212:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 19:05:00,220:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 19:05:00,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,308:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 19:05:00,308:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 19:05:00,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,331:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-19 19:05:00,369:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 19:05:00,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,428:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 19:05:00,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,451:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-19 19:05:00,536:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,604:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,604:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,607:INFO:Preparing preprocessing pipeline...
2025-05-19 19:05:00,609:INFO:Set up simple imputation.
2025-05-19 19:05:00,611:INFO:Set up encoding of categorical features.
2025-05-19 19:05:00,611:INFO:Set up removing multicollinearity.
2025-05-19 19:05:00,611:INFO:Set up column transformation.
2025-05-19 19:05:00,611:INFO:Set up feature normalization.
2025-05-19 19:05:00,612:INFO:Set up feature selection.
2025-05-19 19:05:00,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:00,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:01,107:INFO:Finished creating preprocessing pipeline.
2025-05-19 19:05:01,121:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2025-05-19 19:05:01,121:INFO:Creating final display dataframe.
2025-05-19 19:05:01,539:INFO:Setup _display_container:                     Description             Value
0                    Session id              2025
1                        Target        conversion
2                   Target type            Binary
3           Original data shape         (220, 10)
4        Transformed data shape          (220, 2)
5   Transformed train set shape          (154, 2)
6    Transformed test set shape           (66, 2)
7               Ignore features                 2
8              Numeric features                 3
9          Categorical features                 4
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.9
18               Transformation              True
19        Transformation method       yeo-johnson
20                    Normalize              True
21             Normalize method            zscore
22            Feature selection              True
23     Feature selection method           classic
24  Feature selection estimator          lightgbm
25  Number of features selected               0.2
26               Fold Generator   StratifiedKFold
27                  Fold Number                10
28                     CPU Jobs                -1
29                      Use GPU             False
30               Log Experiment             False
31              Experiment Name  clf-default-name
32                          USI              6c64
2025-05-19 19:05:01,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:01,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:01,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:01,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 19:05:01,698:INFO:setup() successfully completed in 1.7s...............
2025-05-19 19:05:20,796:INFO:Initializing compare_models()
2025-05-19 19:05:20,797:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 19:05:20,797:INFO:Checking exceptions
2025-05-19 19:05:20,803:INFO:Preparing display monitor
2025-05-19 19:05:20,851:INFO:Initializing Logistic Regression
2025-05-19 19:05:20,851:INFO:Total runtime is 0.0 minutes
2025-05-19 19:05:20,860:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:20,861:INFO:Initializing create_model()
2025-05-19 19:05:20,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:20,861:INFO:Checking exceptions
2025-05-19 19:05:20,862:INFO:Importing libraries
2025-05-19 19:05:20,862:INFO:Copying training dataset
2025-05-19 19:05:20,867:INFO:Defining folds
2025-05-19 19:05:20,867:INFO:Declaring metric variables
2025-05-19 19:05:20,873:INFO:Importing untrained model
2025-05-19 19:05:20,883:INFO:Logistic Regression Imported successfully
2025-05-19 19:05:20,897:INFO:Starting cross validation
2025-05-19 19:05:20,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:27,099:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:27,100:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:27,114:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:27,272:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:27,277:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:27,281:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:27,313:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:27,403:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:27,418:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:27,431:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:27,440:INFO:Calculating mean and std
2025-05-19 19:05:27,445:INFO:Creating metrics dataframe
2025-05-19 19:05:27,448:INFO:Uploading results into container
2025-05-19 19:05:27,449:INFO:Uploading model into container now
2025-05-19 19:05:27,450:INFO:_master_model_container: 1
2025-05-19 19:05:27,450:INFO:_display_container: 2
2025-05-19 19:05:27,451:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 19:05:27,451:INFO:create_model() successfully completed......................................
2025-05-19 19:05:27,579:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:27,579:INFO:Creating metrics dataframe
2025-05-19 19:05:27,587:INFO:Initializing K Neighbors Classifier
2025-05-19 19:05:27,587:INFO:Total runtime is 0.11226380666097005 minutes
2025-05-19 19:05:27,592:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:27,592:INFO:Initializing create_model()
2025-05-19 19:05:27,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:27,592:INFO:Checking exceptions
2025-05-19 19:05:27,593:INFO:Importing libraries
2025-05-19 19:05:27,593:INFO:Copying training dataset
2025-05-19 19:05:27,597:INFO:Defining folds
2025-05-19 19:05:27,597:INFO:Declaring metric variables
2025-05-19 19:05:27,600:INFO:Importing untrained model
2025-05-19 19:05:27,602:INFO:K Neighbors Classifier Imported successfully
2025-05-19 19:05:27,610:INFO:Starting cross validation
2025-05-19 19:05:27,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:28,320:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:30,758:INFO:Calculating mean and std
2025-05-19 19:05:30,760:INFO:Creating metrics dataframe
2025-05-19 19:05:30,762:INFO:Uploading results into container
2025-05-19 19:05:30,764:INFO:Uploading model into container now
2025-05-19 19:05:30,764:INFO:_master_model_container: 2
2025-05-19 19:05:30,765:INFO:_display_container: 2
2025-05-19 19:05:30,765:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 19:05:30,765:INFO:create_model() successfully completed......................................
2025-05-19 19:05:30,881:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:30,881:INFO:Creating metrics dataframe
2025-05-19 19:05:30,888:INFO:Initializing Naive Bayes
2025-05-19 19:05:30,888:INFO:Total runtime is 0.16728187799453736 minutes
2025-05-19 19:05:30,894:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:30,894:INFO:Initializing create_model()
2025-05-19 19:05:30,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:30,895:INFO:Checking exceptions
2025-05-19 19:05:30,895:INFO:Importing libraries
2025-05-19 19:05:30,895:INFO:Copying training dataset
2025-05-19 19:05:30,900:INFO:Defining folds
2025-05-19 19:05:30,900:INFO:Declaring metric variables
2025-05-19 19:05:30,905:INFO:Importing untrained model
2025-05-19 19:05:30,909:INFO:Naive Bayes Imported successfully
2025-05-19 19:05:30,916:INFO:Starting cross validation
2025-05-19 19:05:30,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:31,283:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:31,289:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:31,299:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:31,307:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:31,362:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:31,370:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:31,370:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:31,390:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:31,427:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:31,435:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:31,451:INFO:Calculating mean and std
2025-05-19 19:05:31,452:INFO:Creating metrics dataframe
2025-05-19 19:05:31,457:INFO:Uploading results into container
2025-05-19 19:05:31,457:INFO:Uploading model into container now
2025-05-19 19:05:31,459:INFO:_master_model_container: 3
2025-05-19 19:05:31,459:INFO:_display_container: 2
2025-05-19 19:05:31,460:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 19:05:31,460:INFO:create_model() successfully completed......................................
2025-05-19 19:05:31,577:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:31,577:INFO:Creating metrics dataframe
2025-05-19 19:05:31,586:INFO:Initializing Decision Tree Classifier
2025-05-19 19:05:31,586:INFO:Total runtime is 0.1789113481839498 minutes
2025-05-19 19:05:31,590:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:31,590:INFO:Initializing create_model()
2025-05-19 19:05:31,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:31,590:INFO:Checking exceptions
2025-05-19 19:05:31,590:INFO:Importing libraries
2025-05-19 19:05:31,590:INFO:Copying training dataset
2025-05-19 19:05:31,594:INFO:Defining folds
2025-05-19 19:05:31,595:INFO:Declaring metric variables
2025-05-19 19:05:31,599:INFO:Importing untrained model
2025-05-19 19:05:31,603:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:05:31,610:INFO:Starting cross validation
2025-05-19 19:05:31,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:32,112:INFO:Calculating mean and std
2025-05-19 19:05:32,113:INFO:Creating metrics dataframe
2025-05-19 19:05:32,115:INFO:Uploading results into container
2025-05-19 19:05:32,116:INFO:Uploading model into container now
2025-05-19 19:05:32,117:INFO:_master_model_container: 4
2025-05-19 19:05:32,117:INFO:_display_container: 2
2025-05-19 19:05:32,118:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:05:32,118:INFO:create_model() successfully completed......................................
2025-05-19 19:05:32,236:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:32,236:INFO:Creating metrics dataframe
2025-05-19 19:05:32,245:INFO:Initializing SVM - Linear Kernel
2025-05-19 19:05:32,245:INFO:Total runtime is 0.18990034659703572 minutes
2025-05-19 19:05:32,248:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:32,248:INFO:Initializing create_model()
2025-05-19 19:05:32,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:32,249:INFO:Checking exceptions
2025-05-19 19:05:32,249:INFO:Importing libraries
2025-05-19 19:05:32,249:INFO:Copying training dataset
2025-05-19 19:05:32,252:INFO:Defining folds
2025-05-19 19:05:32,253:INFO:Declaring metric variables
2025-05-19 19:05:32,257:INFO:Importing untrained model
2025-05-19 19:05:32,261:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 19:05:32,269:INFO:Starting cross validation
2025-05-19 19:05:32,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:32,669:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:32,680:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:32,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:32,728:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:32,734:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:32,743:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:32,756:INFO:Calculating mean and std
2025-05-19 19:05:32,757:INFO:Creating metrics dataframe
2025-05-19 19:05:32,761:INFO:Uploading results into container
2025-05-19 19:05:32,762:INFO:Uploading model into container now
2025-05-19 19:05:32,763:INFO:_master_model_container: 5
2025-05-19 19:05:32,763:INFO:_display_container: 2
2025-05-19 19:05:32,763:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 19:05:32,764:INFO:create_model() successfully completed......................................
2025-05-19 19:05:32,878:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:32,879:INFO:Creating metrics dataframe
2025-05-19 19:05:32,887:INFO:Initializing Ridge Classifier
2025-05-19 19:05:32,887:INFO:Total runtime is 0.20058924357096353 minutes
2025-05-19 19:05:32,891:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:32,891:INFO:Initializing create_model()
2025-05-19 19:05:32,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:32,892:INFO:Checking exceptions
2025-05-19 19:05:32,892:INFO:Importing libraries
2025-05-19 19:05:32,892:INFO:Copying training dataset
2025-05-19 19:05:32,898:INFO:Defining folds
2025-05-19 19:05:32,898:INFO:Declaring metric variables
2025-05-19 19:05:32,904:INFO:Importing untrained model
2025-05-19 19:05:32,909:INFO:Ridge Classifier Imported successfully
2025-05-19 19:05:32,918:INFO:Starting cross validation
2025-05-19 19:05:32,925:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:33,273:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:33,275:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:33,278:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:33,294:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:33,336:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:33,351:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:33,361:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:33,367:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:33,417:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:33,419:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:33,426:INFO:Calculating mean and std
2025-05-19 19:05:33,428:INFO:Creating metrics dataframe
2025-05-19 19:05:33,430:INFO:Uploading results into container
2025-05-19 19:05:33,430:INFO:Uploading model into container now
2025-05-19 19:05:33,431:INFO:_master_model_container: 6
2025-05-19 19:05:33,431:INFO:_display_container: 2
2025-05-19 19:05:33,432:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-19 19:05:33,432:INFO:create_model() successfully completed......................................
2025-05-19 19:05:33,545:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:33,545:INFO:Creating metrics dataframe
2025-05-19 19:05:33,554:INFO:Initializing Random Forest Classifier
2025-05-19 19:05:33,554:INFO:Total runtime is 0.21172007719675698 minutes
2025-05-19 19:05:33,558:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:33,558:INFO:Initializing create_model()
2025-05-19 19:05:33,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:33,559:INFO:Checking exceptions
2025-05-19 19:05:33,559:INFO:Importing libraries
2025-05-19 19:05:33,559:INFO:Copying training dataset
2025-05-19 19:05:33,562:INFO:Defining folds
2025-05-19 19:05:33,562:INFO:Declaring metric variables
2025-05-19 19:05:33,566:INFO:Importing untrained model
2025-05-19 19:05:33,570:INFO:Random Forest Classifier Imported successfully
2025-05-19 19:05:33,577:INFO:Starting cross validation
2025-05-19 19:05:33,585:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:34,504:INFO:Calculating mean and std
2025-05-19 19:05:34,506:INFO:Creating metrics dataframe
2025-05-19 19:05:34,508:INFO:Uploading results into container
2025-05-19 19:05:34,510:INFO:Uploading model into container now
2025-05-19 19:05:34,510:INFO:_master_model_container: 7
2025-05-19 19:05:34,511:INFO:_display_container: 2
2025-05-19 19:05:34,512:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-19 19:05:34,512:INFO:create_model() successfully completed......................................
2025-05-19 19:05:34,640:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:34,640:INFO:Creating metrics dataframe
2025-05-19 19:05:34,649:INFO:Initializing Quadratic Discriminant Analysis
2025-05-19 19:05:34,649:INFO:Total runtime is 0.2299711187680562 minutes
2025-05-19 19:05:34,655:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:34,656:INFO:Initializing create_model()
2025-05-19 19:05:34,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:34,656:INFO:Checking exceptions
2025-05-19 19:05:34,656:INFO:Importing libraries
2025-05-19 19:05:34,657:INFO:Copying training dataset
2025-05-19 19:05:34,669:INFO:Defining folds
2025-05-19 19:05:34,670:INFO:Declaring metric variables
2025-05-19 19:05:34,675:INFO:Importing untrained model
2025-05-19 19:05:34,679:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 19:05:34,688:INFO:Starting cross validation
2025-05-19 19:05:34,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:35,032:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:35,042:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:35,050:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:35,102:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:35,106:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:35,114:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:35,116:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:35,162:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:35,178:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:35,187:INFO:Calculating mean and std
2025-05-19 19:05:35,189:INFO:Creating metrics dataframe
2025-05-19 19:05:35,191:INFO:Uploading results into container
2025-05-19 19:05:35,193:INFO:Uploading model into container now
2025-05-19 19:05:35,193:INFO:_master_model_container: 8
2025-05-19 19:05:35,194:INFO:_display_container: 2
2025-05-19 19:05:35,194:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 19:05:35,194:INFO:create_model() successfully completed......................................
2025-05-19 19:05:35,306:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:35,307:INFO:Creating metrics dataframe
2025-05-19 19:05:35,317:INFO:Initializing Ada Boost Classifier
2025-05-19 19:05:35,317:INFO:Total runtime is 0.24108858505884803 minutes
2025-05-19 19:05:35,322:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:35,322:INFO:Initializing create_model()
2025-05-19 19:05:35,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:35,322:INFO:Checking exceptions
2025-05-19 19:05:35,322:INFO:Importing libraries
2025-05-19 19:05:35,322:INFO:Copying training dataset
2025-05-19 19:05:35,328:INFO:Defining folds
2025-05-19 19:05:35,329:INFO:Declaring metric variables
2025-05-19 19:05:35,334:INFO:Importing untrained model
2025-05-19 19:05:35,337:INFO:Ada Boost Classifier Imported successfully
2025-05-19 19:05:35,347:INFO:Starting cross validation
2025-05-19 19:05:35,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:35,623:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:05:35,642:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:05:35,663:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:05:35,671:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:05:35,789:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:05:35,823:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:05:35,831:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:05:35,834:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:05:35,938:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:05:35,943:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:05:36,070:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:36,085:INFO:Calculating mean and std
2025-05-19 19:05:36,086:INFO:Creating metrics dataframe
2025-05-19 19:05:36,088:INFO:Uploading results into container
2025-05-19 19:05:36,089:INFO:Uploading model into container now
2025-05-19 19:05:36,090:INFO:_master_model_container: 9
2025-05-19 19:05:36,090:INFO:_display_container: 2
2025-05-19 19:05:36,090:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 19:05:36,090:INFO:create_model() successfully completed......................................
2025-05-19 19:05:36,203:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:36,203:INFO:Creating metrics dataframe
2025-05-19 19:05:36,214:INFO:Initializing Gradient Boosting Classifier
2025-05-19 19:05:36,215:INFO:Total runtime is 0.25606538454691563 minutes
2025-05-19 19:05:36,221:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:36,221:INFO:Initializing create_model()
2025-05-19 19:05:36,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:36,222:INFO:Checking exceptions
2025-05-19 19:05:36,222:INFO:Importing libraries
2025-05-19 19:05:36,222:INFO:Copying training dataset
2025-05-19 19:05:36,228:INFO:Defining folds
2025-05-19 19:05:36,228:INFO:Declaring metric variables
2025-05-19 19:05:36,233:INFO:Importing untrained model
2025-05-19 19:05:36,239:INFO:Gradient Boosting Classifier Imported successfully
2025-05-19 19:05:36,250:INFO:Starting cross validation
2025-05-19 19:05:36,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:36,931:INFO:Calculating mean and std
2025-05-19 19:05:36,932:INFO:Creating metrics dataframe
2025-05-19 19:05:36,935:INFO:Uploading results into container
2025-05-19 19:05:36,936:INFO:Uploading model into container now
2025-05-19 19:05:36,936:INFO:_master_model_container: 10
2025-05-19 19:05:36,936:INFO:_display_container: 2
2025-05-19 19:05:36,937:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-19 19:05:36,937:INFO:create_model() successfully completed......................................
2025-05-19 19:05:37,057:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:37,058:INFO:Creating metrics dataframe
2025-05-19 19:05:37,065:INFO:Initializing Linear Discriminant Analysis
2025-05-19 19:05:37,066:INFO:Total runtime is 0.27024832963943474 minutes
2025-05-19 19:05:37,069:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:37,069:INFO:Initializing create_model()
2025-05-19 19:05:37,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:37,069:INFO:Checking exceptions
2025-05-19 19:05:37,070:INFO:Importing libraries
2025-05-19 19:05:37,070:INFO:Copying training dataset
2025-05-19 19:05:37,073:INFO:Defining folds
2025-05-19 19:05:37,073:INFO:Declaring metric variables
2025-05-19 19:05:37,077:INFO:Importing untrained model
2025-05-19 19:05:37,082:INFO:Linear Discriminant Analysis Imported successfully
2025-05-19 19:05:37,088:INFO:Starting cross validation
2025-05-19 19:05:37,094:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:37,433:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:37,436:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:37,436:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:37,440:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:37,492:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:37,500:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:37,509:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:37,516:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:37,557:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:37,564:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:37,577:INFO:Calculating mean and std
2025-05-19 19:05:37,578:INFO:Creating metrics dataframe
2025-05-19 19:05:37,581:INFO:Uploading results into container
2025-05-19 19:05:37,582:INFO:Uploading model into container now
2025-05-19 19:05:37,582:INFO:_master_model_container: 11
2025-05-19 19:05:37,583:INFO:_display_container: 2
2025-05-19 19:05:37,583:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-19 19:05:37,583:INFO:create_model() successfully completed......................................
2025-05-19 19:05:37,696:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:37,696:INFO:Creating metrics dataframe
2025-05-19 19:05:37,704:INFO:Initializing Extra Trees Classifier
2025-05-19 19:05:37,704:INFO:Total runtime is 0.2808860023816426 minutes
2025-05-19 19:05:37,708:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:37,709:INFO:Initializing create_model()
2025-05-19 19:05:37,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:37,710:INFO:Checking exceptions
2025-05-19 19:05:37,710:INFO:Importing libraries
2025-05-19 19:05:37,710:INFO:Copying training dataset
2025-05-19 19:05:37,716:INFO:Defining folds
2025-05-19 19:05:37,716:INFO:Declaring metric variables
2025-05-19 19:05:37,722:INFO:Importing untrained model
2025-05-19 19:05:37,727:INFO:Extra Trees Classifier Imported successfully
2025-05-19 19:05:37,735:INFO:Starting cross validation
2025-05-19 19:05:37,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:38,569:INFO:Calculating mean and std
2025-05-19 19:05:38,570:INFO:Creating metrics dataframe
2025-05-19 19:05:38,572:INFO:Uploading results into container
2025-05-19 19:05:38,574:INFO:Uploading model into container now
2025-05-19 19:05:38,575:INFO:_master_model_container: 12
2025-05-19 19:05:38,575:INFO:_display_container: 2
2025-05-19 19:05:38,576:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-19 19:05:38,576:INFO:create_model() successfully completed......................................
2025-05-19 19:05:38,695:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:38,695:INFO:Creating metrics dataframe
2025-05-19 19:05:38,713:INFO:Initializing Light Gradient Boosting Machine
2025-05-19 19:05:38,713:INFO:Total runtime is 0.2977020541826883 minutes
2025-05-19 19:05:38,717:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:38,718:INFO:Initializing create_model()
2025-05-19 19:05:38,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:38,718:INFO:Checking exceptions
2025-05-19 19:05:38,718:INFO:Importing libraries
2025-05-19 19:05:38,719:INFO:Copying training dataset
2025-05-19 19:05:38,722:INFO:Defining folds
2025-05-19 19:05:38,722:INFO:Declaring metric variables
2025-05-19 19:05:38,726:INFO:Importing untrained model
2025-05-19 19:05:38,732:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-19 19:05:38,741:INFO:Starting cross validation
2025-05-19 19:05:38,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:39,253:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:39,270:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:39,318:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:39,379:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:39,384:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:39,454:INFO:Calculating mean and std
2025-05-19 19:05:39,456:INFO:Creating metrics dataframe
2025-05-19 19:05:39,460:INFO:Uploading results into container
2025-05-19 19:05:39,460:INFO:Uploading model into container now
2025-05-19 19:05:39,461:INFO:_master_model_container: 13
2025-05-19 19:05:39,461:INFO:_display_container: 2
2025-05-19 19:05:39,462:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-19 19:05:39,462:INFO:create_model() successfully completed......................................
2025-05-19 19:05:39,590:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:39,590:INFO:Creating metrics dataframe
2025-05-19 19:05:39,600:INFO:Initializing Dummy Classifier
2025-05-19 19:05:39,600:INFO:Total runtime is 0.3124844312667846 minutes
2025-05-19 19:05:39,604:INFO:SubProcess create_model() called ==================================
2025-05-19 19:05:39,604:INFO:Initializing create_model()
2025-05-19 19:05:39,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170825C6410>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:39,605:INFO:Checking exceptions
2025-05-19 19:05:39,605:INFO:Importing libraries
2025-05-19 19:05:39,605:INFO:Copying training dataset
2025-05-19 19:05:39,609:INFO:Defining folds
2025-05-19 19:05:39,609:INFO:Declaring metric variables
2025-05-19 19:05:39,614:INFO:Importing untrained model
2025-05-19 19:05:39,618:INFO:Dummy Classifier Imported successfully
2025-05-19 19:05:39,624:INFO:Starting cross validation
2025-05-19 19:05:39,633:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:05:39,945:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:39,946:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:39,952:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:39,968:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:40,029:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:40,040:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:40,099:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:40,100:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:40,122:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:40,155:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:05:40,169:INFO:Calculating mean and std
2025-05-19 19:05:40,170:INFO:Creating metrics dataframe
2025-05-19 19:05:40,173:INFO:Uploading results into container
2025-05-19 19:05:40,174:INFO:Uploading model into container now
2025-05-19 19:05:40,175:INFO:_master_model_container: 14
2025-05-19 19:05:40,176:INFO:_display_container: 2
2025-05-19 19:05:40,176:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-19 19:05:40,176:INFO:create_model() successfully completed......................................
2025-05-19 19:05:40,290:INFO:SubProcess create_model() end ==================================
2025-05-19 19:05:40,290:INFO:Creating metrics dataframe
2025-05-19 19:05:40,304:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-19 19:05:40,314:INFO:Initializing create_model()
2025-05-19 19:05:40,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:05:40,314:INFO:Checking exceptions
2025-05-19 19:05:40,317:INFO:Importing libraries
2025-05-19 19:05:40,317:INFO:Copying training dataset
2025-05-19 19:05:40,319:INFO:Defining folds
2025-05-19 19:05:40,319:INFO:Declaring metric variables
2025-05-19 19:05:40,319:INFO:Importing untrained model
2025-05-19 19:05:40,319:INFO:Declaring custom model
2025-05-19 19:05:40,320:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:05:40,328:INFO:Cross validation set to False
2025-05-19 19:05:40,328:INFO:Fitting Model
2025-05-19 19:05:40,417:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:05:40,417:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000064 seconds.
2025-05-19 19:05:40,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 19:05:40,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 19:05:40,417:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:05:40,417:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:05:40,417:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:05:40,417:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:05:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:05:40,439:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:05:40,439:INFO:create_model() successfully completed......................................
2025-05-19 19:05:40,587:INFO:_master_model_container: 14
2025-05-19 19:05:40,587:INFO:_display_container: 2
2025-05-19 19:05:40,588:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:05:40,588:INFO:compare_models() successfully completed......................................
2025-05-19 19:25:58,433:INFO:Initializing tune_model()
2025-05-19 19:25:58,433:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 19:25:58,433:INFO:Checking exceptions
2025-05-19 19:25:58,453:INFO:Copying training dataset
2025-05-19 19:25:58,457:INFO:Checking base model
2025-05-19 19:25:58,458:INFO:Base model : Decision Tree Classifier
2025-05-19 19:25:58,462:INFO:Declaring metric variables
2025-05-19 19:25:58,467:INFO:Defining Hyperparameters
2025-05-19 19:25:58,657:INFO:Tuning with n_jobs=-1
2025-05-19 19:25:58,657:INFO:Initializing RandomizedSearchCV
2025-05-19 19:26:11,391:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-05-19 19:26:11,393:INFO:Hyperparameter search completed
2025-05-19 19:26:11,393:INFO:SubProcess create_model() called ==================================
2025-05-19 19:26:11,394:INFO:Initializing create_model()
2025-05-19 19:26:11,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B7A950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-05-19 19:26:11,394:INFO:Checking exceptions
2025-05-19 19:26:11,394:INFO:Importing libraries
2025-05-19 19:26:11,394:INFO:Copying training dataset
2025-05-19 19:26:11,401:INFO:Defining folds
2025-05-19 19:26:11,401:INFO:Declaring metric variables
2025-05-19 19:26:11,406:INFO:Importing untrained model
2025-05-19 19:26:11,406:INFO:Declaring custom model
2025-05-19 19:26:11,411:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:26:11,418:INFO:Starting cross validation
2025-05-19 19:26:11,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:26:11,771:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:26:11,909:INFO:Calculating mean and std
2025-05-19 19:26:11,910:INFO:Creating metrics dataframe
2025-05-19 19:26:11,918:INFO:Finalizing model
2025-05-19 19:26:12,028:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:26:12,029:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.
2025-05-19 19:26:12,029:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 19:26:12,029:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 19:26:12,029:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:26:12,029:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:26:12,030:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:26:12,030:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:26:12,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,065:INFO:Uploading results into container
2025-05-19 19:26:12,066:INFO:Uploading model into container now
2025-05-19 19:26:12,068:INFO:_master_model_container: 15
2025-05-19 19:26:12,068:INFO:_display_container: 3
2025-05-19 19:26:12,069:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:26:12,069:INFO:create_model() successfully completed......................................
2025-05-19 19:26:12,207:INFO:SubProcess create_model() end ==================================
2025-05-19 19:26:12,207:INFO:choose_better activated
2025-05-19 19:26:12,211:INFO:SubProcess create_model() called ==================================
2025-05-19 19:26:12,212:INFO:Initializing create_model()
2025-05-19 19:26:12,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:26:12,212:INFO:Checking exceptions
2025-05-19 19:26:12,213:INFO:Importing libraries
2025-05-19 19:26:12,215:INFO:Copying training dataset
2025-05-19 19:26:12,217:INFO:Defining folds
2025-05-19 19:26:12,217:INFO:Declaring metric variables
2025-05-19 19:26:12,218:INFO:Importing untrained model
2025-05-19 19:26:12,218:INFO:Declaring custom model
2025-05-19 19:26:12,218:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:26:12,218:INFO:Starting cross validation
2025-05-19 19:26:12,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:26:12,708:INFO:Calculating mean and std
2025-05-19 19:26:12,708:INFO:Creating metrics dataframe
2025-05-19 19:26:12,710:INFO:Finalizing model
2025-05-19 19:26:12,808:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:26:12,809:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.
2025-05-19 19:26:12,809:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:26:12,809:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:26:12,809:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:26:12,809:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:26:12,809:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:26:12,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:26:12,832:INFO:Uploading results into container
2025-05-19 19:26:12,832:INFO:Uploading model into container now
2025-05-19 19:26:12,833:INFO:_master_model_container: 16
2025-05-19 19:26:12,833:INFO:_display_container: 4
2025-05-19 19:26:12,833:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:26:12,833:INFO:create_model() successfully completed......................................
2025-05-19 19:26:12,958:INFO:SubProcess create_model() end ==================================
2025-05-19 19:26:12,959:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.3333
2025-05-19 19:26:12,959:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.24
2025-05-19 19:26:12,959:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-05-19 19:26:12,959:INFO:choose_better completed
2025-05-19 19:26:12,960:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 19:26:12,971:INFO:_master_model_container: 16
2025-05-19 19:26:12,971:INFO:_display_container: 3
2025-05-19 19:26:12,971:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:26:12,971:INFO:tune_model() successfully completed......................................
2025-05-19 19:26:13,088:INFO:Initializing plot_model()
2025-05-19 19:26:13,089:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:26:13,089:INFO:Checking exceptions
2025-05-19 19:26:13,092:INFO:Preloading libraries
2025-05-19 19:26:13,093:INFO:Copying training dataset
2025-05-19 19:26:13,093:INFO:Plot type: pr
2025-05-19 19:26:13,467:INFO:Fitting Model
2025-05-19 19:26:13,473:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:26:13,473:INFO:Scoring test/hold-out set
2025-05-19 19:26:13,612:INFO:Visual Rendered Successfully
2025-05-19 19:26:13,731:INFO:plot_model() successfully completed......................................
2025-05-19 19:26:13,733:INFO:Initializing plot_model()
2025-05-19 19:26:13,733:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:26:13,733:INFO:Checking exceptions
2025-05-19 19:26:13,737:INFO:Preloading libraries
2025-05-19 19:26:13,737:INFO:Copying training dataset
2025-05-19 19:26:13,737:INFO:Plot type: confusion_matrix
2025-05-19 19:26:14,096:INFO:Fitting Model
2025-05-19 19:26:14,097:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:26:14,097:INFO:Scoring test/hold-out set
2025-05-19 19:26:14,190:INFO:Visual Rendered Successfully
2025-05-19 19:26:14,302:INFO:plot_model() successfully completed......................................
2025-05-19 19:29:20,627:INFO:Initializing create_model()
2025-05-19 19:29:20,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:29:20,627:INFO:Checking exceptions
2025-05-19 19:29:20,643:INFO:Importing libraries
2025-05-19 19:29:20,643:INFO:Copying training dataset
2025-05-19 19:29:20,647:INFO:Defining folds
2025-05-19 19:29:20,647:INFO:Declaring metric variables
2025-05-19 19:29:20,651:INFO:Importing untrained model
2025-05-19 19:29:20,655:INFO:Ada Boost Classifier Imported successfully
2025-05-19 19:29:20,663:INFO:Starting cross validation
2025-05-19 19:29:20,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:29:20,966:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:20,974:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:20,983:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:21,043:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:21,143:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:21,149:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:21,186:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:21,211:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:21,322:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:21,324:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:21,361:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:29:21,459:INFO:Calculating mean and std
2025-05-19 19:29:21,459:INFO:Creating metrics dataframe
2025-05-19 19:29:21,463:INFO:Finalizing model
2025-05-19 19:29:21,538:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:29:21,539:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000198 seconds.
2025-05-19 19:29:21,539:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 19:29:21,539:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 19:29:21,539:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:29:21,539:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:29:21,540:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:29:21,540:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:29:21,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:21,563:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:29:21,630:INFO:Uploading results into container
2025-05-19 19:29:21,631:INFO:Uploading model into container now
2025-05-19 19:29:21,644:INFO:_master_model_container: 17
2025-05-19 19:29:21,644:INFO:_display_container: 4
2025-05-19 19:29:21,645:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 19:29:21,645:INFO:create_model() successfully completed......................................
2025-05-19 19:29:25,588:INFO:Initializing tune_model()
2025-05-19 19:29:25,589:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 19:29:25,589:INFO:Checking exceptions
2025-05-19 19:29:25,607:INFO:Copying training dataset
2025-05-19 19:29:25,611:INFO:Checking base model
2025-05-19 19:29:25,611:INFO:Base model : Decision Tree Classifier
2025-05-19 19:29:25,617:INFO:Declaring metric variables
2025-05-19 19:29:25,620:INFO:Defining Hyperparameters
2025-05-19 19:29:25,786:INFO:Tuning with n_jobs=-1
2025-05-19 19:29:25,786:INFO:Initializing RandomizedSearchCV
2025-05-19 19:29:32,111:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-05-19 19:29:32,112:INFO:Hyperparameter search completed
2025-05-19 19:29:32,112:INFO:SubProcess create_model() called ==================================
2025-05-19 19:29:32,113:INFO:Initializing create_model()
2025-05-19 19:29:32,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017081FC8890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-05-19 19:29:32,113:INFO:Checking exceptions
2025-05-19 19:29:32,113:INFO:Importing libraries
2025-05-19 19:29:32,113:INFO:Copying training dataset
2025-05-19 19:29:32,120:INFO:Defining folds
2025-05-19 19:29:32,121:INFO:Declaring metric variables
2025-05-19 19:29:32,124:INFO:Importing untrained model
2025-05-19 19:29:32,124:INFO:Declaring custom model
2025-05-19 19:29:32,129:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:29:32,137:INFO:Starting cross validation
2025-05-19 19:29:32,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:29:32,530:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:29:32,617:INFO:Calculating mean and std
2025-05-19 19:29:32,619:INFO:Creating metrics dataframe
2025-05-19 19:29:32,625:INFO:Finalizing model
2025-05-19 19:29:32,711:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:29:32,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.
2025-05-19 19:29:32,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:29:32,711:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:29:32,713:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:29:32,713:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:29:32,713:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:29:32,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:32,744:INFO:Uploading results into container
2025-05-19 19:29:32,745:INFO:Uploading model into container now
2025-05-19 19:29:32,746:INFO:_master_model_container: 18
2025-05-19 19:29:32,746:INFO:_display_container: 5
2025-05-19 19:29:32,747:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:29:32,747:INFO:create_model() successfully completed......................................
2025-05-19 19:29:32,875:INFO:SubProcess create_model() end ==================================
2025-05-19 19:29:32,875:INFO:choose_better activated
2025-05-19 19:29:32,879:INFO:SubProcess create_model() called ==================================
2025-05-19 19:29:32,879:INFO:Initializing create_model()
2025-05-19 19:29:32,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:29:32,879:INFO:Checking exceptions
2025-05-19 19:29:32,881:INFO:Importing libraries
2025-05-19 19:29:32,881:INFO:Copying training dataset
2025-05-19 19:29:32,884:INFO:Defining folds
2025-05-19 19:29:32,884:INFO:Declaring metric variables
2025-05-19 19:29:32,884:INFO:Importing untrained model
2025-05-19 19:29:32,884:INFO:Declaring custom model
2025-05-19 19:29:32,884:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:29:32,884:INFO:Starting cross validation
2025-05-19 19:29:32,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:29:33,321:INFO:Calculating mean and std
2025-05-19 19:29:33,321:INFO:Creating metrics dataframe
2025-05-19 19:29:33,322:INFO:Finalizing model
2025-05-19 19:29:33,405:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:29:33,406:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.
2025-05-19 19:29:33,406:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:29:33,406:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:29:33,406:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:29:33,406:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:29:33,406:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:29:33,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:29:33,429:INFO:Uploading results into container
2025-05-19 19:29:33,430:INFO:Uploading model into container now
2025-05-19 19:29:33,430:INFO:_master_model_container: 19
2025-05-19 19:29:33,430:INFO:_display_container: 6
2025-05-19 19:29:33,430:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:29:33,430:INFO:create_model() successfully completed......................................
2025-05-19 19:29:33,547:INFO:SubProcess create_model() end ==================================
2025-05-19 19:29:33,547:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.3333
2025-05-19 19:29:33,548:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for F1 is 0.24
2025-05-19 19:29:33,548:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-05-19 19:29:33,548:INFO:choose_better completed
2025-05-19 19:29:33,549:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 19:29:33,559:INFO:_master_model_container: 19
2025-05-19 19:29:33,559:INFO:_display_container: 5
2025-05-19 19:29:33,559:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:29:33,559:INFO:tune_model() successfully completed......................................
2025-05-19 19:29:33,668:INFO:Initializing plot_model()
2025-05-19 19:29:33,668:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:29:33,668:INFO:Checking exceptions
2025-05-19 19:29:33,672:INFO:Preloading libraries
2025-05-19 19:29:33,672:INFO:Copying training dataset
2025-05-19 19:29:33,672:INFO:Plot type: pr
2025-05-19 19:29:34,001:INFO:Fitting Model
2025-05-19 19:29:34,002:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:29:34,003:INFO:Scoring test/hold-out set
2025-05-19 19:29:34,134:INFO:Visual Rendered Successfully
2025-05-19 19:29:34,246:INFO:plot_model() successfully completed......................................
2025-05-19 19:29:34,247:INFO:Initializing plot_model()
2025-05-19 19:29:34,247:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:29:34,247:INFO:Checking exceptions
2025-05-19 19:29:34,251:INFO:Preloading libraries
2025-05-19 19:29:34,251:INFO:Copying training dataset
2025-05-19 19:29:34,251:INFO:Plot type: confusion_matrix
2025-05-19 19:29:34,590:INFO:Fitting Model
2025-05-19 19:29:34,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:29:34,590:INFO:Scoring test/hold-out set
2025-05-19 19:29:34,677:INFO:Visual Rendered Successfully
2025-05-19 19:29:34,787:INFO:plot_model() successfully completed......................................
2025-05-19 19:31:41,393:INFO:Initializing tune_model()
2025-05-19 19:31:41,393:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 19:31:41,393:INFO:Checking exceptions
2025-05-19 19:31:41,417:INFO:Copying training dataset
2025-05-19 19:31:41,421:INFO:Checking base model
2025-05-19 19:31:41,422:INFO:Base model : Decision Tree Classifier
2025-05-19 19:31:41,429:INFO:Declaring metric variables
2025-05-19 19:31:41,434:INFO:Defining Hyperparameters
2025-05-19 19:31:41,618:INFO:Tuning with n_jobs=-1
2025-05-19 19:31:41,618:INFO:Initializing RandomizedSearchCV
2025-05-19 19:31:42,149:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:42,163:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:42,431:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:42,455:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:42,520:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:42,667:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:43,003:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:43,020:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:43,026:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:43,031:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:43,322:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:43,338:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:43,401:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:43,518:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:43,581:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:44,173:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:44,483:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:44,660:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:44,729:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:44,758:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:44,866:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:44,900:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,066:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,066:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,071:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,100:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,250:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,266:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,281:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,293:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,457:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,466:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,604:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,652:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,664:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,781:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,826:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:45,883:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:46,274:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:46,289:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:46,662:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:46,703:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:46,794:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:46,961:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:46,997:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,024:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,169:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,201:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,289:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,429:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,463:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,520:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,536:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,620:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,621:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,641:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,678:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,697:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,707:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,734:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,762:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,786:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,787:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:47,797:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-05-19 19:31:47,798:INFO:Hyperparameter search completed
2025-05-19 19:31:47,798:INFO:SubProcess create_model() called ==================================
2025-05-19 19:31:47,799:INFO:Initializing create_model()
2025-05-19 19:31:47,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170840DBF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-05-19 19:31:47,799:INFO:Checking exceptions
2025-05-19 19:31:47,799:INFO:Importing libraries
2025-05-19 19:31:47,799:INFO:Copying training dataset
2025-05-19 19:31:47,806:INFO:Defining folds
2025-05-19 19:31:47,806:INFO:Declaring metric variables
2025-05-19 19:31:47,810:INFO:Importing untrained model
2025-05-19 19:31:47,810:INFO:Declaring custom model
2025-05-19 19:31:47,816:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:31:47,824:INFO:Starting cross validation
2025-05-19 19:31:47,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:31:48,183:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:48,337:INFO:Calculating mean and std
2025-05-19 19:31:48,339:INFO:Creating metrics dataframe
2025-05-19 19:31:48,347:INFO:Finalizing model
2025-05-19 19:31:48,426:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:31:48,427:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000071 seconds.
2025-05-19 19:31:48,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:31:48,427:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:31:48,427:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:31:48,427:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:31:48,427:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:31:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:48,453:INFO:Uploading results into container
2025-05-19 19:31:48,454:INFO:Uploading model into container now
2025-05-19 19:31:48,454:INFO:_master_model_container: 20
2025-05-19 19:31:48,454:INFO:_display_container: 6
2025-05-19 19:31:48,454:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:31:48,454:INFO:create_model() successfully completed......................................
2025-05-19 19:31:48,571:INFO:SubProcess create_model() end ==================================
2025-05-19 19:31:48,571:INFO:choose_better activated
2025-05-19 19:31:48,575:INFO:SubProcess create_model() called ==================================
2025-05-19 19:31:48,576:INFO:Initializing create_model()
2025-05-19 19:31:48,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:31:48,576:INFO:Checking exceptions
2025-05-19 19:31:48,578:INFO:Importing libraries
2025-05-19 19:31:48,578:INFO:Copying training dataset
2025-05-19 19:31:48,580:INFO:Defining folds
2025-05-19 19:31:48,580:INFO:Declaring metric variables
2025-05-19 19:31:48,580:INFO:Importing untrained model
2025-05-19 19:31:48,580:INFO:Declaring custom model
2025-05-19 19:31:48,581:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:31:48,581:INFO:Starting cross validation
2025-05-19 19:31:48,586:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:31:49,044:INFO:Calculating mean and std
2025-05-19 19:31:49,044:INFO:Creating metrics dataframe
2025-05-19 19:31:49,047:INFO:Finalizing model
2025-05-19 19:31:49,131:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:31:49,132:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000058 seconds.
2025-05-19 19:31:49,132:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:31:49,132:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:31:49,132:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:31:49,132:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:31:49,132:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:31:49,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:49,158:INFO:Uploading results into container
2025-05-19 19:31:49,158:INFO:Uploading model into container now
2025-05-19 19:31:49,159:INFO:_master_model_container: 21
2025-05-19 19:31:49,159:INFO:_display_container: 7
2025-05-19 19:31:49,159:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:31:49,159:INFO:create_model() successfully completed......................................
2025-05-19 19:31:49,277:INFO:SubProcess create_model() end ==================================
2025-05-19 19:31:49,278:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for Prec. is 0.325
2025-05-19 19:31:49,278:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for Prec. is 0.4333
2025-05-19 19:31:49,278:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-05-19 19:31:49,278:INFO:choose_better completed
2025-05-19 19:31:49,288:INFO:_master_model_container: 21
2025-05-19 19:31:49,288:INFO:_display_container: 6
2025-05-19 19:31:49,289:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:31:49,289:INFO:tune_model() successfully completed......................................
2025-05-19 19:31:49,397:INFO:Initializing plot_model()
2025-05-19 19:31:49,397:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:31:49,397:INFO:Checking exceptions
2025-05-19 19:31:49,401:INFO:Preloading libraries
2025-05-19 19:31:49,402:INFO:Copying training dataset
2025-05-19 19:31:49,402:INFO:Plot type: pr
2025-05-19 19:31:49,728:INFO:Fitting Model
2025-05-19 19:31:49,728:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:31:49,728:INFO:Scoring test/hold-out set
2025-05-19 19:31:49,854:INFO:Visual Rendered Successfully
2025-05-19 19:31:49,958:INFO:plot_model() successfully completed......................................
2025-05-19 19:31:49,959:INFO:Initializing plot_model()
2025-05-19 19:31:49,959:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:31:49,959:INFO:Checking exceptions
2025-05-19 19:31:49,965:INFO:Preloading libraries
2025-05-19 19:31:49,966:INFO:Copying training dataset
2025-05-19 19:31:49,966:INFO:Plot type: confusion_matrix
2025-05-19 19:31:50,300:INFO:Fitting Model
2025-05-19 19:31:50,300:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:31:50,301:INFO:Scoring test/hold-out set
2025-05-19 19:31:50,383:INFO:Visual Rendered Successfully
2025-05-19 19:31:50,490:INFO:plot_model() successfully completed......................................
2025-05-19 19:31:57,490:INFO:Initializing create_model()
2025-05-19 19:31:57,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:31:57,491:INFO:Checking exceptions
2025-05-19 19:31:57,509:INFO:Importing libraries
2025-05-19 19:31:57,509:INFO:Copying training dataset
2025-05-19 19:31:57,515:INFO:Defining folds
2025-05-19 19:31:57,516:INFO:Declaring metric variables
2025-05-19 19:31:57,521:INFO:Importing untrained model
2025-05-19 19:31:57,527:INFO:Ada Boost Classifier Imported successfully
2025-05-19 19:31:57,535:INFO:Starting cross validation
2025-05-19 19:31:57,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:31:57,916:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:57,931:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:57,954:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:58,091:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:58,189:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:58,214:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:58,371:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:58,388:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:58,451:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:58,484:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:58,616:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:31:58,624:INFO:Calculating mean and std
2025-05-19 19:31:58,626:INFO:Creating metrics dataframe
2025-05-19 19:31:58,634:INFO:Finalizing model
2025-05-19 19:31:58,719:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:31:58,720:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.
2025-05-19 19:31:58,720:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:31:58,720:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:31:58,720:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:31:58,721:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:31:58,721:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:31:58,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:31:58,751:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:31:58,826:INFO:Uploading results into container
2025-05-19 19:31:58,827:INFO:Uploading model into container now
2025-05-19 19:31:58,840:INFO:_master_model_container: 22
2025-05-19 19:31:58,841:INFO:_display_container: 7
2025-05-19 19:31:58,841:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 19:31:58,841:INFO:create_model() successfully completed......................................
2025-05-19 19:32:02,359:INFO:Initializing tune_model()
2025-05-19 19:32:02,360:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 19:32:02,360:INFO:Checking exceptions
2025-05-19 19:32:02,381:INFO:Copying training dataset
2025-05-19 19:32:02,386:INFO:Checking base model
2025-05-19 19:32:02,386:INFO:Base model : Decision Tree Classifier
2025-05-19 19:32:02,391:INFO:Declaring metric variables
2025-05-19 19:32:02,397:INFO:Defining Hyperparameters
2025-05-19 19:32:02,604:INFO:Tuning with n_jobs=-1
2025-05-19 19:32:02,604:INFO:Initializing RandomizedSearchCV
2025-05-19 19:32:03,125:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:03,138:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:03,220:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:03,377:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:03,599:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:03,689:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:03,955:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:03,961:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:03,978:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:04,004:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:04,157:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:04,185:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:04,356:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:04,364:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:04,551:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:04,939:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:05,356:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:05,457:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:05,558:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:05,622:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:05,658:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:05,853:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:05,883:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:05,971:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:05,980:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,029:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,065:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,161:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,202:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,232:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,279:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,386:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,520:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,557:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,744:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,757:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:06,783:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:07,048:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:07,359:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:07,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:07,548:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:07,733:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:07,771:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:07,918:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:07,957:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:07,977:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,107:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,131:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,246:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,251:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,347:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,362:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,404:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,413:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,423:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,448:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,476:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,478:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,538:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,546:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,557:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,564:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:08,571:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-05-19 19:32:08,574:INFO:Hyperparameter search completed
2025-05-19 19:32:08,574:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:08,574:INFO:Initializing create_model()
2025-05-19 19:32:08,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170840A57D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-05-19 19:32:08,574:INFO:Checking exceptions
2025-05-19 19:32:08,574:INFO:Importing libraries
2025-05-19 19:32:08,575:INFO:Copying training dataset
2025-05-19 19:32:08,581:INFO:Defining folds
2025-05-19 19:32:08,581:INFO:Declaring metric variables
2025-05-19 19:32:08,585:INFO:Importing untrained model
2025-05-19 19:32:08,585:INFO:Declaring custom model
2025-05-19 19:32:08,589:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:32:08,596:INFO:Starting cross validation
2025-05-19 19:32:08,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:08,923:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:09,048:INFO:Calculating mean and std
2025-05-19 19:32:09,050:INFO:Creating metrics dataframe
2025-05-19 19:32:09,057:INFO:Finalizing model
2025-05-19 19:32:09,136:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:32:09,137:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.
2025-05-19 19:32:09,137:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:32:09,137:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:32:09,137:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:32:09,137:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:32:09,137:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:32:09,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,166:INFO:Uploading results into container
2025-05-19 19:32:09,167:INFO:Uploading model into container now
2025-05-19 19:32:09,168:INFO:_master_model_container: 23
2025-05-19 19:32:09,168:INFO:_display_container: 8
2025-05-19 19:32:09,169:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:32:09,169:INFO:create_model() successfully completed......................................
2025-05-19 19:32:09,289:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:09,289:INFO:choose_better activated
2025-05-19 19:32:09,291:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:09,293:INFO:Initializing create_model()
2025-05-19 19:32:09,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:09,293:INFO:Checking exceptions
2025-05-19 19:32:09,295:INFO:Importing libraries
2025-05-19 19:32:09,295:INFO:Copying training dataset
2025-05-19 19:32:09,297:INFO:Defining folds
2025-05-19 19:32:09,298:INFO:Declaring metric variables
2025-05-19 19:32:09,298:INFO:Importing untrained model
2025-05-19 19:32:09,298:INFO:Declaring custom model
2025-05-19 19:32:09,298:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:32:09,298:INFO:Starting cross validation
2025-05-19 19:32:09,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:09,767:INFO:Calculating mean and std
2025-05-19 19:32:09,768:INFO:Creating metrics dataframe
2025-05-19 19:32:09,771:INFO:Finalizing model
2025-05-19 19:32:09,850:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:32:09,850:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000059 seconds.
2025-05-19 19:32:09,850:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:32:09,850:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:32:09,850:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:32:09,851:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:32:09,851:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:32:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:09,870:INFO:Uploading results into container
2025-05-19 19:32:09,871:INFO:Uploading model into container now
2025-05-19 19:32:09,871:INFO:_master_model_container: 24
2025-05-19 19:32:09,871:INFO:_display_container: 9
2025-05-19 19:32:09,871:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:32:09,871:INFO:create_model() successfully completed......................................
2025-05-19 19:32:09,989:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:09,989:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for Prec. is 0.325
2025-05-19 19:32:09,990:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for Prec. is 0.4333
2025-05-19 19:32:09,990:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-05-19 19:32:09,990:INFO:choose_better completed
2025-05-19 19:32:10,000:INFO:_master_model_container: 24
2025-05-19 19:32:10,000:INFO:_display_container: 8
2025-05-19 19:32:10,001:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:32:10,001:INFO:tune_model() successfully completed......................................
2025-05-19 19:32:10,110:INFO:Initializing plot_model()
2025-05-19 19:32:10,111:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:32:10,111:INFO:Checking exceptions
2025-05-19 19:32:10,114:INFO:Preloading libraries
2025-05-19 19:32:10,115:INFO:Copying training dataset
2025-05-19 19:32:10,115:INFO:Plot type: pr
2025-05-19 19:32:10,493:INFO:Fitting Model
2025-05-19 19:32:10,493:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:32:10,493:INFO:Scoring test/hold-out set
2025-05-19 19:32:10,632:INFO:Visual Rendered Successfully
2025-05-19 19:32:10,747:INFO:plot_model() successfully completed......................................
2025-05-19 19:32:10,748:INFO:Initializing plot_model()
2025-05-19 19:32:10,748:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:32:10,748:INFO:Checking exceptions
2025-05-19 19:32:10,752:INFO:Preloading libraries
2025-05-19 19:32:10,752:INFO:Copying training dataset
2025-05-19 19:32:10,753:INFO:Plot type: confusion_matrix
2025-05-19 19:32:11,085:INFO:Fitting Model
2025-05-19 19:32:11,085:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:32:11,086:INFO:Scoring test/hold-out set
2025-05-19 19:32:11,184:INFO:Visual Rendered Successfully
2025-05-19 19:32:11,295:INFO:plot_model() successfully completed......................................
2025-05-19 19:32:21,760:INFO:Initializing compare_models()
2025-05-19 19:32:21,760:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 19:32:21,760:INFO:Checking exceptions
2025-05-19 19:32:21,763:INFO:Preparing display monitor
2025-05-19 19:32:21,792:INFO:Initializing Logistic Regression
2025-05-19 19:32:21,792:INFO:Total runtime is 0.0 minutes
2025-05-19 19:32:21,798:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:21,799:INFO:Initializing create_model()
2025-05-19 19:32:21,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:21,799:INFO:Checking exceptions
2025-05-19 19:32:21,799:INFO:Importing libraries
2025-05-19 19:32:21,799:INFO:Copying training dataset
2025-05-19 19:32:21,804:INFO:Defining folds
2025-05-19 19:32:21,804:INFO:Declaring metric variables
2025-05-19 19:32:21,809:INFO:Importing untrained model
2025-05-19 19:32:21,814:INFO:Logistic Regression Imported successfully
2025-05-19 19:32:21,822:INFO:Starting cross validation
2025-05-19 19:32:21,831:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:22,391:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:22,415:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:22,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:22,505:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:22,510:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:22,511:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:22,548:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:22,569:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:22,572:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:22,573:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:22,579:INFO:Calculating mean and std
2025-05-19 19:32:22,580:INFO:Creating metrics dataframe
2025-05-19 19:32:22,583:INFO:Uploading results into container
2025-05-19 19:32:22,583:INFO:Uploading model into container now
2025-05-19 19:32:22,584:INFO:_master_model_container: 25
2025-05-19 19:32:22,584:INFO:_display_container: 9
2025-05-19 19:32:22,585:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2025, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 19:32:22,585:INFO:create_model() successfully completed......................................
2025-05-19 19:32:22,741:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:22,741:INFO:Creating metrics dataframe
2025-05-19 19:32:22,750:INFO:Initializing K Neighbors Classifier
2025-05-19 19:32:22,750:INFO:Total runtime is 0.01596458355585734 minutes
2025-05-19 19:32:22,754:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:22,755:INFO:Initializing create_model()
2025-05-19 19:32:22,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:22,755:INFO:Checking exceptions
2025-05-19 19:32:22,755:INFO:Importing libraries
2025-05-19 19:32:22,755:INFO:Copying training dataset
2025-05-19 19:32:22,758:INFO:Defining folds
2025-05-19 19:32:22,758:INFO:Declaring metric variables
2025-05-19 19:32:22,761:INFO:Importing untrained model
2025-05-19 19:32:22,766:INFO:K Neighbors Classifier Imported successfully
2025-05-19 19:32:22,776:INFO:Starting cross validation
2025-05-19 19:32:22,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:23,326:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:23,564:INFO:Calculating mean and std
2025-05-19 19:32:23,566:INFO:Creating metrics dataframe
2025-05-19 19:32:23,569:INFO:Uploading results into container
2025-05-19 19:32:23,570:INFO:Uploading model into container now
2025-05-19 19:32:23,570:INFO:_master_model_container: 26
2025-05-19 19:32:23,571:INFO:_display_container: 9
2025-05-19 19:32:23,571:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 19:32:23,571:INFO:create_model() successfully completed......................................
2025-05-19 19:32:23,726:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:23,727:INFO:Creating metrics dataframe
2025-05-19 19:32:23,735:INFO:Initializing Naive Bayes
2025-05-19 19:32:23,735:INFO:Total runtime is 0.0323827068010966 minutes
2025-05-19 19:32:23,739:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:23,740:INFO:Initializing create_model()
2025-05-19 19:32:23,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:23,740:INFO:Checking exceptions
2025-05-19 19:32:23,740:INFO:Importing libraries
2025-05-19 19:32:23,740:INFO:Copying training dataset
2025-05-19 19:32:23,744:INFO:Defining folds
2025-05-19 19:32:23,744:INFO:Declaring metric variables
2025-05-19 19:32:23,748:INFO:Importing untrained model
2025-05-19 19:32:23,753:INFO:Naive Bayes Imported successfully
2025-05-19 19:32:23,760:INFO:Starting cross validation
2025-05-19 19:32:23,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:24,167:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:24,173:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:24,191:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:24,201:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:24,250:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:24,251:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:24,279:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:24,308:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:24,319:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:24,327:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:24,343:INFO:Calculating mean and std
2025-05-19 19:32:24,344:INFO:Creating metrics dataframe
2025-05-19 19:32:24,349:INFO:Uploading results into container
2025-05-19 19:32:24,350:INFO:Uploading model into container now
2025-05-19 19:32:24,351:INFO:_master_model_container: 27
2025-05-19 19:32:24,351:INFO:_display_container: 9
2025-05-19 19:32:24,352:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 19:32:24,353:INFO:create_model() successfully completed......................................
2025-05-19 19:32:24,511:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:24,512:INFO:Creating metrics dataframe
2025-05-19 19:32:24,521:INFO:Initializing Decision Tree Classifier
2025-05-19 19:32:24,521:INFO:Total runtime is 0.04547995328903199 minutes
2025-05-19 19:32:24,527:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:24,528:INFO:Initializing create_model()
2025-05-19 19:32:24,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:24,529:INFO:Checking exceptions
2025-05-19 19:32:24,529:INFO:Importing libraries
2025-05-19 19:32:24,529:INFO:Copying training dataset
2025-05-19 19:32:24,534:INFO:Defining folds
2025-05-19 19:32:24,534:INFO:Declaring metric variables
2025-05-19 19:32:24,538:INFO:Importing untrained model
2025-05-19 19:32:24,541:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:32:24,551:INFO:Starting cross validation
2025-05-19 19:32:24,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:25,118:INFO:Calculating mean and std
2025-05-19 19:32:25,120:INFO:Creating metrics dataframe
2025-05-19 19:32:25,123:INFO:Uploading results into container
2025-05-19 19:32:25,124:INFO:Uploading model into container now
2025-05-19 19:32:25,125:INFO:_master_model_container: 28
2025-05-19 19:32:25,125:INFO:_display_container: 9
2025-05-19 19:32:25,126:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:32:25,126:INFO:create_model() successfully completed......................................
2025-05-19 19:32:25,248:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:25,248:INFO:Creating metrics dataframe
2025-05-19 19:32:25,256:INFO:Initializing SVM - Linear Kernel
2025-05-19 19:32:25,256:INFO:Total runtime is 0.05772986809412639 minutes
2025-05-19 19:32:25,259:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:25,260:INFO:Initializing create_model()
2025-05-19 19:32:25,260:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:25,260:INFO:Checking exceptions
2025-05-19 19:32:25,260:INFO:Importing libraries
2025-05-19 19:32:25,260:INFO:Copying training dataset
2025-05-19 19:32:25,266:INFO:Defining folds
2025-05-19 19:32:25,266:INFO:Declaring metric variables
2025-05-19 19:32:25,271:INFO:Importing untrained model
2025-05-19 19:32:25,275:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 19:32:25,283:INFO:Starting cross validation
2025-05-19 19:32:25,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:25,659:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:25,665:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:25,684:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:25,723:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:25,733:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:25,745:INFO:Calculating mean and std
2025-05-19 19:32:25,747:INFO:Creating metrics dataframe
2025-05-19 19:32:25,750:INFO:Uploading results into container
2025-05-19 19:32:25,751:INFO:Uploading model into container now
2025-05-19 19:32:25,751:INFO:_master_model_container: 29
2025-05-19 19:32:25,752:INFO:_display_container: 9
2025-05-19 19:32:25,753:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2025, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 19:32:25,753:INFO:create_model() successfully completed......................................
2025-05-19 19:32:25,866:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:25,866:INFO:Creating metrics dataframe
2025-05-19 19:32:25,873:INFO:Initializing Ridge Classifier
2025-05-19 19:32:25,874:INFO:Total runtime is 0.0680214524269104 minutes
2025-05-19 19:32:25,877:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:25,877:INFO:Initializing create_model()
2025-05-19 19:32:25,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:25,877:INFO:Checking exceptions
2025-05-19 19:32:25,877:INFO:Importing libraries
2025-05-19 19:32:25,877:INFO:Copying training dataset
2025-05-19 19:32:25,883:INFO:Defining folds
2025-05-19 19:32:25,884:INFO:Declaring metric variables
2025-05-19 19:32:25,888:INFO:Importing untrained model
2025-05-19 19:32:25,891:INFO:Ridge Classifier Imported successfully
2025-05-19 19:32:25,899:INFO:Starting cross validation
2025-05-19 19:32:25,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:26,224:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:26,226:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:26,229:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:26,240:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:26,296:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:26,299:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:26,310:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:26,311:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:26,358:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:26,367:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:26,377:INFO:Calculating mean and std
2025-05-19 19:32:26,378:INFO:Creating metrics dataframe
2025-05-19 19:32:26,381:INFO:Uploading results into container
2025-05-19 19:32:26,382:INFO:Uploading model into container now
2025-05-19 19:32:26,383:INFO:_master_model_container: 30
2025-05-19 19:32:26,383:INFO:_display_container: 9
2025-05-19 19:32:26,383:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2025, solver='auto',
                tol=0.0001)
2025-05-19 19:32:26,384:INFO:create_model() successfully completed......................................
2025-05-19 19:32:26,501:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:26,501:INFO:Creating metrics dataframe
2025-05-19 19:32:26,508:INFO:Initializing Random Forest Classifier
2025-05-19 19:32:26,509:INFO:Total runtime is 0.07860236167907715 minutes
2025-05-19 19:32:26,512:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:26,512:INFO:Initializing create_model()
2025-05-19 19:32:26,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:26,513:INFO:Checking exceptions
2025-05-19 19:32:26,513:INFO:Importing libraries
2025-05-19 19:32:26,513:INFO:Copying training dataset
2025-05-19 19:32:26,517:INFO:Defining folds
2025-05-19 19:32:26,517:INFO:Declaring metric variables
2025-05-19 19:32:26,520:INFO:Importing untrained model
2025-05-19 19:32:26,523:INFO:Random Forest Classifier Imported successfully
2025-05-19 19:32:26,528:INFO:Starting cross validation
2025-05-19 19:32:26,536:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:27,376:INFO:Calculating mean and std
2025-05-19 19:32:27,377:INFO:Creating metrics dataframe
2025-05-19 19:32:27,380:INFO:Uploading results into container
2025-05-19 19:32:27,380:INFO:Uploading model into container now
2025-05-19 19:32:27,381:INFO:_master_model_container: 31
2025-05-19 19:32:27,381:INFO:_display_container: 9
2025-05-19 19:32:27,381:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2025, verbose=0,
                       warm_start=False)
2025-05-19 19:32:27,381:INFO:create_model() successfully completed......................................
2025-05-19 19:32:27,496:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:27,497:INFO:Creating metrics dataframe
2025-05-19 19:32:27,506:INFO:Initializing Quadratic Discriminant Analysis
2025-05-19 19:32:27,506:INFO:Total runtime is 0.09522035916646322 minutes
2025-05-19 19:32:27,510:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:27,510:INFO:Initializing create_model()
2025-05-19 19:32:27,510:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:27,510:INFO:Checking exceptions
2025-05-19 19:32:27,511:INFO:Importing libraries
2025-05-19 19:32:27,511:INFO:Copying training dataset
2025-05-19 19:32:27,517:INFO:Defining folds
2025-05-19 19:32:27,517:INFO:Declaring metric variables
2025-05-19 19:32:27,521:INFO:Importing untrained model
2025-05-19 19:32:27,526:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 19:32:27,537:INFO:Starting cross validation
2025-05-19 19:32:27,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:27,820:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:27,839:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:27,841:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:27,867:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:27,877:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:27,910:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:27,913:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:27,945:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:27,963:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:27,972:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:27,986:INFO:Calculating mean and std
2025-05-19 19:32:27,988:INFO:Creating metrics dataframe
2025-05-19 19:32:27,991:INFO:Uploading results into container
2025-05-19 19:32:27,992:INFO:Uploading model into container now
2025-05-19 19:32:27,992:INFO:_master_model_container: 32
2025-05-19 19:32:27,993:INFO:_display_container: 9
2025-05-19 19:32:27,993:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 19:32:27,993:INFO:create_model() successfully completed......................................
2025-05-19 19:32:28,110:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:28,110:INFO:Creating metrics dataframe
2025-05-19 19:32:28,121:INFO:Initializing Ada Boost Classifier
2025-05-19 19:32:28,123:INFO:Total runtime is 0.10550625324249269 minutes
2025-05-19 19:32:28,125:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:28,125:INFO:Initializing create_model()
2025-05-19 19:32:28,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:28,126:INFO:Checking exceptions
2025-05-19 19:32:28,126:INFO:Importing libraries
2025-05-19 19:32:28,126:INFO:Copying training dataset
2025-05-19 19:32:28,130:INFO:Defining folds
2025-05-19 19:32:28,130:INFO:Declaring metric variables
2025-05-19 19:32:28,134:INFO:Importing untrained model
2025-05-19 19:32:28,138:INFO:Ada Boost Classifier Imported successfully
2025-05-19 19:32:28,147:INFO:Starting cross validation
2025-05-19 19:32:28,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:28,479:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:28,481:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:28,489:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:28,509:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:28,514:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:28,700:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:28,709:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:28,718:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:28,725:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:28,821:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:28,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:28,937:INFO:Calculating mean and std
2025-05-19 19:32:28,939:INFO:Creating metrics dataframe
2025-05-19 19:32:28,941:INFO:Uploading results into container
2025-05-19 19:32:28,941:INFO:Uploading model into container now
2025-05-19 19:32:28,941:INFO:_master_model_container: 33
2025-05-19 19:32:28,941:INFO:_display_container: 9
2025-05-19 19:32:28,943:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 19:32:28,943:INFO:create_model() successfully completed......................................
2025-05-19 19:32:29,052:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:29,052:INFO:Creating metrics dataframe
2025-05-19 19:32:29,060:INFO:Initializing Gradient Boosting Classifier
2025-05-19 19:32:29,060:INFO:Total runtime is 0.12113370100657146 minutes
2025-05-19 19:32:29,067:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:29,067:INFO:Initializing create_model()
2025-05-19 19:32:29,067:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:29,067:INFO:Checking exceptions
2025-05-19 19:32:29,067:INFO:Importing libraries
2025-05-19 19:32:29,067:INFO:Copying training dataset
2025-05-19 19:32:29,072:INFO:Defining folds
2025-05-19 19:32:29,072:INFO:Declaring metric variables
2025-05-19 19:32:29,076:INFO:Importing untrained model
2025-05-19 19:32:29,081:INFO:Gradient Boosting Classifier Imported successfully
2025-05-19 19:32:29,088:INFO:Starting cross validation
2025-05-19 19:32:29,095:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:29,685:INFO:Calculating mean and std
2025-05-19 19:32:29,687:INFO:Creating metrics dataframe
2025-05-19 19:32:29,688:INFO:Uploading results into container
2025-05-19 19:32:29,689:INFO:Uploading model into container now
2025-05-19 19:32:29,690:INFO:_master_model_container: 34
2025-05-19 19:32:29,690:INFO:_display_container: 9
2025-05-19 19:32:29,690:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2025, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-19 19:32:29,690:INFO:create_model() successfully completed......................................
2025-05-19 19:32:29,804:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:29,804:INFO:Creating metrics dataframe
2025-05-19 19:32:29,814:INFO:Initializing Linear Discriminant Analysis
2025-05-19 19:32:29,814:INFO:Total runtime is 0.13369044462839763 minutes
2025-05-19 19:32:29,818:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:29,819:INFO:Initializing create_model()
2025-05-19 19:32:29,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:29,819:INFO:Checking exceptions
2025-05-19 19:32:29,819:INFO:Importing libraries
2025-05-19 19:32:29,819:INFO:Copying training dataset
2025-05-19 19:32:29,825:INFO:Defining folds
2025-05-19 19:32:29,825:INFO:Declaring metric variables
2025-05-19 19:32:29,830:INFO:Importing untrained model
2025-05-19 19:32:29,834:INFO:Linear Discriminant Analysis Imported successfully
2025-05-19 19:32:29,840:INFO:Starting cross validation
2025-05-19 19:32:29,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:30,142:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:30,150:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:30,151:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:30,153:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:30,206:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:30,216:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:30,221:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:30,236:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:30,270:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:30,279:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:30,293:INFO:Calculating mean and std
2025-05-19 19:32:30,295:INFO:Creating metrics dataframe
2025-05-19 19:32:30,299:INFO:Uploading results into container
2025-05-19 19:32:30,300:INFO:Uploading model into container now
2025-05-19 19:32:30,301:INFO:_master_model_container: 35
2025-05-19 19:32:30,301:INFO:_display_container: 9
2025-05-19 19:32:30,301:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-19 19:32:30,301:INFO:create_model() successfully completed......................................
2025-05-19 19:32:30,421:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:30,421:INFO:Creating metrics dataframe
2025-05-19 19:32:30,430:INFO:Initializing Extra Trees Classifier
2025-05-19 19:32:30,431:INFO:Total runtime is 0.14398277203241985 minutes
2025-05-19 19:32:30,435:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:30,436:INFO:Initializing create_model()
2025-05-19 19:32:30,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:30,436:INFO:Checking exceptions
2025-05-19 19:32:30,436:INFO:Importing libraries
2025-05-19 19:32:30,436:INFO:Copying training dataset
2025-05-19 19:32:30,439:INFO:Defining folds
2025-05-19 19:32:30,439:INFO:Declaring metric variables
2025-05-19 19:32:30,442:INFO:Importing untrained model
2025-05-19 19:32:30,446:INFO:Extra Trees Classifier Imported successfully
2025-05-19 19:32:30,456:INFO:Starting cross validation
2025-05-19 19:32:30,465:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:31,253:INFO:Calculating mean and std
2025-05-19 19:32:31,254:INFO:Creating metrics dataframe
2025-05-19 19:32:31,256:INFO:Uploading results into container
2025-05-19 19:32:31,257:INFO:Uploading model into container now
2025-05-19 19:32:31,257:INFO:_master_model_container: 36
2025-05-19 19:32:31,257:INFO:_display_container: 9
2025-05-19 19:32:31,258:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2025, verbose=0,
                     warm_start=False)
2025-05-19 19:32:31,258:INFO:create_model() successfully completed......................................
2025-05-19 19:32:31,372:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:31,372:INFO:Creating metrics dataframe
2025-05-19 19:32:31,382:INFO:Initializing Light Gradient Boosting Machine
2025-05-19 19:32:31,382:INFO:Total runtime is 0.15981797774632772 minutes
2025-05-19 19:32:31,385:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:31,385:INFO:Initializing create_model()
2025-05-19 19:32:31,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:31,386:INFO:Checking exceptions
2025-05-19 19:32:31,386:INFO:Importing libraries
2025-05-19 19:32:31,386:INFO:Copying training dataset
2025-05-19 19:32:31,391:INFO:Defining folds
2025-05-19 19:32:31,391:INFO:Declaring metric variables
2025-05-19 19:32:31,395:INFO:Importing untrained model
2025-05-19 19:32:31,400:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-19 19:32:31,407:INFO:Starting cross validation
2025-05-19 19:32:31,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:31,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:31,873:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:31,897:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:31,961:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:31,991:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,070:INFO:Calculating mean and std
2025-05-19 19:32:32,071:INFO:Creating metrics dataframe
2025-05-19 19:32:32,075:INFO:Uploading results into container
2025-05-19 19:32:32,076:INFO:Uploading model into container now
2025-05-19 19:32:32,077:INFO:_master_model_container: 37
2025-05-19 19:32:32,077:INFO:_display_container: 9
2025-05-19 19:32:32,078:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2025, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-19 19:32:32,078:INFO:create_model() successfully completed......................................
2025-05-19 19:32:32,206:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:32,206:INFO:Creating metrics dataframe
2025-05-19 19:32:32,218:INFO:Initializing Dummy Classifier
2025-05-19 19:32:32,218:INFO:Total runtime is 0.17375229199727377 minutes
2025-05-19 19:32:32,221:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:32,222:INFO:Initializing create_model()
2025-05-19 19:32:32,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017086B404D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:32,222:INFO:Checking exceptions
2025-05-19 19:32:32,222:INFO:Importing libraries
2025-05-19 19:32:32,222:INFO:Copying training dataset
2025-05-19 19:32:32,224:INFO:Defining folds
2025-05-19 19:32:32,225:INFO:Declaring metric variables
2025-05-19 19:32:32,228:INFO:Importing untrained model
2025-05-19 19:32:32,231:INFO:Dummy Classifier Imported successfully
2025-05-19 19:32:32,239:INFO:Starting cross validation
2025-05-19 19:32:32,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:32,530:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,535:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,555:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,561:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,596:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,614:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,618:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,627:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,659:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,679:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:32,686:INFO:Calculating mean and std
2025-05-19 19:32:32,688:INFO:Creating metrics dataframe
2025-05-19 19:32:32,690:INFO:Uploading results into container
2025-05-19 19:32:32,691:INFO:Uploading model into container now
2025-05-19 19:32:32,691:INFO:_master_model_container: 38
2025-05-19 19:32:32,691:INFO:_display_container: 9
2025-05-19 19:32:32,693:INFO:DummyClassifier(constant=None, random_state=2025, strategy='prior')
2025-05-19 19:32:32,693:INFO:create_model() successfully completed......................................
2025-05-19 19:32:32,804:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:32,804:INFO:Creating metrics dataframe
2025-05-19 19:32:32,815:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-19 19:32:32,824:INFO:Initializing create_model()
2025-05-19 19:32:32,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:32,824:INFO:Checking exceptions
2025-05-19 19:32:32,826:INFO:Importing libraries
2025-05-19 19:32:32,826:INFO:Copying training dataset
2025-05-19 19:32:32,827:INFO:Defining folds
2025-05-19 19:32:32,828:INFO:Declaring metric variables
2025-05-19 19:32:32,828:INFO:Importing untrained model
2025-05-19 19:32:32,828:INFO:Declaring custom model
2025-05-19 19:32:32,828:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:32:32,835:INFO:Cross validation set to False
2025-05-19 19:32:32,835:INFO:Fitting Model
2025-05-19 19:32:32,929:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:32:32,930:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000086 seconds.
2025-05-19 19:32:32,930:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:32:32,930:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:32:32,930:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:32:32,931:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:32:32,931:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:32:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:32,951:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:32:32,951:INFO:create_model() successfully completed......................................
2025-05-19 19:32:33,100:INFO:_master_model_container: 38
2025-05-19 19:32:33,100:INFO:_display_container: 9
2025-05-19 19:32:33,100:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:32:33,100:INFO:compare_models() successfully completed......................................
2025-05-19 19:32:36,041:INFO:Initializing create_model()
2025-05-19 19:32:36,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:36,041:INFO:Checking exceptions
2025-05-19 19:32:36,057:INFO:Importing libraries
2025-05-19 19:32:36,058:INFO:Copying training dataset
2025-05-19 19:32:36,061:INFO:Defining folds
2025-05-19 19:32:36,061:INFO:Declaring metric variables
2025-05-19 19:32:36,064:INFO:Importing untrained model
2025-05-19 19:32:36,068:INFO:Ada Boost Classifier Imported successfully
2025-05-19 19:32:36,074:INFO:Starting cross validation
2025-05-19 19:32:36,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:36,360:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:36,362:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:36,367:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:36,388:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:36,550:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:36,560:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:36,571:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:36,705:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:36,716:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:36,734:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:36,858:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:36,873:INFO:Calculating mean and std
2025-05-19 19:32:36,873:INFO:Creating metrics dataframe
2025-05-19 19:32:36,878:INFO:Finalizing model
2025-05-19 19:32:36,949:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:32:36,950:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.
2025-05-19 19:32:36,950:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:32:36,950:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:32:36,950:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:32:36,950:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:32:36,951:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:36,974:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:32:37,041:INFO:Uploading results into container
2025-05-19 19:32:37,042:INFO:Uploading model into container now
2025-05-19 19:32:37,054:INFO:_master_model_container: 39
2025-05-19 19:32:37,054:INFO:_display_container: 10
2025-05-19 19:32:37,054:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 19:32:37,056:INFO:create_model() successfully completed......................................
2025-05-19 19:32:40,049:INFO:Initializing tune_model()
2025-05-19 19:32:40,049:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 19:32:40,049:INFO:Checking exceptions
2025-05-19 19:32:40,066:INFO:Copying training dataset
2025-05-19 19:32:40,069:INFO:Checking base model
2025-05-19 19:32:40,069:INFO:Base model : Decision Tree Classifier
2025-05-19 19:32:40,073:INFO:Declaring metric variables
2025-05-19 19:32:40,076:INFO:Defining Hyperparameters
2025-05-19 19:32:40,201:INFO:Tuning with n_jobs=-1
2025-05-19 19:32:40,201:INFO:Initializing RandomizedSearchCV
2025-05-19 19:32:40,675:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:40,703:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:40,792:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:40,894:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:40,911:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:40,974:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:41,349:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:41,356:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:41,369:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:41,372:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:41,547:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:41,570:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:41,598:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:41,679:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:41,860:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:42,445:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:42,681:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:42,855:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:42,887:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,068:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,161:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,177:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,283:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,294:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,363:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,505:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,519:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,557:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,559:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,703:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,748:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,824:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,911:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:43,925:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:44,020:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:44,093:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:44,101:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:44,230:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:44,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:44,769:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:44,837:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:44,926:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,015:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,035:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,204:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,216:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,318:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,384:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,471:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,573:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,576:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,591:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,643:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,668:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,717:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,718:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,753:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,753:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,802:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,835:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,853:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,854:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,863:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:45,874:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 11, 'actual_estimator__criterion': 'gini'}
2025-05-19 19:32:45,875:INFO:Hyperparameter search completed
2025-05-19 19:32:45,875:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:45,876:INFO:Initializing create_model()
2025-05-19 19:32:45,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000170840A6110>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.002, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'gini'})
2025-05-19 19:32:45,877:INFO:Checking exceptions
2025-05-19 19:32:45,877:INFO:Importing libraries
2025-05-19 19:32:45,877:INFO:Copying training dataset
2025-05-19 19:32:45,884:INFO:Defining folds
2025-05-19 19:32:45,884:INFO:Declaring metric variables
2025-05-19 19:32:45,887:INFO:Importing untrained model
2025-05-19 19:32:45,887:INFO:Declaring custom model
2025-05-19 19:32:45,891:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:32:45,899:INFO:Starting cross validation
2025-05-19 19:32:45,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:46,210:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:32:46,380:INFO:Calculating mean and std
2025-05-19 19:32:46,381:INFO:Creating metrics dataframe
2025-05-19 19:32:46,389:INFO:Finalizing model
2025-05-19 19:32:46,473:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:32:46,474:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000072 seconds.
2025-05-19 19:32:46,474:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:32:46,474:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:32:46,474:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:32:46,474:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:32:46,474:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:32:46,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:46,506:INFO:Uploading results into container
2025-05-19 19:32:46,507:INFO:Uploading model into container now
2025-05-19 19:32:46,508:INFO:_master_model_container: 40
2025-05-19 19:32:46,508:INFO:_display_container: 11
2025-05-19 19:32:46,509:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:32:46,509:INFO:create_model() successfully completed......................................
2025-05-19 19:32:46,634:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:46,634:INFO:choose_better activated
2025-05-19 19:32:46,637:INFO:SubProcess create_model() called ==================================
2025-05-19 19:32:46,638:INFO:Initializing create_model()
2025-05-19 19:32:46,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:32:46,638:INFO:Checking exceptions
2025-05-19 19:32:46,639:INFO:Importing libraries
2025-05-19 19:32:46,639:INFO:Copying training dataset
2025-05-19 19:32:46,641:INFO:Defining folds
2025-05-19 19:32:46,641:INFO:Declaring metric variables
2025-05-19 19:32:46,641:INFO:Importing untrained model
2025-05-19 19:32:46,641:INFO:Declaring custom model
2025-05-19 19:32:46,643:INFO:Decision Tree Classifier Imported successfully
2025-05-19 19:32:46,643:INFO:Starting cross validation
2025-05-19 19:32:46,648:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:32:47,091:INFO:Calculating mean and std
2025-05-19 19:32:47,091:INFO:Creating metrics dataframe
2025-05-19 19:32:47,092:INFO:Finalizing model
2025-05-19 19:32:47,172:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:32:47,172:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000063 seconds.
2025-05-19 19:32:47,172:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:32:47,173:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:32:47,173:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:32:47,173:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:32:47,173:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:32:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:32:47,197:INFO:Uploading results into container
2025-05-19 19:32:47,198:INFO:Uploading model into container now
2025-05-19 19:32:47,198:INFO:_master_model_container: 41
2025-05-19 19:32:47,198:INFO:_display_container: 12
2025-05-19 19:32:47,199:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:32:47,199:INFO:create_model() successfully completed......................................
2025-05-19 19:32:47,320:INFO:SubProcess create_model() end ==================================
2025-05-19 19:32:47,320:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for Prec. is 0.325
2025-05-19 19:32:47,321:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') result for Prec. is 0.4333
2025-05-19 19:32:47,321:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best') is best model
2025-05-19 19:32:47,321:INFO:choose_better completed
2025-05-19 19:32:47,330:INFO:_master_model_container: 41
2025-05-19 19:32:47,331:INFO:_display_container: 11
2025-05-19 19:32:47,331:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best')
2025-05-19 19:32:47,331:INFO:tune_model() successfully completed......................................
2025-05-19 19:32:47,443:INFO:Initializing plot_model()
2025-05-19 19:32:47,443:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:32:47,443:INFO:Checking exceptions
2025-05-19 19:32:47,447:INFO:Preloading libraries
2025-05-19 19:32:47,447:INFO:Copying training dataset
2025-05-19 19:32:47,447:INFO:Plot type: pr
2025-05-19 19:32:47,794:INFO:Fitting Model
2025-05-19 19:32:47,794:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:32:47,795:INFO:Scoring test/hold-out set
2025-05-19 19:32:47,933:INFO:Visual Rendered Successfully
2025-05-19 19:32:48,056:INFO:plot_model() successfully completed......................................
2025-05-19 19:32:48,057:INFO:Initializing plot_model()
2025-05-19 19:32:48,057:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:32:48,057:INFO:Checking exceptions
2025-05-19 19:32:48,061:INFO:Preloading libraries
2025-05-19 19:32:48,061:INFO:Copying training dataset
2025-05-19 19:32:48,061:INFO:Plot type: confusion_matrix
2025-05-19 19:32:48,411:INFO:Fitting Model
2025-05-19 19:32:48,411:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:32:48,411:INFO:Scoring test/hold-out set
2025-05-19 19:32:48,509:INFO:Visual Rendered Successfully
2025-05-19 19:32:48,616:INFO:plot_model() successfully completed......................................
2025-05-19 19:33:05,200:INFO:Initializing interpret_model()
2025-05-19 19:33:05,200:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-19 19:33:05,200:INFO:Checking exceptions
2025-05-19 19:33:05,200:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-19 19:35:22,885:INFO:Initializing predict_model()
2025-05-19 19:35:22,885:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=11, max_features='sqrt', max_leaf_nodes=None,
                       min_impurity_decrease=0.002, min_samples_leaf=5,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2025, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017084A44040>)
2025-05-19 19:35:22,885:INFO:Checking exceptions
2025-05-19 19:35:22,885:INFO:Preloading libraries
2025-05-19 19:35:22,890:INFO:Set up data.
2025-05-19 19:35:22,895:INFO:Set up index.
2025-05-19 19:39:13,464:INFO:Initializing tune_model()
2025-05-19 19:39:13,464:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Prec., custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 19:39:13,464:INFO:Checking exceptions
2025-05-19 19:39:13,484:INFO:Copying training dataset
2025-05-19 19:39:13,488:INFO:Checking base model
2025-05-19 19:39:13,489:INFO:Base model : Ada Boost Classifier
2025-05-19 19:39:13,492:INFO:Declaring metric variables
2025-05-19 19:39:13,498:INFO:Defining Hyperparameters
2025-05-19 19:39:13,703:INFO:Tuning with n_jobs=-1
2025-05-19 19:39:13,703:INFO:Initializing RandomizedSearchCV
2025-05-19 19:39:24,116:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:24,120:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:24,126:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:24,133:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:24,171:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:24,533:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:24,769:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:24,937:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:25,077:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:25,188:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:25,229:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:25,459:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:26,014:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:26,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:26,651:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:26,656:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:26,718:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:26,996:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:27,107:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:27,165:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:27,397:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:27,433:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:27,501:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:27,676:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:27,919:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:27,926:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:27,945:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:28,184:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:28,438:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:28,525:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:28,621:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:28,670:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:28,998:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:29,014:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:29,120:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:29,172:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:29,315:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:29,431:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:29,501:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:29,911:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:29,913:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,001:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,186:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,228:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,270:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,343:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,487:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,510:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,588:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,765:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,789:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,854:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:30,932:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:31,004:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:31,181:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:31,246:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:31,326:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:31,464:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:31,586:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:31,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:31,802:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:31,858:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:31,960:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,015:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,115:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,182:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,229:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,301:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,391:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,480:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,552:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,557:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,656:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:32,712:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:33,005:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:33,063:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:33,106:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:33,224:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:33,439:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:33,606:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:33,685:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:33,740:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:33,881:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:34,087:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:34,331:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:34,350:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:34,898:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:34,938:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:35,021:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:35,080:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:35,102:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:35,106:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__algorithm': 'SAMME'}
2025-05-19 19:39:35,108:INFO:Hyperparameter search completed
2025-05-19 19:39:35,108:INFO:SubProcess create_model() called ==================================
2025-05-19 19:39:35,108:INFO:Initializing create_model()
2025-05-19 19:39:35,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017087DBA090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'learning_rate': 0.2, 'algorithm': 'SAMME'})
2025-05-19 19:39:35,109:INFO:Checking exceptions
2025-05-19 19:39:35,109:INFO:Importing libraries
2025-05-19 19:39:35,109:INFO:Copying training dataset
2025-05-19 19:39:35,116:INFO:Defining folds
2025-05-19 19:39:35,116:INFO:Declaring metric variables
2025-05-19 19:39:35,120:INFO:Importing untrained model
2025-05-19 19:39:35,120:INFO:Declaring custom model
2025-05-19 19:39:35,124:INFO:Ada Boost Classifier Imported successfully
2025-05-19 19:39:35,132:INFO:Starting cross validation
2025-05-19 19:39:35,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:39:36,306:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:36,355:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:37,049:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:37,052:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:37,247:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:37,326:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:37,388:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:37,402:INFO:Calculating mean and std
2025-05-19 19:39:37,404:INFO:Creating metrics dataframe
2025-05-19 19:39:37,410:INFO:Finalizing model
2025-05-19 19:39:37,496:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:39:37,496:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.
2025-05-19 19:39:37,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-05-19 19:39:37,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-05-19 19:39:37,497:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:39:37,497:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:39:37,497:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:39:37,497:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:39:37,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:37,828:INFO:Uploading results into container
2025-05-19 19:39:37,829:INFO:Uploading model into container now
2025-05-19 19:39:37,830:INFO:_master_model_container: 42
2025-05-19 19:39:37,830:INFO:_display_container: 12
2025-05-19 19:39:37,831:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025)
2025-05-19 19:39:37,831:INFO:create_model() successfully completed......................................
2025-05-19 19:39:38,007:INFO:SubProcess create_model() end ==================================
2025-05-19 19:39:38,007:INFO:choose_better activated
2025-05-19 19:39:38,016:INFO:SubProcess create_model() called ==================================
2025-05-19 19:39:38,017:INFO:Initializing create_model()
2025-05-19 19:39:38,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 19:39:38,017:INFO:Checking exceptions
2025-05-19 19:39:38,021:INFO:Importing libraries
2025-05-19 19:39:38,021:INFO:Copying training dataset
2025-05-19 19:39:38,025:INFO:Defining folds
2025-05-19 19:39:38,025:INFO:Declaring metric variables
2025-05-19 19:39:38,025:INFO:Importing untrained model
2025-05-19 19:39:38,026:INFO:Declaring custom model
2025-05-19 19:39:38,026:INFO:Ada Boost Classifier Imported successfully
2025-05-19 19:39:38,026:INFO:Starting cross validation
2025-05-19 19:39:38,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 19:39:38,302:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,303:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,305:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,316:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,467:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,477:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,482:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,493:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,601:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,603:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,727:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 19:39:38,736:INFO:Calculating mean and std
2025-05-19 19:39:38,736:INFO:Creating metrics dataframe
2025-05-19 19:39:38,738:INFO:Finalizing model
2025-05-19 19:39:38,817:INFO:[LightGBM] [Info] Number of positive: 32, number of negative: 122
2025-05-19 19:39:38,818:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000072 seconds.
2025-05-19 19:39:38,818:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-05-19 19:39:38,818:INFO:[LightGBM] [Info] Total Bins 186
2025-05-19 19:39:38,818:INFO:[LightGBM] [Info] Number of data points in the train set: 154, number of used features: 14
2025-05-19 19:39:38,818:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.207792 -> initscore=-1.338285
2025-05-19 19:39:38,818:INFO:[LightGBM] [Info] Start training from score -1.338285
2025-05-19 19:39:38,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-05-19 19:39:38,847:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 19:39:38,910:INFO:Uploading results into container
2025-05-19 19:39:38,911:INFO:Uploading model into container now
2025-05-19 19:39:38,911:INFO:_master_model_container: 43
2025-05-19 19:39:38,911:INFO:_display_container: 13
2025-05-19 19:39:38,911:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 19:39:38,911:INFO:create_model() successfully completed......................................
2025-05-19 19:39:39,081:INFO:SubProcess create_model() end ==================================
2025-05-19 19:39:39,081:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) result for Prec. is 0.4167
2025-05-19 19:39:39,081:INFO:AdaBoostClassifier(algorithm='SAMME', estimator=None, learning_rate=0.2,
                   n_estimators=240, random_state=2025) result for Prec. is 0.3
2025-05-19 19:39:39,081:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025) is best model
2025-05-19 19:39:39,081:INFO:choose_better completed
2025-05-19 19:39:39,083:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 19:39:39,093:INFO:_master_model_container: 43
2025-05-19 19:39:39,094:INFO:_display_container: 12
2025-05-19 19:39:39,094:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025)
2025-05-19 19:39:39,094:INFO:tune_model() successfully completed......................................
2025-05-19 19:39:39,271:INFO:Initializing plot_model()
2025-05-19 19:39:39,271:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:39:39,271:INFO:Checking exceptions
2025-05-19 19:39:39,275:INFO:Preloading libraries
2025-05-19 19:39:39,285:INFO:Copying training dataset
2025-05-19 19:39:39,285:INFO:Plot type: pr
2025-05-19 19:39:39,684:INFO:Fitting Model
2025-05-19 19:39:39,684:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:39:39,684:INFO:Scoring test/hold-out set
2025-05-19 19:39:39,849:INFO:Visual Rendered Successfully
2025-05-19 19:39:40,024:INFO:plot_model() successfully completed......................................
2025-05-19 19:39:40,024:INFO:Initializing plot_model()
2025-05-19 19:39:40,024:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 19:39:40,024:INFO:Checking exceptions
2025-05-19 19:39:40,029:INFO:Preloading libraries
2025-05-19 19:39:40,034:INFO:Copying training dataset
2025-05-19 19:39:40,034:INFO:Plot type: confusion_matrix
2025-05-19 19:39:40,380:INFO:Fitting Model
2025-05-19 19:39:40,380:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2025-05-19 19:39:40,380:INFO:Scoring test/hold-out set
2025-05-19 19:39:40,480:INFO:Visual Rendered Successfully
2025-05-19 19:39:40,651:INFO:plot_model() successfully completed......................................
2025-05-19 19:39:53,698:INFO:Initializing interpret_model()
2025-05-19 19:39:53,698:INFO:interpret_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), plot=summary, feature=None, observation=None, use_train_data=False, X_new_sample=None, y_new_sample=None, save=False, kwargs={})
2025-05-19 19:39:53,698:INFO:Checking exceptions
2025-05-19 19:39:53,698:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-05-19 19:39:57,953:INFO:Initializing predict_model()
2025-05-19 19:39:57,953:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000170536A1940>)
2025-05-19 19:39:57,953:INFO:Checking exceptions
2025-05-19 19:39:57,953:INFO:Preloading libraries
2025-05-19 19:39:57,958:INFO:Set up data.
2025-05-19 19:39:57,967:INFO:Set up index.
2025-05-19 19:40:58,682:INFO:Initializing predict_model()
2025-05-19 19:40:58,682:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017084A0E750>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017084AA2660>)
2025-05-19 19:40:58,682:INFO:Checking exceptions
2025-05-19 19:40:58,682:INFO:Preloading libraries
2025-05-19 19:40:58,686:INFO:Set up data.
2025-05-19 19:40:58,690:INFO:Set up index.
2025-05-19 19:41:21,795:INFO:Initializing save_model()
2025-05-19 19:41:21,795:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2025), model_name=modelo_marketing_conversion_predictor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Trans...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-19 19:41:21,795:INFO:Adding model into prep_pipe
2025-05-19 19:41:21,832:INFO:modelo_marketing_conversion_predictor.pkl saved in current working directory
2025-05-19 19:41:21,847:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['likes', 'comentarios',
                                             'engagement'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['plataf...
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=1,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=2025))],
         verbose=False)
2025-05-19 19:41:21,847:INFO:save_model() successfully completed......................................
2025-05-19 20:31:45,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 20:31:45,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 20:31:45,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 20:31:45,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-19 20:40:52,699:WARNING:C:\Users\amonreal\AppData\Local\Temp\ipykernel_28716\1421193740.py:15: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=fuga_counts.index, y=fuga_counts.values, palette="pastel")

2025-05-19 21:01:40,383:INFO:PyCaret ClassificationExperiment
2025-05-19 21:01:40,383:INFO:Logging name: clf-default-name
2025-05-19 21:01:40,383:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-19 21:01:40,383:INFO:version 3.3.2
2025-05-19 21:01:40,383:INFO:Initializing setup()
2025-05-19 21:01:40,383:INFO:self.USI: fc27
2025-05-19 21:01:40,384:INFO:self._variable_keys: {'seed', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'pipeline', 'exp_name_log', 'log_plots_param', 'fold_shuffle_param', 'X', 'X_test', 'y', 'target_param', 'exp_id', 'n_jobs_param', '_available_plots', 'y_test', 'fold_generator', 'USI', 'fix_imbalance', 'gpu_param', 'y_train', 'idx', 'logging_param', 'is_multiclass', 'html_param', '_ml_usecase', 'X_train', 'memory'}
2025-05-19 21:01:40,384:INFO:Checking environment
2025-05-19 21:01:40,384:INFO:python_version: 3.11.9
2025-05-19 21:01:40,384:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-05-19 21:01:40,384:INFO:machine: AMD64
2025-05-19 21:01:40,384:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-19 21:01:40,399:INFO:Memory: svmem(total=33554628608, available=15940325376, percent=52.5, used=17614303232, free=15940325376)
2025-05-19 21:01:40,399:INFO:Physical Core: 6
2025-05-19 21:01:40,399:INFO:Logical Core: 12
2025-05-19 21:01:40,399:INFO:Checking libraries
2025-05-19 21:01:40,399:INFO:System:
2025-05-19 21:01:40,399:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-05-19 21:01:40,399:INFO:executable: C:\Users\amonreal\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-05-19 21:01:40,399:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-19 21:01:40,399:INFO:PyCaret required dependencies:
2025-05-19 21:01:40,454:INFO:                 pip: 24.0
2025-05-19 21:01:40,454:INFO:          setuptools: 65.5.0
2025-05-19 21:01:40,454:INFO:             pycaret: 3.3.2
2025-05-19 21:01:40,454:INFO:             IPython: 9.2.0
2025-05-19 21:01:40,454:INFO:          ipywidgets: 8.1.7
2025-05-19 21:01:40,454:INFO:                tqdm: 4.67.1
2025-05-19 21:01:40,454:INFO:               numpy: 1.26.4
2025-05-19 21:01:40,454:INFO:              pandas: 2.1.4
2025-05-19 21:01:40,454:INFO:              jinja2: 3.1.6
2025-05-19 21:01:40,454:INFO:               scipy: 1.11.4
2025-05-19 21:01:40,454:INFO:              joblib: 1.3.2
2025-05-19 21:01:40,454:INFO:             sklearn: 1.4.2
2025-05-19 21:01:40,454:INFO:                pyod: 2.0.5
2025-05-19 21:01:40,454:INFO:            imblearn: 0.13.0
2025-05-19 21:01:40,454:INFO:   category_encoders: 2.7.0
2025-05-19 21:01:40,454:INFO:            lightgbm: 4.6.0
2025-05-19 21:01:40,454:INFO:               numba: 0.61.2
2025-05-19 21:01:40,454:INFO:            requests: 2.32.3
2025-05-19 21:01:40,454:INFO:          matplotlib: 3.7.5
2025-05-19 21:01:40,454:INFO:          scikitplot: 0.3.7
2025-05-19 21:01:40,456:INFO:         yellowbrick: 1.5
2025-05-19 21:01:40,456:INFO:              plotly: 5.24.1
2025-05-19 21:01:40,456:INFO:    plotly-resampler: Not installed
2025-05-19 21:01:40,456:INFO:             kaleido: 0.2.1
2025-05-19 21:01:40,456:INFO:           schemdraw: 0.15
2025-05-19 21:01:40,456:INFO:         statsmodels: 0.14.4
2025-05-19 21:01:40,456:INFO:              sktime: 0.26.0
2025-05-19 21:01:40,456:INFO:               tbats: 1.1.3
2025-05-19 21:01:40,456:INFO:            pmdarima: 2.0.4
2025-05-19 21:01:40,456:INFO:              psutil: 7.0.0
2025-05-19 21:01:40,456:INFO:          markupsafe: 3.0.2
2025-05-19 21:01:40,456:INFO:             pickle5: Not installed
2025-05-19 21:01:40,456:INFO:         cloudpickle: 3.1.1
2025-05-19 21:01:40,456:INFO:         deprecation: 2.1.0
2025-05-19 21:01:40,456:INFO:              xxhash: 3.5.0
2025-05-19 21:01:40,456:INFO:           wurlitzer: Not installed
2025-05-19 21:01:40,456:INFO:PyCaret optional dependencies:
2025-05-19 21:01:40,476:INFO:                shap: Not installed
2025-05-19 21:01:40,476:INFO:           interpret: Not installed
2025-05-19 21:01:40,477:INFO:                umap: Not installed
2025-05-19 21:01:40,477:INFO:     ydata_profiling: Not installed
2025-05-19 21:01:40,477:INFO:  explainerdashboard: Not installed
2025-05-19 21:01:40,477:INFO:             autoviz: Not installed
2025-05-19 21:01:40,477:INFO:           fairlearn: Not installed
2025-05-19 21:01:40,477:INFO:          deepchecks: Not installed
2025-05-19 21:01:40,477:INFO:             xgboost: Not installed
2025-05-19 21:01:40,477:INFO:            catboost: Not installed
2025-05-19 21:01:40,477:INFO:              kmodes: Not installed
2025-05-19 21:01:40,477:INFO:             mlxtend: Not installed
2025-05-19 21:01:40,477:INFO:       statsforecast: Not installed
2025-05-19 21:01:40,477:INFO:        tune_sklearn: Not installed
2025-05-19 21:01:40,477:INFO:                 ray: Not installed
2025-05-19 21:01:40,477:INFO:            hyperopt: Not installed
2025-05-19 21:01:40,477:INFO:              optuna: Not installed
2025-05-19 21:01:40,477:INFO:               skopt: Not installed
2025-05-19 21:01:40,477:INFO:              mlflow: Not installed
2025-05-19 21:01:40,477:INFO:              gradio: Not installed
2025-05-19 21:01:40,477:INFO:             fastapi: Not installed
2025-05-19 21:01:40,477:INFO:             uvicorn: Not installed
2025-05-19 21:01:40,477:INFO:              m2cgen: Not installed
2025-05-19 21:01:40,477:INFO:           evidently: Not installed
2025-05-19 21:01:40,477:INFO:               fugue: Not installed
2025-05-19 21:01:40,477:INFO:           streamlit: Not installed
2025-05-19 21:01:40,477:INFO:             prophet: Not installed
2025-05-19 21:01:40,477:INFO:None
2025-05-19 21:01:40,477:INFO:Set up data.
2025-05-19 21:01:40,488:INFO:Set up folding strategy.
2025-05-19 21:01:40,488:INFO:Set up train/test split.
2025-05-19 21:01:40,498:INFO:Set up index.
2025-05-19 21:01:40,498:INFO:Assigning column types.
2025-05-19 21:01:40,502:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-19 21:01:40,539:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 21:01:40,548:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 21:01:40,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,637:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-19 21:01:40,637:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 21:01:40,662:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,663:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-19 21:01:40,700:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 21:01:40,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-19 21:01:40,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,793:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-19 21:01:40,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:40,933:INFO:Preparing preprocessing pipeline...
2025-05-19 21:01:40,936:INFO:Set up simple imputation.
2025-05-19 21:01:40,941:INFO:Set up encoding of categorical features.
2025-05-19 21:01:40,941:INFO:Set up removing multicollinearity.
2025-05-19 21:01:40,941:INFO:Set up binning of numerical features.
2025-05-19 21:01:40,943:INFO:Set up imbalanced handling.
2025-05-19 21:01:40,943:INFO:Set up column transformation.
2025-05-19 21:01:41,063:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:01:41,358:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:01:41,358:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:01:41,360:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:01:41,360:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:01:41,520:INFO:Finished creating preprocessing pipeline.
2025-05-19 21:01:41,527:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                                 strategy='kmeans',
                                                                 subsample='warn'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=777,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-19 21:01:41,527:INFO:Creating final display dataframe.
2025-05-19 21:01:41,836:INFO:Setup _display_container:                     Description             Value
0                    Session id               777
1                        Target    cerrara_cuenta
2                   Target type            Binary
3           Original data shape        (5000, 13)
4        Transformed data shape        (7518, 20)
5   Transformed train set shape        (6018, 20)
6    Transformed test set shape        (1500, 20)
7              Numeric features                 9
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19               Transformation              True
20        Transformation method       yeo-johnson
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              fc27
2025-05-19 21:01:41,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:41,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:41,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:41,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-19 21:01:41,978:INFO:setup() successfully completed in 1.61s...............
2025-05-19 21:06:38,552:INFO:Initializing compare_models()
2025-05-19 21:06:38,552:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Recall, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Recall', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-19 21:06:38,553:INFO:Checking exceptions
2025-05-19 21:06:38,560:INFO:Preparing display monitor
2025-05-19 21:06:38,597:INFO:Initializing Logistic Regression
2025-05-19 21:06:38,598:INFO:Total runtime is 1.770655314127604e-05 minutes
2025-05-19 21:06:38,602:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:38,603:INFO:Initializing create_model()
2025-05-19 21:06:38,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:38,604:INFO:Checking exceptions
2025-05-19 21:06:38,604:INFO:Importing libraries
2025-05-19 21:06:38,604:INFO:Copying training dataset
2025-05-19 21:06:38,610:INFO:Defining folds
2025-05-19 21:06:38,611:INFO:Declaring metric variables
2025-05-19 21:06:38,615:INFO:Importing untrained model
2025-05-19 21:06:38,621:INFO:Logistic Regression Imported successfully
2025-05-19 21:06:38,630:INFO:Starting cross validation
2025-05-19 21:06:38,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:44,358:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:44,362:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:44,394:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:44,398:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:44,433:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:44,485:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:44,520:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:44,531:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:44,535:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,535:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,538:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,539:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,539:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,539:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,541:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,541:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,550:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:44,557:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:44,573:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,573:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,575:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,576:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,578:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,578:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,580:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,580:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,612:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,612:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,614:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,614:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,649:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,649:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,652:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,652:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,682:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,682:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,686:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,687:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,695:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,695:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,697:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,716:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,717:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,719:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,719:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,721:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,723:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:44,725:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:44,726:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,211:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-19 21:06:45,211:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-19 21:06:45,235:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-19 21:06:45,268:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-19 21:06:45,299:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-19 21:06:45,315:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-19 21:06:45,369:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-19 21:06:45,388:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-19 21:06:45,394:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-19 21:06:45,395:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-19 21:06:45,451:INFO:Calculating mean and std
2025-05-19 21:06:45,453:INFO:Creating metrics dataframe
2025-05-19 21:06:45,456:INFO:Uploading results into container
2025-05-19 21:06:45,457:INFO:Uploading model into container now
2025-05-19 21:06:45,457:INFO:_master_model_container: 1
2025-05-19 21:06:45,457:INFO:_display_container: 2
2025-05-19 21:06:45,458:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=777, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-19 21:06:45,458:INFO:create_model() successfully completed......................................
2025-05-19 21:06:45,622:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:45,623:INFO:Creating metrics dataframe
2025-05-19 21:06:45,630:INFO:Initializing K Neighbors Classifier
2025-05-19 21:06:45,631:INFO:Total runtime is 0.11724373499552408 minutes
2025-05-19 21:06:45,634:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:45,635:INFO:Initializing create_model()
2025-05-19 21:06:45,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:45,635:INFO:Checking exceptions
2025-05-19 21:06:45,635:INFO:Importing libraries
2025-05-19 21:06:45,635:INFO:Copying training dataset
2025-05-19 21:06:45,641:INFO:Defining folds
2025-05-19 21:06:45,642:INFO:Declaring metric variables
2025-05-19 21:06:45,645:INFO:Importing untrained model
2025-05-19 21:06:45,649:INFO:K Neighbors Classifier Imported successfully
2025-05-19 21:06:45,663:INFO:Starting cross validation
2025-05-19 21:06:45,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:45,797:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:45,801:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,801:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,803:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,804:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,806:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:45,806:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:45,808:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:45,809:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,810:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,809:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,810:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,810:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,810:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,812:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,813:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,813:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,813:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,815:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,815:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,819:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:45,822:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,822:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,824:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,825:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,829:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:45,829:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:45,831:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,831:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,832:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,832:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,833:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,833:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,834:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,834:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,850:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:45,852:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,854:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:45,856:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:45,856:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:48,494:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:48,498:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:48,597:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:48,597:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:48,598:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:48,598:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:48,599:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:48,599:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:48,599:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:48,600:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:48,803:INFO:Calculating mean and std
2025-05-19 21:06:48,805:INFO:Creating metrics dataframe
2025-05-19 21:06:48,807:INFO:Uploading results into container
2025-05-19 21:06:48,808:INFO:Uploading model into container now
2025-05-19 21:06:48,808:INFO:_master_model_container: 2
2025-05-19 21:06:48,809:INFO:_display_container: 2
2025-05-19 21:06:48,809:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-19 21:06:48,809:INFO:create_model() successfully completed......................................
2025-05-19 21:06:48,959:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:48,959:INFO:Creating metrics dataframe
2025-05-19 21:06:48,966:INFO:Initializing Naive Bayes
2025-05-19 21:06:48,966:INFO:Total runtime is 0.17282572189966838 minutes
2025-05-19 21:06:48,969:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:48,969:INFO:Initializing create_model()
2025-05-19 21:06:48,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:48,969:INFO:Checking exceptions
2025-05-19 21:06:48,969:INFO:Importing libraries
2025-05-19 21:06:48,969:INFO:Copying training dataset
2025-05-19 21:06:48,975:INFO:Defining folds
2025-05-19 21:06:48,975:INFO:Declaring metric variables
2025-05-19 21:06:48,979:INFO:Importing untrained model
2025-05-19 21:06:48,982:INFO:Naive Bayes Imported successfully
2025-05-19 21:06:48,989:INFO:Starting cross validation
2025-05-19 21:06:48,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:49,093:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,096:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,096:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,098:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,098:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,098:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,099:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,100:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,100:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,101:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,101:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,101:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,101:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,103:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,104:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,104:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,106:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,106:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,106:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,106:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,107:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,107:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,108:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,108:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,108:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,108:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,108:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,109:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,109:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,109:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,110:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,110:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,110:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,111:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,111:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,111:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,111:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,111:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,113:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,113:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,113:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,115:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,117:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,118:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,118:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,328:INFO:Calculating mean and std
2025-05-19 21:06:49,329:INFO:Creating metrics dataframe
2025-05-19 21:06:49,330:INFO:Uploading results into container
2025-05-19 21:06:49,331:INFO:Uploading model into container now
2025-05-19 21:06:49,331:INFO:_master_model_container: 3
2025-05-19 21:06:49,332:INFO:_display_container: 2
2025-05-19 21:06:49,332:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-19 21:06:49,333:INFO:create_model() successfully completed......................................
2025-05-19 21:06:49,445:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:49,445:INFO:Creating metrics dataframe
2025-05-19 21:06:49,453:INFO:Initializing Decision Tree Classifier
2025-05-19 21:06:49,454:INFO:Total runtime is 0.18096075852711996 minutes
2025-05-19 21:06:49,458:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:49,458:INFO:Initializing create_model()
2025-05-19 21:06:49,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:49,458:INFO:Checking exceptions
2025-05-19 21:06:49,460:INFO:Importing libraries
2025-05-19 21:06:49,460:INFO:Copying training dataset
2025-05-19 21:06:49,465:INFO:Defining folds
2025-05-19 21:06:49,465:INFO:Declaring metric variables
2025-05-19 21:06:49,469:INFO:Importing untrained model
2025-05-19 21:06:49,474:INFO:Decision Tree Classifier Imported successfully
2025-05-19 21:06:49,480:INFO:Starting cross validation
2025-05-19 21:06:49,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:49,580:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,583:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

ubsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,583:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,585:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,585:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,585:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,586:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,586:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,587:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,587:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,587:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,587:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,587:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,589:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,589:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,589:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,591:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,591:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,592:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,592:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,592:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,593:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,593:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,593:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,593:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,593:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,594:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,594:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,596:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,599:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,600:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,600:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:49,601:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,601:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,601:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,601:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,604:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:49,605:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:49,852:INFO:Calculating mean and std
2025-05-19 21:06:49,853:INFO:Creating metrics dataframe
2025-05-19 21:06:49,855:INFO:Uploading results into container
2025-05-19 21:06:49,855:INFO:Uploading model into container now
2025-05-19 21:06:49,855:INFO:_master_model_container: 4
2025-05-19 21:06:49,857:INFO:_display_container: 2
2025-05-19 21:06:49,857:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=777, splitter='best')
2025-05-19 21:06:49,858:INFO:create_model() successfully completed......................................
2025-05-19 21:06:49,971:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:49,971:INFO:Creating metrics dataframe
2025-05-19 21:06:49,983:INFO:Initializing SVM - Linear Kernel
2025-05-19 21:06:49,984:INFO:Total runtime is 0.18979235092798868 minutes
2025-05-19 21:06:49,994:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:49,994:INFO:Initializing create_model()
2025-05-19 21:06:49,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:49,995:INFO:Checking exceptions
2025-05-19 21:06:49,995:INFO:Importing libraries
2025-05-19 21:06:49,995:INFO:Copying training dataset
2025-05-19 21:06:50,001:INFO:Defining folds
2025-05-19 21:06:50,001:INFO:Declaring metric variables
2025-05-19 21:06:50,006:INFO:Importing untrained model
2025-05-19 21:06:50,010:INFO:SVM - Linear Kernel Imported successfully
2025-05-19 21:06:50,017:INFO:Starting cross validation
2025-05-19 21:06:50,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:50,125:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,128:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,128:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,128:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,128:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,129:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,129:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,129:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,130:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,130:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,131:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,131:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,131:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,131:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,131:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,132:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,132:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,133:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,133:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,133:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,133:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,134:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,134:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,135:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,135:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,135:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,135:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,137:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,137:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,137:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,137:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,137:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,139:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,139:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,139:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,140:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,140:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,140:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,140:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,140:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,140:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,140:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,141:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,142:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,142:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,142:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,143:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,145:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,145:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,431:INFO:Calculating mean and std
2025-05-19 21:06:50,432:INFO:Creating metrics dataframe
2025-05-19 21:06:50,433:INFO:Uploading results into container
2025-05-19 21:06:50,434:INFO:Uploading model into container now
2025-05-19 21:06:50,434:INFO:_master_model_container: 5
2025-05-19 21:06:50,434:INFO:_display_container: 2
2025-05-19 21:06:50,435:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=777, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-19 21:06:50,435:INFO:create_model() successfully completed......................................
2025-05-19 21:06:50,549:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:50,549:INFO:Creating metrics dataframe
2025-05-19 21:06:50,559:INFO:Initializing Ridge Classifier
2025-05-19 21:06:50,559:INFO:Total runtime is 0.19936438004175822 minutes
2025-05-19 21:06:50,562:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:50,562:INFO:Initializing create_model()
2025-05-19 21:06:50,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:50,564:INFO:Checking exceptions
2025-05-19 21:06:50,564:INFO:Importing libraries
2025-05-19 21:06:50,564:INFO:Copying training dataset
2025-05-19 21:06:50,569:INFO:Defining folds
2025-05-19 21:06:50,569:INFO:Declaring metric variables
2025-05-19 21:06:50,573:INFO:Importing untrained model
2025-05-19 21:06:50,577:INFO:Ridge Classifier Imported successfully
2025-05-19 21:06:50,585:INFO:Starting cross validation
2025-05-19 21:06:50,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:50,680:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,682:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,683:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,685:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,686:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,688:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,690:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,690:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,690:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,692:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,692:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,693:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,693:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,693:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,694:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,694:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,695:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,695:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,695:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,695:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,696:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,696:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,696:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,696:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,696:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,699:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,699:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,699:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,699:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,700:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,700:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,700:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,700:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,700:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,700:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:50,700:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,702:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,702:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,702:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,703:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,707:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:50,707:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:50,926:INFO:Calculating mean and std
2025-05-19 21:06:50,928:INFO:Creating metrics dataframe
2025-05-19 21:06:50,929:INFO:Uploading results into container
2025-05-19 21:06:50,930:INFO:Uploading model into container now
2025-05-19 21:06:50,930:INFO:_master_model_container: 6
2025-05-19 21:06:50,930:INFO:_display_container: 2
2025-05-19 21:06:50,930:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=777, solver='auto',
                tol=0.0001)
2025-05-19 21:06:50,931:INFO:create_model() successfully completed......................................
2025-05-19 21:06:51,045:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:51,045:INFO:Creating metrics dataframe
2025-05-19 21:06:51,053:INFO:Initializing Random Forest Classifier
2025-05-19 21:06:51,053:INFO:Total runtime is 0.20760988394419352 minutes
2025-05-19 21:06:51,057:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:51,057:INFO:Initializing create_model()
2025-05-19 21:06:51,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:51,058:INFO:Checking exceptions
2025-05-19 21:06:51,058:INFO:Importing libraries
2025-05-19 21:06:51,058:INFO:Copying training dataset
2025-05-19 21:06:51,062:INFO:Defining folds
2025-05-19 21:06:51,063:INFO:Declaring metric variables
2025-05-19 21:06:51,068:INFO:Importing untrained model
2025-05-19 21:06:51,074:INFO:Random Forest Classifier Imported successfully
2025-05-19 21:06:51,080:INFO:Starting cross validation
2025-05-19 21:06:51,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:51,188:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:51,189:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:51,190:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,190:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,191:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:51,191:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,191:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,192:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,192:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,193:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,193:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,194:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:51,194:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,194:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:51,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:51,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,196:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,196:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,196:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:51,197:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,197:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,197:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,198:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,198:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,199:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

gs)

2025-05-19 21:06:51,199:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,199:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,199:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,200:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,200:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,200:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:51,200:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:51,201:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,201:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,202:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,203:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,203:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,203:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,206:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,206:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:51,206:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,207:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,207:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,208:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,209:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:51,212:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:51,212:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,576:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:52,657:INFO:Calculating mean and std
2025-05-19 21:06:52,658:INFO:Creating metrics dataframe
2025-05-19 21:06:52,660:INFO:Uploading results into container
2025-05-19 21:06:52,661:INFO:Uploading model into container now
2025-05-19 21:06:52,661:INFO:_master_model_container: 7
2025-05-19 21:06:52,662:INFO:_display_container: 2
2025-05-19 21:06:52,662:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=777, verbose=0,
                       warm_start=False)
2025-05-19 21:06:52,664:INFO:create_model() successfully completed......................................
2025-05-19 21:06:52,780:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:52,780:INFO:Creating metrics dataframe
2025-05-19 21:06:52,788:INFO:Initializing Quadratic Discriminant Analysis
2025-05-19 21:06:52,788:INFO:Total runtime is 0.23652100960413616 minutes
2025-05-19 21:06:52,791:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:52,791:INFO:Initializing create_model()
2025-05-19 21:06:52,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:52,792:INFO:Checking exceptions
2025-05-19 21:06:52,792:INFO:Importing libraries
2025-05-19 21:06:52,792:INFO:Copying training dataset
2025-05-19 21:06:52,797:INFO:Defining folds
2025-05-19 21:06:52,797:INFO:Declaring metric variables
2025-05-19 21:06:52,801:INFO:Importing untrained model
2025-05-19 21:06:52,806:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 21:06:52,812:INFO:Starting cross validation
2025-05-19 21:06:52,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:52,918:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:52,918:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:52,920:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,920:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,921:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:52,921:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,921:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,922:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,922:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,924:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:52,924:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:52,925:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,925:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,925:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:52,925:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,925:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,925:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:52,925:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:52,926:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,926:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,926:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:52,926:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:52,926:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,930:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,930:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,930:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,930:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:52,930:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:52,930:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,086:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:06:53,086:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:06:53,086:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:06:53,090:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:06:53,094:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:06:53,094:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:06:53,098:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:06:53,098:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:06:53,103:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:06:53,114:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:06:53,184:INFO:Calculating mean and std
2025-05-19 21:06:53,185:INFO:Creating metrics dataframe
2025-05-19 21:06:53,189:INFO:Uploading results into container
2025-05-19 21:06:53,190:INFO:Uploading model into container now
2025-05-19 21:06:53,190:INFO:_master_model_container: 8
2025-05-19 21:06:53,190:INFO:_display_container: 2
2025-05-19 21:06:53,191:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 21:06:53,191:INFO:create_model() successfully completed......................................
2025-05-19 21:06:53,309:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:53,309:INFO:Creating metrics dataframe
2025-05-19 21:06:53,318:INFO:Initializing Ada Boost Classifier
2025-05-19 21:06:53,318:INFO:Total runtime is 0.2453506906827291 minutes
2025-05-19 21:06:53,322:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:53,322:INFO:Initializing create_model()
2025-05-19 21:06:53,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:53,322:INFO:Checking exceptions
2025-05-19 21:06:53,322:INFO:Importing libraries
2025-05-19 21:06:53,323:INFO:Copying training dataset
2025-05-19 21:06:53,338:INFO:Defining folds
2025-05-19 21:06:53,338:INFO:Declaring metric variables
2025-05-19 21:06:53,343:INFO:Importing untrained model
2025-05-19 21:06:53,349:INFO:Ada Boost Classifier Imported successfully
2025-05-19 21:06:53,360:INFO:Starting cross validation
2025-05-19 21:06:53,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:53,489:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:53,491:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,491:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,493:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,494:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,495:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:53,496:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:53,498:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,498:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,499:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,499:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,500:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,500:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,501:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,501:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,512:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:53,512:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:53,515:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:53,515:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,516:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,516:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,516:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,518:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,518:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,518:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,519:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,519:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,520:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:53,520:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,521:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,524:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:53,524:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,525:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,525:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:53,525:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,526:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,526:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,527:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,527:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,527:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,527:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,528:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,529:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:53,529:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,530:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,532:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,532:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,536:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:53,536:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:53,658:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 21:06:53,666:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 21:06:53,671:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 21:06:53,674:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 21:06:53,684:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 21:06:53,692:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 21:06:53,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 21:06:53,701:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 21:06:53,703:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 21:06:53,704:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-19 21:06:54,282:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:54,329:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:54,341:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:54,342:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:54,356:INFO:Calculating mean and std
2025-05-19 21:06:54,357:INFO:Creating metrics dataframe
2025-05-19 21:06:54,359:INFO:Uploading results into container
2025-05-19 21:06:54,359:INFO:Uploading model into container now
2025-05-19 21:06:54,360:INFO:_master_model_container: 9
2025-05-19 21:06:54,360:INFO:_display_container: 2
2025-05-19 21:06:54,360:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=777)
2025-05-19 21:06:54,360:INFO:create_model() successfully completed......................................
2025-05-19 21:06:54,478:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:54,478:INFO:Creating metrics dataframe
2025-05-19 21:06:54,485:INFO:Initializing Gradient Boosting Classifier
2025-05-19 21:06:54,485:INFO:Total runtime is 0.2648125449816386 minutes
2025-05-19 21:06:54,490:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:54,490:INFO:Initializing create_model()
2025-05-19 21:06:54,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:54,490:INFO:Checking exceptions
2025-05-19 21:06:54,490:INFO:Importing libraries
2025-05-19 21:06:54,490:INFO:Copying training dataset
2025-05-19 21:06:54,496:INFO:Defining folds
2025-05-19 21:06:54,497:INFO:Declaring metric variables
2025-05-19 21:06:54,501:INFO:Importing untrained model
2025-05-19 21:06:54,505:INFO:Gradient Boosting Classifier Imported successfully
2025-05-19 21:06:54,512:INFO:Starting cross validation
2025-05-19 21:06:54,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:54,619:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:54,619:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:54,620:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:54,621:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,621:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,621:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,622:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,622:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,622:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,622:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:54,623:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,623:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:54,623:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,623:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,624:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,624:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,625:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:54,625:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,625:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,626:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:54,626:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,626:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,626:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:54,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:54,629:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,629:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,629:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,629:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,631:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,631:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:54,632:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,632:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,632:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,632:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,633:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,633:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:54,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:54,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,008:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:57,012:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:57,030:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:57,037:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:57,039:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:57,043:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:57,047:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:57,074:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:06:57,089:INFO:Calculating mean and std
2025-05-19 21:06:57,090:INFO:Creating metrics dataframe
2025-05-19 21:06:57,093:INFO:Uploading results into container
2025-05-19 21:06:57,094:INFO:Uploading model into container now
2025-05-19 21:06:57,095:INFO:_master_model_container: 10
2025-05-19 21:06:57,095:INFO:_display_container: 2
2025-05-19 21:06:57,095:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=777, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-19 21:06:57,095:INFO:create_model() successfully completed......................................
2025-05-19 21:06:57,225:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:57,225:INFO:Creating metrics dataframe
2025-05-19 21:06:57,240:INFO:Initializing Linear Discriminant Analysis
2025-05-19 21:06:57,240:INFO:Total runtime is 0.3107240080833435 minutes
2025-05-19 21:06:57,244:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:57,245:INFO:Initializing create_model()
2025-05-19 21:06:57,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:57,245:INFO:Checking exceptions
2025-05-19 21:06:57,245:INFO:Importing libraries
2025-05-19 21:06:57,245:INFO:Copying training dataset
2025-05-19 21:06:57,250:INFO:Defining folds
2025-05-19 21:06:57,250:INFO:Declaring metric variables
2025-05-19 21:06:57,255:INFO:Importing untrained model
2025-05-19 21:06:57,258:INFO:Linear Discriminant Analysis Imported successfully
2025-05-19 21:06:57,265:INFO:Starting cross validation
2025-05-19 21:06:57,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:57,373:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,373:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,375:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,376:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,376:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,376:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,378:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,378:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,379:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,379:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,379:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,381:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,381:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,382:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,382:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,383:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,384:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,384:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,384:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,384:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,385:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,385:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,385:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,386:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,388:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,389:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,390:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,390:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,390:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,391:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,391:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,394:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,395:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,397:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,398:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,400:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,400:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,400:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,400:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,401:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,401:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,405:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,405:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,411:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,415:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,415:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,417:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,417:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,654:INFO:Calculating mean and std
2025-05-19 21:06:57,655:INFO:Creating metrics dataframe
2025-05-19 21:06:57,658:INFO:Uploading results into container
2025-05-19 21:06:57,659:INFO:Uploading model into container now
2025-05-19 21:06:57,660:INFO:_master_model_container: 11
2025-05-19 21:06:57,660:INFO:_display_container: 2
2025-05-19 21:06:57,660:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-19 21:06:57,660:INFO:create_model() successfully completed......................................
2025-05-19 21:06:57,789:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:57,789:INFO:Creating metrics dataframe
2025-05-19 21:06:57,798:INFO:Initializing Extra Trees Classifier
2025-05-19 21:06:57,798:INFO:Total runtime is 0.32001336018244425 minutes
2025-05-19 21:06:57,800:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:57,801:INFO:Initializing create_model()
2025-05-19 21:06:57,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:57,801:INFO:Checking exceptions
2025-05-19 21:06:57,801:INFO:Importing libraries
2025-05-19 21:06:57,801:INFO:Copying training dataset
2025-05-19 21:06:57,808:INFO:Defining folds
2025-05-19 21:06:57,808:INFO:Declaring metric variables
2025-05-19 21:06:57,812:INFO:Importing untrained model
2025-05-19 21:06:57,819:INFO:Extra Trees Classifier Imported successfully
2025-05-19 21:06:57,829:INFO:Starting cross validation
2025-05-19 21:06:57,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:57,958:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,959:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,960:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,960:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,961:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,961:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,962:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,962:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,962:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,962:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,963:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,963:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,963:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,963:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,963:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,964:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,965:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,965:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,965:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,965:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,965:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,965:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,967:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,968:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,968:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,968:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,968:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,968:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,968:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,969:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,970:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,970:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,970:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,970:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,970:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,971:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,971:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,972:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,972:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,974:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,974:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,974:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,974:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,976:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:57,979:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,980:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:57,982:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:57,982:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,122:INFO:Calculating mean and std
2025-05-19 21:06:59,123:INFO:Creating metrics dataframe
2025-05-19 21:06:59,126:INFO:Uploading results into container
2025-05-19 21:06:59,127:INFO:Uploading model into container now
2025-05-19 21:06:59,127:INFO:_master_model_container: 12
2025-05-19 21:06:59,128:INFO:_display_container: 2
2025-05-19 21:06:59,128:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=777, verbose=0,
                     warm_start=False)
2025-05-19 21:06:59,128:INFO:create_model() successfully completed......................................
2025-05-19 21:06:59,262:INFO:SubProcess create_model() end ==================================
2025-05-19 21:06:59,264:INFO:Creating metrics dataframe
2025-05-19 21:06:59,276:INFO:Initializing Light Gradient Boosting Machine
2025-05-19 21:06:59,277:INFO:Total runtime is 0.3446792721748352 minutes
2025-05-19 21:06:59,281:INFO:SubProcess create_model() called ==================================
2025-05-19 21:06:59,281:INFO:Initializing create_model()
2025-05-19 21:06:59,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:06:59,281:INFO:Checking exceptions
2025-05-19 21:06:59,281:INFO:Importing libraries
2025-05-19 21:06:59,281:INFO:Copying training dataset
2025-05-19 21:06:59,287:INFO:Defining folds
2025-05-19 21:06:59,287:INFO:Declaring metric variables
2025-05-19 21:06:59,290:INFO:Importing untrained model
2025-05-19 21:06:59,295:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-19 21:06:59,301:INFO:Starting cross validation
2025-05-19 21:06:59,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:06:59,401:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:59,404:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:59,404:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,405:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,406:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,408:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,408:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:59,408:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,409:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,410:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,410:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,411:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,411:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,412:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,414:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,414:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:59,415:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:59,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,417:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:59,417:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,417:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,418:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,418:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,419:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:59,419:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,419:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:59,419:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,420:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,421:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,421:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,422:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,422:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,423:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,423:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,423:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,423:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,424:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,424:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,426:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,429:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:59,432:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,432:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:06:59,432:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,433:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,433:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,433:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,434:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:06:59,435:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:06:59,436:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,313:INFO:Calculating mean and std
2025-05-19 21:07:01,315:INFO:Creating metrics dataframe
2025-05-19 21:07:01,317:INFO:Uploading results into container
2025-05-19 21:07:01,318:INFO:Uploading model into container now
2025-05-19 21:07:01,318:INFO:_master_model_container: 13
2025-05-19 21:07:01,319:INFO:_display_container: 2
2025-05-19 21:07:01,320:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=777, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-19 21:07:01,320:INFO:create_model() successfully completed......................................
2025-05-19 21:07:01,470:INFO:SubProcess create_model() end ==================================
2025-05-19 21:07:01,470:INFO:Creating metrics dataframe
2025-05-19 21:07:01,480:INFO:Initializing Dummy Classifier
2025-05-19 21:07:01,480:INFO:Total runtime is 0.38138670126597085 minutes
2025-05-19 21:07:01,483:INFO:SubProcess create_model() called ==================================
2025-05-19 21:07:01,483:INFO:Initializing create_model()
2025-05-19 21:07:01,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69EFED7D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:07:01,483:INFO:Checking exceptions
2025-05-19 21:07:01,484:INFO:Importing libraries
2025-05-19 21:07:01,484:INFO:Copying training dataset
2025-05-19 21:07:01,489:INFO:Defining folds
2025-05-19 21:07:01,490:INFO:Declaring metric variables
2025-05-19 21:07:01,494:INFO:Importing untrained model
2025-05-19 21:07:01,498:INFO:Dummy Classifier Imported successfully
2025-05-19 21:07:01,512:INFO:Starting cross validation
2025-05-19 21:07:01,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:07:01,626:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:01,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:01,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,630:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:01,631:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:01,631:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:01,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:01,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,636:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,637:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,637:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:01,637:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

ubsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:01,637:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,637:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,637:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,638:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,638:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,638:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,638:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:01,639:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,639:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,640:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,640:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,640:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,641:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,641:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,641:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,641:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,642:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,642:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,643:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,643:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,643:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,644:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,663:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:01,665:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,667:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,677:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:01,678:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:01,845:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:07:01,850:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:07:01,851:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:07:01,855:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:07:01,856:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:07:01,861:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:07:01,862:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:07:01,864:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:07:01,877:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:07:01,879:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-19 21:07:01,885:INFO:Calculating mean and std
2025-05-19 21:07:01,886:INFO:Creating metrics dataframe
2025-05-19 21:07:01,887:INFO:Uploading results into container
2025-05-19 21:07:01,888:INFO:Uploading model into container now
2025-05-19 21:07:01,889:INFO:_master_model_container: 14
2025-05-19 21:07:01,889:INFO:_display_container: 2
2025-05-19 21:07:01,890:INFO:DummyClassifier(constant=None, random_state=777, strategy='prior')
2025-05-19 21:07:01,890:INFO:create_model() successfully completed......................................
2025-05-19 21:07:02,017:INFO:SubProcess create_model() end ==================================
2025-05-19 21:07:02,017:INFO:Creating metrics dataframe
2025-05-19 21:07:02,032:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-05-19 21:07:02,042:INFO:Initializing create_model()
2025-05-19 21:07:02,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:07:02,042:INFO:Checking exceptions
2025-05-19 21:07:02,044:INFO:Importing libraries
2025-05-19 21:07:02,044:INFO:Copying training dataset
2025-05-19 21:07:02,050:INFO:Defining folds
2025-05-19 21:07:02,050:INFO:Declaring metric variables
2025-05-19 21:07:02,050:INFO:Importing untrained model
2025-05-19 21:07:02,050:INFO:Declaring custom model
2025-05-19 21:07:02,050:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 21:07:02,052:INFO:Cross validation set to False
2025-05-19 21:07:02,053:INFO:Fitting Model
2025-05-19 21:07:02,110:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:07:02,116:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:02,116:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:02,118:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:07:02,118:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:07:02,240:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:07:02,244:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 21:07:02,244:INFO:create_model() successfully completed......................................
2025-05-19 21:07:02,393:INFO:_master_model_container: 14
2025-05-19 21:07:02,393:INFO:_display_container: 2
2025-05-19 21:07:02,394:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 21:07:02,394:INFO:compare_models() successfully completed......................................
2025-05-19 21:13:04,398:INFO:Initializing create_model()
2025-05-19 21:13:04,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:13:04,398:INFO:Checking exceptions
2025-05-19 21:13:04,414:INFO:Importing libraries
2025-05-19 21:13:04,414:INFO:Copying training dataset
2025-05-19 21:13:04,422:INFO:Defining folds
2025-05-19 21:13:04,422:INFO:Declaring metric variables
2025-05-19 21:13:04,425:INFO:Importing untrained model
2025-05-19 21:13:04,429:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 21:13:04,437:INFO:Starting cross validation
2025-05-19 21:13:04,439:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:13:09,123:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:09,126:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:09,127:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:09,132:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:09,233:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:09,238:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:09,251:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:09,277:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:09,282:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,282:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,282:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,282:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,284:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,284:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,284:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,285:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,289:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:09,289:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,289:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,290:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,290:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,290:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,290:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,290:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,292:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,293:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,293:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,293:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,294:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,387:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,387:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,388:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,388:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,389:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,389:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,390:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,390:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,406:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,406:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,407:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,407:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,420:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,420:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,423:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,423:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,434:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,437:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,437:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,443:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,443:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,445:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,445:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,447:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,448:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,551:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,551:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,553:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,580:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,594:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,644:INFO:Calculating mean and std
2025-05-19 21:13:09,647:INFO:Creating metrics dataframe
2025-05-19 21:13:09,655:INFO:Finalizing model
2025-05-19 21:13:09,713:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:09,718:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,719:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,720:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:09,720:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:09,834:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:09,844:INFO:Uploading results into container
2025-05-19 21:13:09,845:INFO:Uploading model into container now
2025-05-19 21:13:09,855:INFO:_master_model_container: 15
2025-05-19 21:13:09,855:INFO:_display_container: 3
2025-05-19 21:13:09,855:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 21:13:09,855:INFO:create_model() successfully completed......................................
2025-05-19 21:13:14,248:INFO:Initializing tune_model()
2025-05-19 21:13:14,248:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 21:13:14,248:INFO:Checking exceptions
2025-05-19 21:13:14,268:INFO:Copying training dataset
2025-05-19 21:13:14,272:INFO:Checking base model
2025-05-19 21:13:14,273:INFO:Base model : Quadratic Discriminant Analysis
2025-05-19 21:13:14,277:INFO:Declaring metric variables
2025-05-19 21:13:14,280:INFO:Defining Hyperparameters
2025-05-19 21:13:14,425:INFO:Tuning with n_jobs=-1
2025-05-19 21:13:14,425:INFO:Initializing RandomizedSearchCV
2025-05-19 21:13:14,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,546:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,547:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,548:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,548:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,548:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,551:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,551:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,553:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,554:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,554:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,556:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,559:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,559:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,559:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,559:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,560:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,561:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,561:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,561:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,561:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,563:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,564:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,564:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,565:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,565:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,566:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,568:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,569:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,570:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,570:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,571:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,572:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,572:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,572:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,573:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,573:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,575:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,575:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,575:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,575:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,578:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,578:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,582:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,585:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,587:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,589:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,589:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,706:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:14,728:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:14,737:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:14,748:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:14,759:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:14,767:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:14,784:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:14,791:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:14,798:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:14,810:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:14,869:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,872:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,873:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,876:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,876:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,880:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,885:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,887:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,892:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,892:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,915:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,917:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,918:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,919:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,921:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,921:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,921:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,921:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,923:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,923:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,926:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,926:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,931:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,931:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,932:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,932:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,932:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,935:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,935:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,935:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,936:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,938:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,938:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,938:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,939:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,965:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,968:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,969:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,970:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,972:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:14,995:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:14,998:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:14,998:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,001:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,001:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,065:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,084:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,098:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,099:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,104:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,132:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,131:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,139:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,154:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,184:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,220:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,223:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

ubsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,223:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,226:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,226:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,227:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,227:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,228:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,228:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,260:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,262:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,263:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,263:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,264:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,264:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,265:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,265:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,265:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,267:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,267:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,267:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,269:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,270:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,275:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,277:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,278:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,279:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,280:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,280:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,282:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,283:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,287:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,287:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,288:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,290:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,291:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,293:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,293:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,304:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,306:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,306:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,308:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,309:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,327:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,328:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,329:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,332:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,332:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,393:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,402:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,432:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,435:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,453:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,460:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,475:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,480:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,495:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,525:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,529:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,529:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,532:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,533:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,537:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,547:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,549:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,549:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,552:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,553:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,592:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,593:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,594:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,595:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,595:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,599:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,600:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,600:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,602:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,604:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,604:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,607:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,607:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,607:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,607:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,609:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,612:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,612:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,614:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,615:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,623:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,623:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,625:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,625:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,626:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,626:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,644:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,646:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,647:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,649:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,649:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,677:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,680:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,681:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,682:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,683:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,722:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,724:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,772:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,788:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,790:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,794:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,796:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,809:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,817:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,849:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:15,853:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,855:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,855:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,857:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,857:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,863:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,870:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,870:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,873:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,873:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,923:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,923:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,924:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,925:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,925:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,928:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,930:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,931:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,931:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,931:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,931:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,933:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,933:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,938:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,940:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,940:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,942:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,943:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,947:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,952:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,952:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,955:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,955:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,957:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,959:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,959:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,961:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,961:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,980:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:15,983:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,983:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:15,986:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:15,987:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,022:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,041:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,085:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,086:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,100:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,105:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,124:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,129:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,146:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,157:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,160:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,160:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,163:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,163:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,170:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,180:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,183:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,183:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,185:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,186:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,224:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,227:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,228:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,228:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,229:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,230:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,230:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,230:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,232:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,232:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,240:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,243:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,243:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,245:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,246:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,246:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,247:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,247:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,253:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,253:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,263:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,265:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,265:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,269:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,269:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,277:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,279:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,279:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,280:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,281:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,293:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,295:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,295:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,298:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,298:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,310:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,313:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,313:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,315:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,315:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,353:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,361:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,389:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,392:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,413:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,448:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,448:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,448:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,475:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,483:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,487:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,487:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,489:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,490:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,502:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,512:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,514:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,514:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,517:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,517:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,525:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,528:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,528:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,530:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,530:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,538:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,566:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,569:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,569:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,572:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,572:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,593:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,595:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,595:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,595:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,598:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,598:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,598:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,598:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,600:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,600:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,608:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,610:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,611:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,612:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,615:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,632:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,634:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,635:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,637:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,637:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,657:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,659:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,659:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,661:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,661:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,688:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,688:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,689:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,694:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,762:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,789:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,795:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,815:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,825:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,828:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,828:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,830:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,830:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,830:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,832:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,835:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,837:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,839:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,839:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,844:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,847:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,847:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,849:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,849:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,856:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,858:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,858:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,860:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,860:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,879:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:16,899:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,902:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,902:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,904:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,905:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,922:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,924:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,924:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,956:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,959:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,959:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,961:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,961:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,967:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,970:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,970:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,972:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,972:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:16,972:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,974:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,974:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:16,977:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:16,977:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,023:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,028:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,034:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,043:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,044:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,045:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,047:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,047:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,065:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,086:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,095:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,148:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,150:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,157:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,160:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,160:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,160:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,162:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,162:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,162:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,163:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,166:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,166:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,171:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,172:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,173:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,175:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,175:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,205:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,208:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,208:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,209:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,210:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,211:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,215:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,215:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,218:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,218:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,251:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,253:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,253:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,255:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,255:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,258:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,280:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,283:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,283:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,286:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,286:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,294:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,295:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,297:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,298:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,299:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,333:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,339:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,350:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,354:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,354:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,356:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,356:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,364:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,383:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,394:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,396:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,397:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,399:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,399:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,402:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,427:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,464:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,469:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,479:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,481:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,482:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,483:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,485:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,485:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,485:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,487:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,489:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,489:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,522:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,524:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,526:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,528:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,528:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,531:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,535:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,535:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,538:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,538:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,538:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,541:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,545:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,545:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,565:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,566:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,568:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,568:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,587:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,605:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,608:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,608:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,615:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,615:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,617:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:17,619:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,619:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,622:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:17,622:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:17,644:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,664:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,695:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,702:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,713:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,737:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,769:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:17,774:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:18,446:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,446:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,560:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,560:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,563:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,564:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,661:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:18,681:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:18,720:INFO:best_params: {'actual_estimator__reg_param': 0.29}
2025-05-19 21:13:18,722:INFO:Hyperparameter search completed
2025-05-19 21:13:18,722:INFO:SubProcess create_model() called ==================================
2025-05-19 21:13:18,723:INFO:Initializing create_model()
2025-05-19 21:13:18,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D67D3DC2D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_param': 0.29})
2025-05-19 21:13:18,724:INFO:Checking exceptions
2025-05-19 21:13:18,724:INFO:Importing libraries
2025-05-19 21:13:18,724:INFO:Copying training dataset
2025-05-19 21:13:18,733:INFO:Defining folds
2025-05-19 21:13:18,733:INFO:Declaring metric variables
2025-05-19 21:13:18,737:INFO:Importing untrained model
2025-05-19 21:13:18,737:INFO:Declaring custom model
2025-05-19 21:13:18,742:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 21:13:18,748:INFO:Starting cross validation
2025-05-19 21:13:18,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:13:18,868:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,870:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,871:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,871:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,871:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,871:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,873:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,874:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,875:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,875:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,875:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,875:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,875:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,876:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,876:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,876:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,879:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,879:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,880:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,880:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,880:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,880:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,882:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,882:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,882:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,885:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,885:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,887:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,887:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,887:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,887:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,888:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,888:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,888:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,889:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,889:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,889:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,890:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:18,893:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,893:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:18,894:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:18,895:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,036:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,042:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,045:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,047:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,051:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,052:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,054:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,055:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,060:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,063:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,111:INFO:Calculating mean and std
2025-05-19 21:13:19,113:INFO:Creating metrics dataframe
2025-05-19 21:13:19,117:INFO:Finalizing model
2025-05-19 21:13:19,169:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,172:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,172:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,174:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,175:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,292:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,303:INFO:Uploading results into container
2025-05-19 21:13:19,303:INFO:Uploading model into container now
2025-05-19 21:13:19,304:INFO:_master_model_container: 16
2025-05-19 21:13:19,304:INFO:_display_container: 4
2025-05-19 21:13:19,304:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001)
2025-05-19 21:13:19,304:INFO:create_model() successfully completed......................................
2025-05-19 21:13:19,422:INFO:SubProcess create_model() end ==================================
2025-05-19 21:13:19,422:INFO:choose_better activated
2025-05-19 21:13:19,425:INFO:SubProcess create_model() called ==================================
2025-05-19 21:13:19,426:INFO:Initializing create_model()
2025-05-19 21:13:19,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:13:19,427:INFO:Checking exceptions
2025-05-19 21:13:19,429:INFO:Importing libraries
2025-05-19 21:13:19,429:INFO:Copying training dataset
2025-05-19 21:13:19,436:INFO:Defining folds
2025-05-19 21:13:19,436:INFO:Declaring metric variables
2025-05-19 21:13:19,436:INFO:Importing untrained model
2025-05-19 21:13:19,436:INFO:Declaring custom model
2025-05-19 21:13:19,437:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 21:13:19,437:INFO:Starting cross validation
2025-05-19 21:13:19,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:13:19,537:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,538:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,539:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,539:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,539:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,544:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,544:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,544:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,544:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,544:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,544:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,545:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,545:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,545:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,545:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,547:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,547:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,547:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,547:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,559:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,560:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,560:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,689:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,696:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,696:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,700:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,709:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,719:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,722:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,722:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,730:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,731:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,785:INFO:Calculating mean and std
2025-05-19 21:13:19,785:INFO:Creating metrics dataframe
2025-05-19 21:13:19,787:INFO:Finalizing model
2025-05-19 21:13:19,837:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:13:19,840:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,840:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,843:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:13:19,843:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:13:19,957:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:13:19,961:INFO:Uploading results into container
2025-05-19 21:13:19,963:INFO:Uploading model into container now
2025-05-19 21:13:19,963:INFO:_master_model_container: 17
2025-05-19 21:13:19,963:INFO:_display_container: 5
2025-05-19 21:13:19,963:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 21:13:19,963:INFO:create_model() successfully completed......................................
2025-05-19 21:13:20,078:INFO:SubProcess create_model() end ==================================
2025-05-19 21:13:20,079:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for Recall is 0.8858
2025-05-19 21:13:20,079:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001) result for Recall is 0.4275
2025-05-19 21:13:20,079:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) is best model
2025-05-19 21:13:20,079:INFO:choose_better completed
2025-05-19 21:13:20,080:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 21:13:20,097:INFO:_master_model_container: 17
2025-05-19 21:13:20,097:INFO:_display_container: 4
2025-05-19 21:13:20,098:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 21:13:20,098:INFO:tune_model() successfully completed......................................
2025-05-19 21:14:32,558:INFO:Initializing tune_model()
2025-05-19 21:14:32,558:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-05-19 21:14:32,558:INFO:Checking exceptions
2025-05-19 21:14:32,577:INFO:Copying training dataset
2025-05-19 21:14:32,580:INFO:Checking base model
2025-05-19 21:14:32,580:INFO:Base model : Quadratic Discriminant Analysis
2025-05-19 21:14:32,584:INFO:Declaring metric variables
2025-05-19 21:14:32,588:INFO:Defining Hyperparameters
2025-05-19 21:14:32,715:INFO:Tuning with n_jobs=-1
2025-05-19 21:14:32,715:INFO:Initializing RandomizedSearchCV
2025-05-19 21:14:32,836:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,839:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,839:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,839:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,840:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,844:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,844:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,844:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,845:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,845:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,845:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,847:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,847:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,848:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,848:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,848:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,849:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,849:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,850:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,851:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,851:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,851:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,852:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,853:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,853:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,853:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,853:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,854:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,855:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,855:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,855:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,855:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,857:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,857:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,858:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,858:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,860:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,860:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,860:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,860:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,863:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,863:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,868:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,872:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,872:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,876:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,876:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,894:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:32,896:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,896:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:32,898:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:32,898:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,013:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,019:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,025:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,025:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,035:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,046:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,049:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,062:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,064:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,068:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,078:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,114:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,166:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,168:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,168:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,170:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,170:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,184:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,184:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,185:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,189:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,191:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,191:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,188:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,192:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,193:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,193:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,193:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,193:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,194:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,194:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,193:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,196:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,198:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,198:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,198:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,198:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,200:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,202:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,202:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,204:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,204:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,205:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,209:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,209:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,212:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,212:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,216:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,218:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,218:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,218:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,221:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,222:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,222:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,222:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,222:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,224:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,222:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,225:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,226:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,226:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,251:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,253:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,253:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,255:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,255:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,369:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,375:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,385:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,387:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,389:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,396:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,400:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,444:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,464:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,471:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,480:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,512:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,515:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,515:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,515:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,517:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,517:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,517:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,519:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

ubsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,520:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,520:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,520:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,522:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,523:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,523:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,523:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,523:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,525:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,526:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,526:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,526:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,528:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,528:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,530:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,530:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,541:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,544:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,545:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,545:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,546:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,546:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,595:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,598:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,598:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,600:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,600:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,610:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,610:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,613:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,613:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,613:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,615:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,615:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,615:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,615:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,620:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,625:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,626:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,627:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,628:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,665:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,667:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,668:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,669:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,669:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,687:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,696:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,702:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,705:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,705:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,710:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,724:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,781:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,799:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,803:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,832:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,836:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,836:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,838:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,838:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,839:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,840:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,842:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,843:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,843:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,844:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,845:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,845:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,846:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,846:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,846:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,846:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,847:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,848:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,848:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,848:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,850:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,850:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,856:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,859:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:33,859:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,859:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,862:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,862:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,873:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,876:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,876:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,879:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,879:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,919:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,922:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,922:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,924:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,924:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,933:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,936:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,936:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,937:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,938:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,939:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:33,942:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,943:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:33,944:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:33,944:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,000:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,004:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,005:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,005:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,007:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,007:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,008:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,008:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,010:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,010:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,022:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,035:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,037:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,039:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,042:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,049:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,052:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,070:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,112:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,122:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,161:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,162:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,163:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,165:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,165:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,172:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,175:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,176:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,176:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,177:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,177:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,177:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,179:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,179:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,179:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,180:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,182:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,182:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,182:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,182:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,185:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,198:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,200:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,200:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,201:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,202:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,202:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,202:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,202:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,204:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,204:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,215:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,219:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,219:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,220:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,221:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,221:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,221:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,221:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,223:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,223:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,262:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,262:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,265:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,266:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,267:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,267:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,267:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,267:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,269:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,269:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,317:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,319:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,320:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,321:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,321:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,321:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,324:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,324:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,326:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,326:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,332:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,362:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,366:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,376:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,377:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,381:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,394:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,406:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,451:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,453:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,472:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,474:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,474:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,477:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,477:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,490:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,494:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,497:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,497:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,499:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,499:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,502:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,504:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,504:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,505:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,506:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,506:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,513:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,516:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,516:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,517:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,517:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,534:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,538:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,539:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,540:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,542:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,543:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,544:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,555:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,559:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,560:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,561:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,563:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,572:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,572:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,575:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,576:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,584:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,586:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,586:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,588:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,589:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,593:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,595:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,595:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,597:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,597:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,622:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,625:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,625:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,627:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,627:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,650:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,661:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,664:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,664:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,666:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,666:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,678:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,706:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,709:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,716:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,728:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,746:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,755:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,778:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,783:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,793:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,796:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,796:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,796:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,799:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,799:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,824:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,826:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,826:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,828:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,828:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,846:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,848:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,849:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,852:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,853:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,853:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,854:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,854:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,856:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,857:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,858:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,861:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,861:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,863:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,863:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,871:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,871:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,875:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,875:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,875:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,877:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,880:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,880:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,900:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,902:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,902:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,905:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,905:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,924:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,926:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,927:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,929:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,930:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,931:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,934:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,934:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,936:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

ubsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,936:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,940:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,940:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,943:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,944:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,965:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,983:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:34,994:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:34,996:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,997:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:34,999:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:34,999:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,015:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,024:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,044:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,047:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,065:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,070:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,099:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,100:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,107:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,107:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,109:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,109:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,109:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,112:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,121:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,125:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,126:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,127:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,128:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,146:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,150:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,150:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,152:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,153:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,158:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,170:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,172:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,172:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,176:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,176:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,183:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,185:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,186:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,188:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,188:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,190:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,191:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,192:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,194:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,195:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,196:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,198:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,198:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,198:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,199:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,200:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,200:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,200:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,201:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,202:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,232:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,235:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,235:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,237:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,237:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,238:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,241:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,241:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,246:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,246:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,247:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,249:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,249:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,251:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,251:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,261:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,285:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,287:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,287:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,288:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,289:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,292:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,324:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,357:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,362:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,364:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,368:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,374:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,380:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,384:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,384:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,386:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,386:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,404:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,406:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,411:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,414:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,414:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,419:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,448:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,455:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,458:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,458:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,460:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,461:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,468:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,470:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,470:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,471:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,471:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,512:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,539:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,568:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,575:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,607:INFO:best_params: {'actual_estimator__reg_param': 0.29}
2025-05-19 21:14:35,608:INFO:Hyperparameter search completed
2025-05-19 21:14:35,608:INFO:SubProcess create_model() called ==================================
2025-05-19 21:14:35,609:INFO:Initializing create_model()
2025-05-19 21:14:35,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D69E1C9590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_param': 0.29})
2025-05-19 21:14:35,609:INFO:Checking exceptions
2025-05-19 21:14:35,610:INFO:Importing libraries
2025-05-19 21:14:35,610:INFO:Copying training dataset
2025-05-19 21:14:35,617:INFO:Defining folds
2025-05-19 21:14:35,617:INFO:Declaring metric variables
2025-05-19 21:14:35,620:INFO:Importing untrained model
2025-05-19 21:14:35,620:INFO:Declaring custom model
2025-05-19 21:14:35,624:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 21:14:35,630:INFO:Starting cross validation
2025-05-19 21:14:35,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:14:35,720:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,722:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,722:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,722:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,724:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,724:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,725:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,725:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,725:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,726:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,726:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,726:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,726:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,726:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,727:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,727:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,727:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,727:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,728:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,728:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,728:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,728:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,728:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,730:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,730:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,730:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,730:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,731:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,732:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,732:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,732:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,732:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,732:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,732:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,732:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,732:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,732:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:35,735:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,735:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,735:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,735:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,735:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,735:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,735:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,736:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,736:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,736:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,737:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:35,737:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:35,865:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,869:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,876:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,878:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,880:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,886:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,886:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,891:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,893:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,899:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:35,951:INFO:Calculating mean and std
2025-05-19 21:14:35,952:INFO:Creating metrics dataframe
2025-05-19 21:14:35,957:INFO:Finalizing model
2025-05-19 21:14:36,009:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,012:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,012:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,014:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,014:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,133:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,142:INFO:Uploading results into container
2025-05-19 21:14:36,143:INFO:Uploading model into container now
2025-05-19 21:14:36,144:INFO:_master_model_container: 18
2025-05-19 21:14:36,144:INFO:_display_container: 5
2025-05-19 21:14:36,144:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001)
2025-05-19 21:14:36,145:INFO:create_model() successfully completed......................................
2025-05-19 21:14:36,295:INFO:SubProcess create_model() end ==================================
2025-05-19 21:14:36,295:INFO:choose_better activated
2025-05-19 21:14:36,298:INFO:SubProcess create_model() called ==================================
2025-05-19 21:14:36,299:INFO:Initializing create_model()
2025-05-19 21:14:36,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-19 21:14:36,299:INFO:Checking exceptions
2025-05-19 21:14:36,300:INFO:Importing libraries
2025-05-19 21:14:36,300:INFO:Copying training dataset
2025-05-19 21:14:36,305:INFO:Defining folds
2025-05-19 21:14:36,305:INFO:Declaring metric variables
2025-05-19 21:14:36,306:INFO:Importing untrained model
2025-05-19 21:14:36,306:INFO:Declaring custom model
2025-05-19 21:14:36,306:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-19 21:14:36,307:INFO:Starting cross validation
2025-05-19 21:14:36,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-19 21:14:36,401:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,403:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,403:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,404:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,406:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,406:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,406:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,406:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,406:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,408:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,409:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,409:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,409:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,409:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,409:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,409:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,411:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,411:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,411:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,411:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,412:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,412:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,412:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,412:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,413:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,413:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,413:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,413:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,414:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,414:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,414:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,415:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,415:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,415:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,416:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,417:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,417:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,418:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,418:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,418:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,420:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,420:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,423:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,423:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,554:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,562:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,563:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,569:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,569:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,578:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,585:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,588:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,590:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,592:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,641:INFO:Calculating mean and std
2025-05-19 21:14:36,641:INFO:Creating metrics dataframe
2025-05-19 21:14:36,643:INFO:Finalizing model
2025-05-19 21:14:36,692:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:248: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.
  warnings.warn(

2025-05-19 21:14:36,696:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,697:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:1474: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (5). Possibly due to duplicate points in X.
  return fit_method(estimator, *args, **kwargs)

2025-05-19 21:14:36,698:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\preprocessing\_discretization.py:322: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.
  warnings.warn(

2025-05-19 21:14:36,814:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-19 21:14:36,819:INFO:Uploading results into container
2025-05-19 21:14:36,819:INFO:Uploading model into container now
2025-05-19 21:14:36,819:INFO:_master_model_container: 19
2025-05-19 21:14:36,819:INFO:_display_container: 6
2025-05-19 21:14:36,820:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 21:14:36,820:INFO:create_model() successfully completed......................................
2025-05-19 21:14:36,933:INFO:SubProcess create_model() end ==================================
2025-05-19 21:14:36,934:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for Recall is 0.8858
2025-05-19 21:14:36,934:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.29,
                              store_covariance=False, tol=0.0001) result for Recall is 0.4275
2025-05-19 21:14:36,935:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) is best model
2025-05-19 21:14:36,935:INFO:choose_better completed
2025-05-19 21:14:36,935:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-05-19 21:14:36,949:INFO:_master_model_container: 19
2025-05-19 21:14:36,949:INFO:_display_container: 5
2025-05-19 21:14:36,950:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-19 21:14:36,950:INFO:tune_model() successfully completed......................................
2025-05-19 21:14:37,065:INFO:Initializing plot_model()
2025-05-19 21:14:37,065:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), plot=pr, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 21:14:37,065:INFO:Checking exceptions
2025-05-19 21:14:37,070:INFO:Preloading libraries
2025-05-19 21:14:37,070:INFO:Copying training dataset
2025-05-19 21:14:37,070:INFO:Plot type: pr
2025-05-19 21:14:37,427:INFO:Fitting Model
2025-05-19 21:14:37,427:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but QuadraticDiscriminantAnalysis was fitted with feature names
  warnings.warn(

2025-05-19 21:14:37,427:INFO:Scoring test/hold-out set
2025-05-19 21:14:37,562:INFO:Visual Rendered Successfully
2025-05-19 21:14:37,680:INFO:plot_model() successfully completed......................................
2025-05-19 21:14:37,680:INFO:Initializing plot_model()
2025-05-19 21:14:37,680:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D69EF6AC10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), plot=confusion_matrix, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-05-19 21:14:37,680:INFO:Checking exceptions
2025-05-19 21:14:37,685:INFO:Preloading libraries
2025-05-19 21:14:37,685:INFO:Copying training dataset
2025-05-19 21:14:37,685:INFO:Plot type: confusion_matrix
2025-05-19 21:14:38,000:INFO:Fitting Model
2025-05-19 21:14:38,000:WARNING:C:\Users\amonreal\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but QuadraticDiscriminantAnalysis was fitted with feature names
  warnings.warn(

2025-05-19 21:14:38,002:INFO:Scoring test/hold-out set
2025-05-19 21:14:38,090:INFO:Visual Rendered Successfully
2025-05-19 21:14:38,227:INFO:plot_model() successfully completed......................................
2025-05-20 20:21:52,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-20 20:21:52,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-20 20:21:52,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-20 20:21:52,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-20 20:22:08,498:INFO:PyCaret ClassificationExperiment
2025-05-20 20:22:08,499:INFO:Logging name: clf-default-name
2025-05-20 20:22:08,499:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-20 20:22:08,499:INFO:version 3.3.2
2025-05-20 20:22:08,499:INFO:Initializing setup()
2025-05-20 20:22:08,499:INFO:self.USI: 0e60
2025-05-20 20:22:08,499:INFO:self._variable_keys: {'X_train', 'gpu_param', 'memory', '_available_plots', 'y_test', 'fold_groups_param', 'X_test', 'USI', 'exp_name_log', 'fold_shuffle_param', 'logging_param', 'fold_generator', 'html_param', 'is_multiclass', 'exp_id', 'gpu_n_jobs_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'data', 'pipeline', 'target_param', 'idx', '_ml_usecase', 'X', 'seed', 'y', 'log_plots_param'}
2025-05-20 20:22:08,499:INFO:Checking environment
2025-05-20 20:22:08,499:INFO:python_version: 3.11.9
2025-05-20 20:22:08,499:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-05-20 20:22:08,499:INFO:machine: AMD64
2025-05-20 20:22:08,499:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-20 20:22:08,509:INFO:Memory: svmem(total=33554628608, available=14595469312, percent=56.5, used=18959159296, free=14595469312)
2025-05-20 20:22:08,509:INFO:Physical Core: 6
2025-05-20 20:22:08,509:INFO:Logical Core: 12
2025-05-20 20:22:08,509:INFO:Checking libraries
2025-05-20 20:22:08,509:INFO:System:
2025-05-20 20:22:08,509:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-05-20 20:22:08,509:INFO:executable: C:\Users\amonreal\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\python.exe
2025-05-20 20:22:08,509:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-20 20:22:08,509:INFO:PyCaret required dependencies:
2025-05-20 20:22:08,602:INFO:                 pip: 24.0
2025-05-20 20:22:08,602:INFO:          setuptools: 65.5.0
2025-05-20 20:22:08,602:INFO:             pycaret: 3.3.2
2025-05-20 20:22:08,602:INFO:             IPython: 9.2.0
2025-05-20 20:22:08,602:INFO:          ipywidgets: 8.1.7
2025-05-20 20:22:08,602:INFO:                tqdm: 4.67.1
2025-05-20 20:22:08,602:INFO:               numpy: 1.26.4
2025-05-20 20:22:08,602:INFO:              pandas: 2.1.4
2025-05-20 20:22:08,602:INFO:              jinja2: 3.1.6
2025-05-20 20:22:08,602:INFO:               scipy: 1.11.4
2025-05-20 20:22:08,602:INFO:              joblib: 1.3.2
2025-05-20 20:22:08,602:INFO:             sklearn: 1.4.2
2025-05-20 20:22:08,602:INFO:                pyod: 2.0.5
2025-05-20 20:22:08,602:INFO:            imblearn: 0.13.0
2025-05-20 20:22:08,602:INFO:   category_encoders: 2.7.0
2025-05-20 20:22:08,602:INFO:            lightgbm: 4.6.0
2025-05-20 20:22:08,602:INFO:               numba: 0.61.2
2025-05-20 20:22:08,602:INFO:            requests: 2.32.3
2025-05-20 20:22:08,602:INFO:          matplotlib: 3.7.5
2025-05-20 20:22:08,602:INFO:          scikitplot: 0.3.7
2025-05-20 20:22:08,602:INFO:         yellowbrick: 1.5
2025-05-20 20:22:08,602:INFO:              plotly: 5.24.1
2025-05-20 20:22:08,602:INFO:    plotly-resampler: Not installed
2025-05-20 20:22:08,602:INFO:             kaleido: 0.2.1
2025-05-20 20:22:08,602:INFO:           schemdraw: 0.15
2025-05-20 20:22:08,602:INFO:         statsmodels: 0.14.4
2025-05-20 20:22:08,602:INFO:              sktime: 0.26.0
2025-05-20 20:22:08,602:INFO:               tbats: 1.1.3
2025-05-20 20:22:08,602:INFO:            pmdarima: 2.0.4
2025-05-20 20:22:08,602:INFO:              psutil: 7.0.0
2025-05-20 20:22:08,602:INFO:          markupsafe: 3.0.2
2025-05-20 20:22:08,602:INFO:             pickle5: Not installed
2025-05-20 20:22:08,602:INFO:         cloudpickle: 3.1.1
2025-05-20 20:22:08,602:INFO:         deprecation: 2.1.0
2025-05-20 20:22:08,602:INFO:              xxhash: 3.5.0
2025-05-20 20:22:08,602:INFO:           wurlitzer: Not installed
2025-05-20 20:22:08,602:INFO:PyCaret optional dependencies:
2025-05-20 20:22:08,616:INFO:                shap: Not installed
2025-05-20 20:22:08,616:INFO:           interpret: Not installed
2025-05-20 20:22:08,616:INFO:                umap: Not installed
2025-05-20 20:22:08,616:INFO:     ydata_profiling: Not installed
2025-05-20 20:22:08,616:INFO:  explainerdashboard: Not installed
2025-05-20 20:22:08,616:INFO:             autoviz: Not installed
2025-05-20 20:22:08,616:INFO:           fairlearn: Not installed
2025-05-20 20:22:08,616:INFO:          deepchecks: Not installed
2025-05-20 20:22:08,616:INFO:             xgboost: Not installed
2025-05-20 20:22:08,616:INFO:            catboost: Not installed
2025-05-20 20:22:08,616:INFO:              kmodes: Not installed
2025-05-20 20:22:08,616:INFO:             mlxtend: Not installed
2025-05-20 20:22:08,616:INFO:       statsforecast: Not installed
2025-05-20 20:22:08,616:INFO:        tune_sklearn: Not installed
2025-05-20 20:22:08,616:INFO:                 ray: Not installed
2025-05-20 20:22:08,616:INFO:            hyperopt: Not installed
2025-05-20 20:22:08,616:INFO:              optuna: Not installed
2025-05-20 20:22:08,616:INFO:               skopt: Not installed
2025-05-20 20:22:08,616:INFO:              mlflow: Not installed
2025-05-20 20:22:08,616:INFO:              gradio: Not installed
2025-05-20 20:22:08,616:INFO:             fastapi: Not installed
2025-05-20 20:22:08,616:INFO:             uvicorn: Not installed
2025-05-20 20:22:08,616:INFO:              m2cgen: Not installed
2025-05-20 20:22:08,616:INFO:           evidently: Not installed
2025-05-20 20:22:08,616:INFO:               fugue: Not installed
2025-05-20 20:22:08,616:INFO:           streamlit: Not installed
2025-05-20 20:22:08,616:INFO:             prophet: Not installed
2025-05-20 20:22:08,616:INFO:None
2025-05-20 20:22:08,616:INFO:Set up data.
2025-05-20 20:22:08,632:INFO:Set up folding strategy.
2025-05-20 20:22:08,632:INFO:Set up train/test split.
2025-05-20 20:22:08,648:INFO:Set up index.
2025-05-20 20:22:08,649:INFO:Assigning column types.
2025-05-20 20:22:08,653:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-20 20:22:08,681:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-20 20:22:08,694:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-20 20:22:08,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:08,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:08,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-20 20:22:08,789:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-20 20:22:08,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:08,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:08,815:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-20 20:22:08,848:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-20 20:22:08,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:08,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:08,914:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-20 20:22:08,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:08,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:08,932:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-20 20:22:09,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:09,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:09,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:09,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:09,063:INFO:Preparing preprocessing pipeline...
2025-05-20 20:22:09,063:INFO:Set up simple imputation.
2025-05-20 20:22:09,078:INFO:Set up encoding of categorical features.
2025-05-20 20:22:09,078:INFO:Set up removing multicollinearity.
2025-05-20 20:22:09,078:INFO:Set up binning of numerical features.
2025-05-20 20:22:09,078:INFO:Set up imbalanced handling.
2025-05-20 20:22:09,078:INFO:Set up column transformation.
2025-05-20 20:22:09,648:INFO:Finished creating preprocessing pipeline.
2025-05-20 20:22:09,648:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                                 strategy='kmeans',
                                                                 subsample='warn'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              random_state=777,
                                                                              sampling_strategy='auto')))),
                ('transformation',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=PowerTransformer(copy=True,
                                                                 method='yeo-johnson',
                                                                 standardize=False)))],
         verbose=False)
2025-05-20 20:22:09,648:INFO:Creating final display dataframe.
2025-05-20 20:22:10,045:INFO:Setup _display_container:                     Description             Value
0                    Session id               777
1                        Target    cerrara_cuenta
2                   Target type            Binary
3           Original data shape        (5000, 13)
4        Transformed data shape        (7518, 20)
5   Transformed train set shape        (6018, 20)
6    Transformed test set shape        (1500, 20)
7              Numeric features                 9
8          Categorical features                 3
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17                Fix imbalance              True
18         Fix imbalance method             SMOTE
19               Transformation              True
20        Transformation method       yeo-johnson
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              0e60
2025-05-20 20:22:10,113:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:10,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:10,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:10,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-20 20:22:10,168:INFO:setup() successfully completed in 1.68s...............
2025-05-20 20:26:55,738:WARNING:C:\Users\amonreal\AppData\Local\Temp\ipykernel_27812\1421193740.py:15: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.barplot(x=fuga_counts.index, y=fuga_counts.values, palette="pastel")

2025-05-26 19:27:35,342:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:27:35,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:27:35,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:27:35,343:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:29:02,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:29:02,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:29:02,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:29:02,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:29:03,635:INFO:PyCaret ClassificationExperiment
2025-05-26 19:29:03,635:INFO:Logging name: clase_ml_s7_amonreal
2025-05-26 19:29:03,635:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-26 19:29:03,635:INFO:version 3.3.2
2025-05-26 19:29:03,635:INFO:Initializing setup()
2025-05-26 19:29:03,635:INFO:self.USI: 5d13
2025-05-26 19:29:03,635:INFO:self._variable_keys: {'gpu_n_jobs_param', 'html_param', 'y_train', 'fix_imbalance', '_ml_usecase', 'y', 'n_jobs_param', 'exp_id', 'fold_shuffle_param', 'log_plots_param', 'exp_name_log', 'fold_groups_param', 'target_param', 'X', '_available_plots', 'USI', 'y_test', 'gpu_param', 'data', 'memory', 'logging_param', 'idx', 'pipeline', 'X_test', 'seed', 'fold_generator', 'is_multiclass', 'X_train'}
2025-05-26 19:29:03,635:INFO:Checking environment
2025-05-26 19:29:03,637:INFO:python_version: 3.11.9
2025-05-26 19:29:03,637:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-05-26 19:29:03,637:INFO:machine: AMD64
2025-05-26 19:29:03,653:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-26 19:29:03,659:INFO:Memory: svmem(total=33554628608, available=14829662208, percent=55.8, used=18724966400, free=14829662208)
2025-05-26 19:29:03,659:INFO:Physical Core: 6
2025-05-26 19:29:03,660:INFO:Logical Core: 12
2025-05-26 19:29:03,660:INFO:Checking libraries
2025-05-26 19:29:03,660:INFO:System:
2025-05-26 19:29:03,660:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-05-26 19:29:03,660:INFO:executable: C:\Users\amonreal\Documents\amlbash\.venv\Scripts\python.exe
2025-05-26 19:29:03,660:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-26 19:29:03,660:INFO:PyCaret required dependencies:
2025-05-26 19:29:03,813:INFO:                 pip: 24.0
2025-05-26 19:29:03,813:INFO:          setuptools: 65.5.0
2025-05-26 19:29:03,813:INFO:             pycaret: 3.3.2
2025-05-26 19:29:03,813:INFO:             IPython: 9.2.0
2025-05-26 19:29:03,813:INFO:          ipywidgets: 8.1.7
2025-05-26 19:29:03,813:INFO:                tqdm: 4.67.1
2025-05-26 19:29:03,814:INFO:               numpy: 1.26.4
2025-05-26 19:29:03,814:INFO:              pandas: 2.1.4
2025-05-26 19:29:03,814:INFO:              jinja2: 3.1.6
2025-05-26 19:29:03,814:INFO:               scipy: 1.11.4
2025-05-26 19:29:03,814:INFO:              joblib: 1.3.2
2025-05-26 19:29:03,814:INFO:             sklearn: 1.4.2
2025-05-26 19:29:03,814:INFO:                pyod: 2.0.5
2025-05-26 19:29:03,814:INFO:            imblearn: 0.13.0
2025-05-26 19:29:03,814:INFO:   category_encoders: 2.7.0
2025-05-26 19:29:03,814:INFO:            lightgbm: 4.6.0
2025-05-26 19:29:03,814:INFO:               numba: 0.61.2
2025-05-26 19:29:03,814:INFO:            requests: 2.32.3
2025-05-26 19:29:03,814:INFO:          matplotlib: 3.7.5
2025-05-26 19:29:03,814:INFO:          scikitplot: 0.3.7
2025-05-26 19:29:03,814:INFO:         yellowbrick: 1.5
2025-05-26 19:29:03,814:INFO:              plotly: 5.24.1
2025-05-26 19:29:03,814:INFO:    plotly-resampler: Not installed
2025-05-26 19:29:03,814:INFO:             kaleido: 0.2.1
2025-05-26 19:29:03,814:INFO:           schemdraw: 0.15
2025-05-26 19:29:03,814:INFO:         statsmodels: 0.14.4
2025-05-26 19:29:03,814:INFO:              sktime: 0.26.0
2025-05-26 19:29:03,814:INFO:               tbats: 1.1.3
2025-05-26 19:29:03,814:INFO:            pmdarima: 2.0.4
2025-05-26 19:29:03,814:INFO:              psutil: 7.0.0
2025-05-26 19:29:03,814:INFO:          markupsafe: 3.0.2
2025-05-26 19:29:03,814:INFO:             pickle5: Not installed
2025-05-26 19:29:03,814:INFO:         cloudpickle: 3.1.1
2025-05-26 19:29:03,814:INFO:         deprecation: 2.1.0
2025-05-26 19:29:03,814:INFO:              xxhash: 3.5.0
2025-05-26 19:29:03,814:INFO:           wurlitzer: Not installed
2025-05-26 19:29:03,814:INFO:PyCaret optional dependencies:
2025-05-26 19:29:04,136:INFO:                shap: Not installed
2025-05-26 19:29:04,136:INFO:           interpret: Not installed
2025-05-26 19:29:04,136:INFO:                umap: Not installed
2025-05-26 19:29:04,136:INFO:     ydata_profiling: Not installed
2025-05-26 19:29:04,136:INFO:  explainerdashboard: Not installed
2025-05-26 19:29:04,136:INFO:             autoviz: Not installed
2025-05-26 19:29:04,136:INFO:           fairlearn: Not installed
2025-05-26 19:29:04,136:INFO:          deepchecks: Not installed
2025-05-26 19:29:04,136:INFO:             xgboost: Not installed
2025-05-26 19:29:04,136:INFO:            catboost: Not installed
2025-05-26 19:29:04,136:INFO:              kmodes: Not installed
2025-05-26 19:29:04,136:INFO:             mlxtend: Not installed
2025-05-26 19:29:04,136:INFO:       statsforecast: Not installed
2025-05-26 19:29:04,136:INFO:        tune_sklearn: Not installed
2025-05-26 19:29:04,136:INFO:                 ray: Not installed
2025-05-26 19:29:04,136:INFO:            hyperopt: Not installed
2025-05-26 19:29:04,136:INFO:              optuna: Not installed
2025-05-26 19:29:04,136:INFO:               skopt: Not installed
2025-05-26 19:29:04,136:INFO:              mlflow: 2.22.0
2025-05-26 19:29:04,136:INFO:              gradio: Not installed
2025-05-26 19:29:04,136:INFO:             fastapi: 0.115.12
2025-05-26 19:29:04,136:INFO:             uvicorn: 0.34.2
2025-05-26 19:29:04,136:INFO:              m2cgen: Not installed
2025-05-26 19:29:04,136:INFO:           evidently: Not installed
2025-05-26 19:29:04,136:INFO:               fugue: Not installed
2025-05-26 19:29:04,136:INFO:           streamlit: Not installed
2025-05-26 19:29:04,137:INFO:             prophet: Not installed
2025-05-26 19:29:04,137:INFO:None
2025-05-26 19:29:04,137:INFO:Set up data.
2025-05-26 19:29:04,148:INFO:Set up folding strategy.
2025-05-26 19:29:04,149:INFO:Set up train/test split.
2025-05-26 19:29:04,160:INFO:Set up index.
2025-05-26 19:29:04,161:INFO:Assigning column types.
2025-05-26 19:29:04,163:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-26 19:29:04,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-26 19:29:04,205:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:29:04,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-26 19:29:04,284:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:29:04,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,310:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-26 19:29:04,346:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:29:04,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,403:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:29:04,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,428:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-26 19:29:04,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,553:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,553:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,554:INFO:Preparing preprocessing pipeline...
2025-05-26 19:29:04,556:INFO:Set up simple imputation.
2025-05-26 19:29:04,558:INFO:Set up encoding of categorical features.
2025-05-26 19:29:04,609:INFO:Finished creating preprocessing pipeline.
2025-05-26 19:29:04,618:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'income', 'loan_amount',
                                             'loan_duration', 'credit_score',
                                             'has_credit_card',
                                             'num_dependents'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missin...
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['marital_status',
                                             'employment_status', 'education'],
                                    transformer=OneHotEncoder(cols=['marital_status',
                                                                    'employment_status',
                                                                    'education'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-26 19:29:04,618:INFO:Creating final display dataframe.
2025-05-26 19:29:04,778:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   989
1                        Target               default
2                   Target type                Binary
3           Original data shape             (500, 11)
4        Transformed data shape             (500, 17)
5   Transformed train set shape             (350, 17)
6    Transformed test set shape             (150, 17)
7              Numeric features                     7
8          Categorical features                     3
9                    Preprocess                  True
10              Imputation type                simple
11           Numeric imputation                  mean
12       Categorical imputation                  mode
13     Maximum one-hot encoding                    25
14              Encoding method                  None
15               Fold Generator       StratifiedKFold
16                  Fold Number                    10
17                     CPU Jobs                    -1
18                      Use GPU                 False
19               Log Experiment          MlflowLogger
20              Experiment Name  clase_ml_s7_amonreal
21                          USI                  5d13
2025-05-26 19:29:04,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:29:04,899:INFO:Logging experiment in loggers
2025-05-26 19:31:31,365:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:31:31,365:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:31:31,365:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:31:31,365:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:32:19,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:32:19,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:32:19,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:32:19,872:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:32:21,266:INFO:PyCaret ClassificationExperiment
2025-05-26 19:32:21,266:INFO:Logging name: clase_ml_s7_amonreal
2025-05-26 19:32:21,267:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-26 19:32:21,267:INFO:version 3.3.2
2025-05-26 19:32:21,267:INFO:Initializing setup()
2025-05-26 19:32:21,267:INFO:self.USI: fdd6
2025-05-26 19:32:21,267:INFO:self._variable_keys: {'X', 'y', 'fold_groups_param', 'fix_imbalance', '_ml_usecase', 'X_train', 'gpu_n_jobs_param', 'logging_param', 'memory', 'data', 'pipeline', 'y_train', 'fold_shuffle_param', 'log_plots_param', 'html_param', 'target_param', '_available_plots', 'gpu_param', 'is_multiclass', 'idx', 'n_jobs_param', 'fold_generator', 'USI', 'X_test', 'seed', 'exp_id', 'y_test', 'exp_name_log'}
2025-05-26 19:32:21,267:INFO:Checking environment
2025-05-26 19:32:21,267:INFO:python_version: 3.11.9
2025-05-26 19:32:21,267:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-05-26 19:32:21,267:INFO:machine: AMD64
2025-05-26 19:32:21,284:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-26 19:32:21,292:INFO:Memory: svmem(total=33554628608, available=15161114624, percent=54.8, used=18393513984, free=15161114624)
2025-05-26 19:32:21,292:INFO:Physical Core: 6
2025-05-26 19:32:21,292:INFO:Logical Core: 12
2025-05-26 19:32:21,292:INFO:Checking libraries
2025-05-26 19:32:21,292:INFO:System:
2025-05-26 19:32:21,292:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-05-26 19:32:21,292:INFO:executable: C:\Users\amonreal\Documents\amlbash\.venv\Scripts\python.exe
2025-05-26 19:32:21,292:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-26 19:32:21,292:INFO:PyCaret required dependencies:
2025-05-26 19:32:21,350:INFO:                 pip: 24.0
2025-05-26 19:32:21,350:INFO:          setuptools: 65.5.0
2025-05-26 19:32:21,350:INFO:             pycaret: 3.3.2
2025-05-26 19:32:21,351:INFO:             IPython: 9.2.0
2025-05-26 19:32:21,351:INFO:          ipywidgets: 8.1.7
2025-05-26 19:32:21,351:INFO:                tqdm: 4.67.1
2025-05-26 19:32:21,351:INFO:               numpy: 1.26.4
2025-05-26 19:32:21,351:INFO:              pandas: 2.1.4
2025-05-26 19:32:21,351:INFO:              jinja2: 3.1.6
2025-05-26 19:32:21,351:INFO:               scipy: 1.11.4
2025-05-26 19:32:21,351:INFO:              joblib: 1.3.2
2025-05-26 19:32:21,351:INFO:             sklearn: 1.4.2
2025-05-26 19:32:21,351:INFO:                pyod: 2.0.5
2025-05-26 19:32:21,351:INFO:            imblearn: 0.13.0
2025-05-26 19:32:21,351:INFO:   category_encoders: 2.7.0
2025-05-26 19:32:21,351:INFO:            lightgbm: 4.6.0
2025-05-26 19:32:21,351:INFO:               numba: 0.61.2
2025-05-26 19:32:21,351:INFO:            requests: 2.32.3
2025-05-26 19:32:21,351:INFO:          matplotlib: 3.7.5
2025-05-26 19:32:21,351:INFO:          scikitplot: 0.3.7
2025-05-26 19:32:21,351:INFO:         yellowbrick: 1.5
2025-05-26 19:32:21,351:INFO:              plotly: 5.24.1
2025-05-26 19:32:21,351:INFO:    plotly-resampler: Not installed
2025-05-26 19:32:21,351:INFO:             kaleido: 0.2.1
2025-05-26 19:32:21,351:INFO:           schemdraw: 0.15
2025-05-26 19:32:21,351:INFO:         statsmodels: 0.14.4
2025-05-26 19:32:21,351:INFO:              sktime: 0.26.0
2025-05-26 19:32:21,351:INFO:               tbats: 1.1.3
2025-05-26 19:32:21,351:INFO:            pmdarima: 2.0.4
2025-05-26 19:32:21,351:INFO:              psutil: 7.0.0
2025-05-26 19:32:21,351:INFO:          markupsafe: 3.0.2
2025-05-26 19:32:21,351:INFO:             pickle5: Not installed
2025-05-26 19:32:21,351:INFO:         cloudpickle: 3.1.1
2025-05-26 19:32:21,351:INFO:         deprecation: 2.1.0
2025-05-26 19:32:21,351:INFO:              xxhash: 3.5.0
2025-05-26 19:32:21,351:INFO:           wurlitzer: Not installed
2025-05-26 19:32:21,351:INFO:PyCaret optional dependencies:
2025-05-26 19:32:21,601:INFO:                shap: Not installed
2025-05-26 19:32:21,601:INFO:           interpret: Not installed
2025-05-26 19:32:21,601:INFO:                umap: Not installed
2025-05-26 19:32:21,601:INFO:     ydata_profiling: Not installed
2025-05-26 19:32:21,601:INFO:  explainerdashboard: Not installed
2025-05-26 19:32:21,601:INFO:             autoviz: Not installed
2025-05-26 19:32:21,601:INFO:           fairlearn: Not installed
2025-05-26 19:32:21,601:INFO:          deepchecks: Not installed
2025-05-26 19:32:21,601:INFO:             xgboost: Not installed
2025-05-26 19:32:21,601:INFO:            catboost: Not installed
2025-05-26 19:32:21,601:INFO:              kmodes: Not installed
2025-05-26 19:32:21,601:INFO:             mlxtend: Not installed
2025-05-26 19:32:21,601:INFO:       statsforecast: Not installed
2025-05-26 19:32:21,601:INFO:        tune_sklearn: Not installed
2025-05-26 19:32:21,601:INFO:                 ray: Not installed
2025-05-26 19:32:21,602:INFO:            hyperopt: Not installed
2025-05-26 19:32:21,602:INFO:              optuna: Not installed
2025-05-26 19:32:21,602:INFO:               skopt: Not installed
2025-05-26 19:32:21,602:INFO:              mlflow: 2.22.0
2025-05-26 19:32:21,602:INFO:              gradio: Not installed
2025-05-26 19:32:21,602:INFO:             fastapi: 0.115.12
2025-05-26 19:32:21,602:INFO:             uvicorn: 0.34.2
2025-05-26 19:32:21,602:INFO:              m2cgen: Not installed
2025-05-26 19:32:21,602:INFO:           evidently: Not installed
2025-05-26 19:32:21,602:INFO:               fugue: Not installed
2025-05-26 19:32:21,602:INFO:           streamlit: Not installed
2025-05-26 19:32:21,602:INFO:             prophet: Not installed
2025-05-26 19:32:21,602:INFO:None
2025-05-26 19:32:21,602:INFO:Set up data.
2025-05-26 19:32:21,607:INFO:Set up folding strategy.
2025-05-26 19:32:21,607:INFO:Set up train/test split.
2025-05-26 19:32:21,612:INFO:Set up index.
2025-05-26 19:32:21,613:INFO:Assigning column types.
2025-05-26 19:32:21,616:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-26 19:32:21,650:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-26 19:32:21,653:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:32:21,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,726:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-26 19:32:21,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:32:21,750:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,750:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-26 19:32:21,785:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:32:21,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,851:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:32:21,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,872:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-26 19:32:21,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:21,989:INFO:Preparing preprocessing pipeline...
2025-05-26 19:32:21,990:INFO:Set up simple imputation.
2025-05-26 19:32:21,991:INFO:Set up encoding of categorical features.
2025-05-26 19:32:22,036:INFO:Finished creating preprocessing pipeline.
2025-05-26 19:32:22,040:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'income', 'loan_amount',
                                             'loan_duration', 'credit_score',
                                             'has_credit_card',
                                             'num_dependents'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missin...
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['marital_status',
                                             'employment_status', 'education'],
                                    transformer=OneHotEncoder(cols=['marital_status',
                                                                    'employment_status',
                                                                    'education'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-26 19:32:22,040:INFO:Creating final display dataframe.
2025-05-26 19:32:22,185:INFO:Setup _display_container:                     Description                 Value
0                    Session id                   989
1                        Target               default
2                   Target type                Binary
3           Original data shape             (500, 11)
4        Transformed data shape             (500, 17)
5   Transformed train set shape             (350, 17)
6    Transformed test set shape             (150, 17)
7              Numeric features                     7
8          Categorical features                     3
9                    Preprocess                  True
10              Imputation type                simple
11           Numeric imputation                  mean
12       Categorical imputation                  mode
13     Maximum one-hot encoding                    25
14              Encoding method                  None
15               Fold Generator       StratifiedKFold
16                  Fold Number                    10
17                     CPU Jobs                    -1
18                      Use GPU                 False
19               Log Experiment          MlflowLogger
20              Experiment Name  clase_ml_s7_amonreal
21                          USI                  fdd6
2025-05-26 19:32:22,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:22,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:22,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:22,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:32:22,307:INFO:Logging experiment in loggers
2025-05-26 19:32:55,889:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:32:55,889:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:32:55,889:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:32:55,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:33:35,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:33:35,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:33:35,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:33:35,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:33:36,964:INFO:PyCaret ClassificationExperiment
2025-05-26 19:33:36,964:INFO:Logging name: Clase_ml_s7_alemonreal
2025-05-26 19:33:36,964:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-26 19:33:36,964:INFO:version 3.3.2
2025-05-26 19:33:36,964:INFO:Initializing setup()
2025-05-26 19:33:36,964:INFO:self.USI: eeb7
2025-05-26 19:33:36,966:INFO:self._variable_keys: {'y', 'X', 'fold_shuffle_param', 'fold_groups_param', 'data', 'html_param', 'y_train', 'seed', '_ml_usecase', 'USI', 'fix_imbalance', 'n_jobs_param', '_available_plots', 'is_multiclass', 'y_test', 'logging_param', 'log_plots_param', 'exp_id', 'idx', 'pipeline', 'X_test', 'gpu_n_jobs_param', 'memory', 'target_param', 'exp_name_log', 'gpu_param', 'fold_generator', 'X_train'}
2025-05-26 19:33:36,966:INFO:Checking environment
2025-05-26 19:33:36,966:INFO:python_version: 3.11.9
2025-05-26 19:33:36,966:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-05-26 19:33:36,966:INFO:machine: AMD64
2025-05-26 19:33:36,984:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-26 19:33:36,991:INFO:Memory: svmem(total=33554628608, available=14982635520, percent=55.3, used=18571993088, free=14982635520)
2025-05-26 19:33:36,991:INFO:Physical Core: 6
2025-05-26 19:33:36,991:INFO:Logical Core: 12
2025-05-26 19:33:36,992:INFO:Checking libraries
2025-05-26 19:33:36,992:INFO:System:
2025-05-26 19:33:36,992:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-05-26 19:33:36,992:INFO:executable: C:\Users\amonreal\Documents\amlbash\.venv\Scripts\python.exe
2025-05-26 19:33:36,992:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-26 19:33:36,992:INFO:PyCaret required dependencies:
2025-05-26 19:33:37,048:INFO:                 pip: 24.0
2025-05-26 19:33:37,048:INFO:          setuptools: 65.5.0
2025-05-26 19:33:37,048:INFO:             pycaret: 3.3.2
2025-05-26 19:33:37,048:INFO:             IPython: 9.2.0
2025-05-26 19:33:37,048:INFO:          ipywidgets: 8.1.7
2025-05-26 19:33:37,048:INFO:                tqdm: 4.67.1
2025-05-26 19:33:37,048:INFO:               numpy: 1.26.4
2025-05-26 19:33:37,048:INFO:              pandas: 2.1.4
2025-05-26 19:33:37,048:INFO:              jinja2: 3.1.6
2025-05-26 19:33:37,048:INFO:               scipy: 1.11.4
2025-05-26 19:33:37,048:INFO:              joblib: 1.3.2
2025-05-26 19:33:37,048:INFO:             sklearn: 1.4.2
2025-05-26 19:33:37,048:INFO:                pyod: 2.0.5
2025-05-26 19:33:37,048:INFO:            imblearn: 0.13.0
2025-05-26 19:33:37,048:INFO:   category_encoders: 2.7.0
2025-05-26 19:33:37,048:INFO:            lightgbm: 4.6.0
2025-05-26 19:33:37,048:INFO:               numba: 0.61.2
2025-05-26 19:33:37,049:INFO:            requests: 2.32.3
2025-05-26 19:33:37,049:INFO:          matplotlib: 3.7.5
2025-05-26 19:33:37,049:INFO:          scikitplot: 0.3.7
2025-05-26 19:33:37,049:INFO:         yellowbrick: 1.5
2025-05-26 19:33:37,049:INFO:              plotly: 5.24.1
2025-05-26 19:33:37,049:INFO:    plotly-resampler: Not installed
2025-05-26 19:33:37,049:INFO:             kaleido: 0.2.1
2025-05-26 19:33:37,049:INFO:           schemdraw: 0.15
2025-05-26 19:33:37,049:INFO:         statsmodels: 0.14.4
2025-05-26 19:33:37,049:INFO:              sktime: 0.26.0
2025-05-26 19:33:37,049:INFO:               tbats: 1.1.3
2025-05-26 19:33:37,049:INFO:            pmdarima: 2.0.4
2025-05-26 19:33:37,049:INFO:              psutil: 7.0.0
2025-05-26 19:33:37,049:INFO:          markupsafe: 3.0.2
2025-05-26 19:33:37,049:INFO:             pickle5: Not installed
2025-05-26 19:33:37,049:INFO:         cloudpickle: 3.1.1
2025-05-26 19:33:37,049:INFO:         deprecation: 2.1.0
2025-05-26 19:33:37,049:INFO:              xxhash: 3.5.0
2025-05-26 19:33:37,049:INFO:           wurlitzer: Not installed
2025-05-26 19:33:37,049:INFO:PyCaret optional dependencies:
2025-05-26 19:33:37,286:INFO:                shap: Not installed
2025-05-26 19:33:37,286:INFO:           interpret: Not installed
2025-05-26 19:33:37,286:INFO:                umap: Not installed
2025-05-26 19:33:37,286:INFO:     ydata_profiling: Not installed
2025-05-26 19:33:37,286:INFO:  explainerdashboard: Not installed
2025-05-26 19:33:37,286:INFO:             autoviz: Not installed
2025-05-26 19:33:37,286:INFO:           fairlearn: Not installed
2025-05-26 19:33:37,286:INFO:          deepchecks: Not installed
2025-05-26 19:33:37,286:INFO:             xgboost: Not installed
2025-05-26 19:33:37,286:INFO:            catboost: Not installed
2025-05-26 19:33:37,286:INFO:              kmodes: Not installed
2025-05-26 19:33:37,286:INFO:             mlxtend: Not installed
2025-05-26 19:33:37,286:INFO:       statsforecast: Not installed
2025-05-26 19:33:37,286:INFO:        tune_sklearn: Not installed
2025-05-26 19:33:37,286:INFO:                 ray: Not installed
2025-05-26 19:33:37,286:INFO:            hyperopt: Not installed
2025-05-26 19:33:37,286:INFO:              optuna: Not installed
2025-05-26 19:33:37,287:INFO:               skopt: Not installed
2025-05-26 19:33:37,287:INFO:              mlflow: 2.22.0
2025-05-26 19:33:37,287:INFO:              gradio: Not installed
2025-05-26 19:33:37,287:INFO:             fastapi: 0.115.12
2025-05-26 19:33:37,287:INFO:             uvicorn: 0.34.2
2025-05-26 19:33:37,287:INFO:              m2cgen: Not installed
2025-05-26 19:33:37,287:INFO:           evidently: Not installed
2025-05-26 19:33:37,287:INFO:               fugue: Not installed
2025-05-26 19:33:37,287:INFO:           streamlit: Not installed
2025-05-26 19:33:37,287:INFO:             prophet: Not installed
2025-05-26 19:33:37,287:INFO:None
2025-05-26 19:33:37,287:INFO:Set up data.
2025-05-26 19:33:37,292:INFO:Set up folding strategy.
2025-05-26 19:33:37,292:INFO:Set up train/test split.
2025-05-26 19:33:37,297:INFO:Set up index.
2025-05-26 19:33:37,297:INFO:Assigning column types.
2025-05-26 19:33:37,299:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-26 19:33:37,333:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-26 19:33:37,337:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:33:37,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-26 19:33:37,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:33:37,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,430:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-26 19:33:37,468:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:33:37,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,527:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:33:37,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,549:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-26 19:33:37,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,676:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,677:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,678:INFO:Preparing preprocessing pipeline...
2025-05-26 19:33:37,679:INFO:Set up simple imputation.
2025-05-26 19:33:37,681:INFO:Set up encoding of categorical features.
2025-05-26 19:33:37,729:INFO:Finished creating preprocessing pipeline.
2025-05-26 19:33:37,734:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'income', 'loan_amount',
                                             'loan_duration', 'credit_score',
                                             'has_credit_card',
                                             'num_dependents'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missin...
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['marital_status',
                                             'employment_status', 'education'],
                                    transformer=OneHotEncoder(cols=['marital_status',
                                                                    'employment_status',
                                                                    'education'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-26 19:33:37,734:INFO:Creating final display dataframe.
2025-05-26 19:33:37,893:INFO:Setup _display_container:                     Description                   Value
0                    Session id                     989
1                        Target                 default
2                   Target type                  Binary
3           Original data shape               (500, 11)
4        Transformed data shape               (500, 17)
5   Transformed train set shape               (350, 17)
6    Transformed test set shape               (150, 17)
7              Numeric features                       7
8          Categorical features                       3
9                    Preprocess                    True
10              Imputation type                  simple
11           Numeric imputation                    mean
12       Categorical imputation                    mode
13     Maximum one-hot encoding                      25
14              Encoding method                    None
15               Fold Generator         StratifiedKFold
16                  Fold Number                      10
17                     CPU Jobs                      -1
18                      Use GPU                   False
19               Log Experiment            MlflowLogger
20              Experiment Name  Clase_ml_s7_alemonreal
21                          USI                    eeb7
2025-05-26 19:33:37,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:37,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:38,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:38,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:33:38,016:INFO:Logging experiment in loggers
2025-05-26 19:37:25,565:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:37:25,565:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:37:25,565:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:37:25,565:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 19:37:26,935:INFO:PyCaret ClassificationExperiment
2025-05-26 19:37:26,935:INFO:Logging name: Clase_ml_s7_alemonreal
2025-05-26 19:37:26,935:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-26 19:37:26,935:INFO:version 3.3.2
2025-05-26 19:37:26,935:INFO:Initializing setup()
2025-05-26 19:37:26,935:INFO:self.USI: df4b
2025-05-26 19:37:26,935:INFO:self._variable_keys: {'X', 'exp_id', 'fold_shuffle_param', 'y_test', 'logging_param', 'idx', 'pipeline', 'gpu_param', 'y_train', 'gpu_n_jobs_param', 'is_multiclass', 'fold_groups_param', 'X_test', 'log_plots_param', 'target_param', 'html_param', 'y', '_ml_usecase', 'n_jobs_param', 'fix_imbalance', 'X_train', 'seed', 'memory', 'data', 'USI', 'fold_generator', '_available_plots', 'exp_name_log'}
2025-05-26 19:37:26,935:INFO:Checking environment
2025-05-26 19:37:26,935:INFO:python_version: 3.11.9
2025-05-26 19:37:26,935:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-05-26 19:37:26,935:INFO:machine: AMD64
2025-05-26 19:37:26,952:INFO:platform: Windows-10-10.0.26100-SP0
2025-05-26 19:37:26,959:INFO:Memory: svmem(total=33554628608, available=15102103552, percent=55.0, used=18452525056, free=15102103552)
2025-05-26 19:37:26,959:INFO:Physical Core: 6
2025-05-26 19:37:26,959:INFO:Logical Core: 12
2025-05-26 19:37:26,959:INFO:Checking libraries
2025-05-26 19:37:26,959:INFO:System:
2025-05-26 19:37:26,959:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-05-26 19:37:26,959:INFO:executable: C:\Users\amonreal\Documents\amlbash\.venv\Scripts\python.exe
2025-05-26 19:37:26,959:INFO:   machine: Windows-10-10.0.26100-SP0
2025-05-26 19:37:26,960:INFO:PyCaret required dependencies:
2025-05-26 19:37:27,016:INFO:                 pip: 24.0
2025-05-26 19:37:27,016:INFO:          setuptools: 65.5.0
2025-05-26 19:37:27,016:INFO:             pycaret: 3.3.2
2025-05-26 19:37:27,016:INFO:             IPython: 9.2.0
2025-05-26 19:37:27,016:INFO:          ipywidgets: 8.1.7
2025-05-26 19:37:27,016:INFO:                tqdm: 4.67.1
2025-05-26 19:37:27,016:INFO:               numpy: 1.26.4
2025-05-26 19:37:27,016:INFO:              pandas: 2.1.4
2025-05-26 19:37:27,016:INFO:              jinja2: 3.1.6
2025-05-26 19:37:27,016:INFO:               scipy: 1.11.4
2025-05-26 19:37:27,016:INFO:              joblib: 1.3.2
2025-05-26 19:37:27,016:INFO:             sklearn: 1.4.2
2025-05-26 19:37:27,016:INFO:                pyod: 2.0.5
2025-05-26 19:37:27,016:INFO:            imblearn: 0.13.0
2025-05-26 19:37:27,016:INFO:   category_encoders: 2.7.0
2025-05-26 19:37:27,016:INFO:            lightgbm: 4.6.0
2025-05-26 19:37:27,016:INFO:               numba: 0.61.2
2025-05-26 19:37:27,016:INFO:            requests: 2.32.3
2025-05-26 19:37:27,016:INFO:          matplotlib: 3.7.5
2025-05-26 19:37:27,016:INFO:          scikitplot: 0.3.7
2025-05-26 19:37:27,016:INFO:         yellowbrick: 1.5
2025-05-26 19:37:27,016:INFO:              plotly: 5.24.1
2025-05-26 19:37:27,016:INFO:    plotly-resampler: Not installed
2025-05-26 19:37:27,016:INFO:             kaleido: 0.2.1
2025-05-26 19:37:27,016:INFO:           schemdraw: 0.15
2025-05-26 19:37:27,016:INFO:         statsmodels: 0.14.4
2025-05-26 19:37:27,016:INFO:              sktime: 0.26.0
2025-05-26 19:37:27,016:INFO:               tbats: 1.1.3
2025-05-26 19:37:27,016:INFO:            pmdarima: 2.0.4
2025-05-26 19:37:27,016:INFO:              psutil: 7.0.0
2025-05-26 19:37:27,016:INFO:          markupsafe: 3.0.2
2025-05-26 19:37:27,016:INFO:             pickle5: Not installed
2025-05-26 19:37:27,016:INFO:         cloudpickle: 3.1.1
2025-05-26 19:37:27,016:INFO:         deprecation: 2.1.0
2025-05-26 19:37:27,016:INFO:              xxhash: 3.5.0
2025-05-26 19:37:27,016:INFO:           wurlitzer: Not installed
2025-05-26 19:37:27,016:INFO:PyCaret optional dependencies:
2025-05-26 19:37:27,272:INFO:                shap: Not installed
2025-05-26 19:37:27,272:INFO:           interpret: Not installed
2025-05-26 19:37:27,272:INFO:                umap: Not installed
2025-05-26 19:37:27,272:INFO:     ydata_profiling: Not installed
2025-05-26 19:37:27,272:INFO:  explainerdashboard: Not installed
2025-05-26 19:37:27,272:INFO:             autoviz: Not installed
2025-05-26 19:37:27,272:INFO:           fairlearn: Not installed
2025-05-26 19:37:27,272:INFO:          deepchecks: Not installed
2025-05-26 19:37:27,272:INFO:             xgboost: Not installed
2025-05-26 19:37:27,272:INFO:            catboost: Not installed
2025-05-26 19:37:27,272:INFO:              kmodes: Not installed
2025-05-26 19:37:27,272:INFO:             mlxtend: Not installed
2025-05-26 19:37:27,272:INFO:       statsforecast: Not installed
2025-05-26 19:37:27,272:INFO:        tune_sklearn: Not installed
2025-05-26 19:37:27,273:INFO:                 ray: Not installed
2025-05-26 19:37:27,273:INFO:            hyperopt: Not installed
2025-05-26 19:37:27,273:INFO:              optuna: Not installed
2025-05-26 19:37:27,273:INFO:               skopt: Not installed
2025-05-26 19:37:27,273:INFO:              mlflow: 2.22.0
2025-05-26 19:37:27,273:INFO:              gradio: Not installed
2025-05-26 19:37:27,273:INFO:             fastapi: 0.115.12
2025-05-26 19:37:27,273:INFO:             uvicorn: 0.34.2
2025-05-26 19:37:27,273:INFO:              m2cgen: Not installed
2025-05-26 19:37:27,273:INFO:           evidently: Not installed
2025-05-26 19:37:27,273:INFO:               fugue: Not installed
2025-05-26 19:37:27,273:INFO:           streamlit: Not installed
2025-05-26 19:37:27,273:INFO:             prophet: Not installed
2025-05-26 19:37:27,273:INFO:None
2025-05-26 19:37:27,273:INFO:Set up data.
2025-05-26 19:37:27,278:INFO:Set up folding strategy.
2025-05-26 19:37:27,278:INFO:Set up train/test split.
2025-05-26 19:37:27,283:INFO:Set up index.
2025-05-26 19:37:27,283:INFO:Assigning column types.
2025-05-26 19:37:27,286:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-26 19:37:27,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-26 19:37:27,323:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:37:27,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-26 19:37:27,386:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:37:27,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,412:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-26 19:37:27,448:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:37:27,471:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,512:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-26 19:37:27,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,534:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-26 19:37:27,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,653:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,655:INFO:Preparing preprocessing pipeline...
2025-05-26 19:37:27,656:INFO:Set up simple imputation.
2025-05-26 19:37:27,658:INFO:Set up encoding of categorical features.
2025-05-26 19:37:27,704:INFO:Finished creating preprocessing pipeline.
2025-05-26 19:37:27,709:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'income', 'loan_amount',
                                             'loan_duration', 'credit_score',
                                             'has_credit_card',
                                             'num_dependents'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missin...
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['marital_status',
                                             'employment_status', 'education'],
                                    transformer=OneHotEncoder(cols=['marital_status',
                                                                    'employment_status',
                                                                    'education'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-26 19:37:27,709:INFO:Creating final display dataframe.
2025-05-26 19:37:27,878:INFO:Setup _display_container:                     Description                   Value
0                    Session id                     989
1                        Target                 default
2                   Target type                  Binary
3           Original data shape               (500, 11)
4        Transformed data shape               (500, 17)
5   Transformed train set shape               (350, 17)
6    Transformed test set shape               (150, 17)
7              Numeric features                       7
8          Categorical features                       3
9                    Preprocess                    True
10              Imputation type                  simple
11           Numeric imputation                    mean
12       Categorical imputation                    mode
13     Maximum one-hot encoding                      25
14              Encoding method                    None
15               Fold Generator         StratifiedKFold
16                  Fold Number                      10
17                     CPU Jobs                      -1
18                      Use GPU                   False
19               Log Experiment                   False
20              Experiment Name  Clase_ml_s7_alemonreal
21                          USI                    df4b
2025-05-26 19:37:27,938:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-26 19:37:27,996:INFO:setup() successfully completed in 1.07s...............
2025-05-26 19:37:27,996:INFO:Initializing compare_models()
2025-05-26 19:37:27,996:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-05-26 19:37:27,996:INFO:Checking exceptions
2025-05-26 19:37:28,003:INFO:Preparing display monitor
2025-05-26 19:37:28,007:INFO:Initializing Logistic Regression
2025-05-26 19:37:28,007:INFO:Total runtime is 0.0 minutes
2025-05-26 19:37:28,007:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:28,007:INFO:Initializing create_model()
2025-05-26 19:37:28,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:28,007:INFO:Checking exceptions
2025-05-26 19:37:28,007:INFO:Importing libraries
2025-05-26 19:37:28,007:INFO:Copying training dataset
2025-05-26 19:37:28,010:INFO:Defining folds
2025-05-26 19:37:28,010:INFO:Declaring metric variables
2025-05-26 19:37:28,010:INFO:Importing untrained model
2025-05-26 19:37:28,010:INFO:Logistic Regression Imported successfully
2025-05-26 19:37:28,011:INFO:Starting cross validation
2025-05-26 19:37:28,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:32,713:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-26 19:37:32,732:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-26 19:37:32,764:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-26 19:37:32,767:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-26 19:37:32,780:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:32,790:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-26 19:37:32,797:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:32,801:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-26 19:37:32,808:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:32,809:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:32,824:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:32,846:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:32,872:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-26 19:37:32,889:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-26 19:37:32,914:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:32,924:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:32,931:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-26 19:37:32,960:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:32,966:INFO:Calculating mean and std
2025-05-26 19:37:32,968:INFO:Creating metrics dataframe
2025-05-26 19:37:32,971:INFO:Uploading results into container
2025-05-26 19:37:32,971:INFO:Uploading model into container now
2025-05-26 19:37:32,972:INFO:_master_model_container: 1
2025-05-26 19:37:32,972:INFO:_display_container: 2
2025-05-26 19:37:32,972:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=989, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-26 19:37:32,972:INFO:create_model() successfully completed......................................
2025-05-26 19:37:33,136:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:33,136:INFO:Creating metrics dataframe
2025-05-26 19:37:33,140:INFO:Initializing K Neighbors Classifier
2025-05-26 19:37:33,140:INFO:Total runtime is 0.08554578224817912 minutes
2025-05-26 19:37:33,140:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:33,141:INFO:Initializing create_model()
2025-05-26 19:37:33,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:33,141:INFO:Checking exceptions
2025-05-26 19:37:33,141:INFO:Importing libraries
2025-05-26 19:37:33,141:INFO:Copying training dataset
2025-05-26 19:37:33,147:INFO:Defining folds
2025-05-26 19:37:33,147:INFO:Declaring metric variables
2025-05-26 19:37:33,147:INFO:Importing untrained model
2025-05-26 19:37:33,147:INFO:K Neighbors Classifier Imported successfully
2025-05-26 19:37:33,147:INFO:Starting cross validation
2025-05-26 19:37:33,149:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:35,927:INFO:Calculating mean and std
2025-05-26 19:37:35,928:INFO:Creating metrics dataframe
2025-05-26 19:37:35,929:INFO:Uploading results into container
2025-05-26 19:37:35,930:INFO:Uploading model into container now
2025-05-26 19:37:35,930:INFO:_master_model_container: 2
2025-05-26 19:37:35,930:INFO:_display_container: 2
2025-05-26 19:37:35,931:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-26 19:37:35,931:INFO:create_model() successfully completed......................................
2025-05-26 19:37:36,078:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:36,078:INFO:Creating metrics dataframe
2025-05-26 19:37:36,080:INFO:Initializing Naive Bayes
2025-05-26 19:37:36,080:INFO:Total runtime is 0.13455638885498047 minutes
2025-05-26 19:37:36,080:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:36,080:INFO:Initializing create_model()
2025-05-26 19:37:36,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:36,080:INFO:Checking exceptions
2025-05-26 19:37:36,080:INFO:Importing libraries
2025-05-26 19:37:36,081:INFO:Copying training dataset
2025-05-26 19:37:36,084:INFO:Defining folds
2025-05-26 19:37:36,084:INFO:Declaring metric variables
2025-05-26 19:37:36,084:INFO:Importing untrained model
2025-05-26 19:37:36,084:INFO:Naive Bayes Imported successfully
2025-05-26 19:37:36,084:INFO:Starting cross validation
2025-05-26 19:37:36,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:36,181:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,186:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,186:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,188:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,199:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,212:INFO:Calculating mean and std
2025-05-26 19:37:36,213:INFO:Creating metrics dataframe
2025-05-26 19:37:36,214:INFO:Uploading results into container
2025-05-26 19:37:36,214:INFO:Uploading model into container now
2025-05-26 19:37:36,214:INFO:_master_model_container: 3
2025-05-26 19:37:36,216:INFO:_display_container: 2
2025-05-26 19:37:36,216:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-26 19:37:36,216:INFO:create_model() successfully completed......................................
2025-05-26 19:37:36,356:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:36,356:INFO:Creating metrics dataframe
2025-05-26 19:37:36,358:INFO:Initializing Decision Tree Classifier
2025-05-26 19:37:36,358:INFO:Total runtime is 0.1391868273417155 minutes
2025-05-26 19:37:36,358:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:36,358:INFO:Initializing create_model()
2025-05-26 19:37:36,358:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:36,358:INFO:Checking exceptions
2025-05-26 19:37:36,358:INFO:Importing libraries
2025-05-26 19:37:36,358:INFO:Copying training dataset
2025-05-26 19:37:36,361:INFO:Defining folds
2025-05-26 19:37:36,361:INFO:Declaring metric variables
2025-05-26 19:37:36,361:INFO:Importing untrained model
2025-05-26 19:37:36,362:INFO:Decision Tree Classifier Imported successfully
2025-05-26 19:37:36,362:INFO:Starting cross validation
2025-05-26 19:37:36,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:36,489:INFO:Calculating mean and std
2025-05-26 19:37:36,490:INFO:Creating metrics dataframe
2025-05-26 19:37:36,492:INFO:Uploading results into container
2025-05-26 19:37:36,492:INFO:Uploading model into container now
2025-05-26 19:37:36,492:INFO:_master_model_container: 4
2025-05-26 19:37:36,492:INFO:_display_container: 2
2025-05-26 19:37:36,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=989, splitter='best')
2025-05-26 19:37:36,493:INFO:create_model() successfully completed......................................
2025-05-26 19:37:36,627:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:36,627:INFO:Creating metrics dataframe
2025-05-26 19:37:36,629:INFO:Initializing SVM - Linear Kernel
2025-05-26 19:37:36,629:INFO:Total runtime is 0.1436992685000102 minutes
2025-05-26 19:37:36,629:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:36,629:INFO:Initializing create_model()
2025-05-26 19:37:36,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:36,630:INFO:Checking exceptions
2025-05-26 19:37:36,630:INFO:Importing libraries
2025-05-26 19:37:36,630:INFO:Copying training dataset
2025-05-26 19:37:36,632:INFO:Defining folds
2025-05-26 19:37:36,632:INFO:Declaring metric variables
2025-05-26 19:37:36,632:INFO:Importing untrained model
2025-05-26 19:37:36,633:INFO:SVM - Linear Kernel Imported successfully
2025-05-26 19:37:36,633:INFO:Starting cross validation
2025-05-26 19:37:36,634:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:36,732:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,734:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,735:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,736:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,739:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,751:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:36,762:INFO:Calculating mean and std
2025-05-26 19:37:36,762:INFO:Creating metrics dataframe
2025-05-26 19:37:36,765:INFO:Uploading results into container
2025-05-26 19:37:36,765:INFO:Uploading model into container now
2025-05-26 19:37:36,765:INFO:_master_model_container: 5
2025-05-26 19:37:36,766:INFO:_display_container: 2
2025-05-26 19:37:36,766:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=989, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-26 19:37:36,766:INFO:create_model() successfully completed......................................
2025-05-26 19:37:36,905:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:36,905:INFO:Creating metrics dataframe
2025-05-26 19:37:36,907:INFO:Initializing Ridge Classifier
2025-05-26 19:37:36,907:INFO:Total runtime is 0.14833634297053022 minutes
2025-05-26 19:37:36,907:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:36,908:INFO:Initializing create_model()
2025-05-26 19:37:36,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:36,908:INFO:Checking exceptions
2025-05-26 19:37:36,908:INFO:Importing libraries
2025-05-26 19:37:36,908:INFO:Copying training dataset
2025-05-26 19:37:36,910:INFO:Defining folds
2025-05-26 19:37:36,911:INFO:Declaring metric variables
2025-05-26 19:37:36,911:INFO:Importing untrained model
2025-05-26 19:37:36,911:INFO:Ridge Classifier Imported successfully
2025-05-26 19:37:36,911:INFO:Starting cross validation
2025-05-26 19:37:36,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:37,004:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:37,006:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:37,008:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:37,008:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:37,008:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:37,011:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:37,013:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:37,014:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:37,026:INFO:Calculating mean and std
2025-05-26 19:37:37,027:INFO:Creating metrics dataframe
2025-05-26 19:37:37,028:INFO:Uploading results into container
2025-05-26 19:37:37,029:INFO:Uploading model into container now
2025-05-26 19:37:37,029:INFO:_master_model_container: 6
2025-05-26 19:37:37,029:INFO:_display_container: 2
2025-05-26 19:37:37,029:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=989, solver='auto',
                tol=0.0001)
2025-05-26 19:37:37,029:INFO:create_model() successfully completed......................................
2025-05-26 19:37:37,163:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:37,163:INFO:Creating metrics dataframe
2025-05-26 19:37:37,164:INFO:Initializing Random Forest Classifier
2025-05-26 19:37:37,164:INFO:Total runtime is 0.1526254534721375 minutes
2025-05-26 19:37:37,166:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:37,166:INFO:Initializing create_model()
2025-05-26 19:37:37,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:37,166:INFO:Checking exceptions
2025-05-26 19:37:37,166:INFO:Importing libraries
2025-05-26 19:37:37,166:INFO:Copying training dataset
2025-05-26 19:37:37,169:INFO:Defining folds
2025-05-26 19:37:37,169:INFO:Declaring metric variables
2025-05-26 19:37:37,169:INFO:Importing untrained model
2025-05-26 19:37:37,169:INFO:Random Forest Classifier Imported successfully
2025-05-26 19:37:37,169:INFO:Starting cross validation
2025-05-26 19:37:37,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:37,540:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:37,541:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:37,584:INFO:Calculating mean and std
2025-05-26 19:37:37,584:INFO:Creating metrics dataframe
2025-05-26 19:37:37,586:INFO:Uploading results into container
2025-05-26 19:37:37,587:INFO:Uploading model into container now
2025-05-26 19:37:37,587:INFO:_master_model_container: 7
2025-05-26 19:37:37,587:INFO:_display_container: 2
2025-05-26 19:37:37,588:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=989, verbose=0,
                       warm_start=False)
2025-05-26 19:37:37,588:INFO:create_model() successfully completed......................................
2025-05-26 19:37:37,726:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:37,726:INFO:Creating metrics dataframe
2025-05-26 19:37:37,728:INFO:Initializing Quadratic Discriminant Analysis
2025-05-26 19:37:37,728:INFO:Total runtime is 0.1620206673940023 minutes
2025-05-26 19:37:37,728:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:37,728:INFO:Initializing create_model()
2025-05-26 19:37:37,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:37,728:INFO:Checking exceptions
2025-05-26 19:37:37,728:INFO:Importing libraries
2025-05-26 19:37:37,728:INFO:Copying training dataset
2025-05-26 19:37:37,731:INFO:Defining folds
2025-05-26 19:37:37,731:INFO:Declaring metric variables
2025-05-26 19:37:37,731:INFO:Importing untrained model
2025-05-26 19:37:37,732:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-26 19:37:37,732:INFO:Starting cross validation
2025-05-26 19:37:37,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:37,799:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-26 19:37:37,800:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-26 19:37:37,800:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-26 19:37:37,800:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-26 19:37:37,801:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-26 19:37:37,801:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-26 19:37:37,802:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-26 19:37:37,804:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-26 19:37:37,806:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-26 19:37:37,806:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-26 19:37:37,846:INFO:Calculating mean and std
2025-05-26 19:37:37,846:INFO:Creating metrics dataframe
2025-05-26 19:37:37,848:INFO:Uploading results into container
2025-05-26 19:37:37,848:INFO:Uploading model into container now
2025-05-26 19:37:37,848:INFO:_master_model_container: 8
2025-05-26 19:37:37,848:INFO:_display_container: 2
2025-05-26 19:37:37,849:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-26 19:37:37,849:INFO:create_model() successfully completed......................................
2025-05-26 19:37:37,991:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:37,991:INFO:Creating metrics dataframe
2025-05-26 19:37:37,993:INFO:Initializing Ada Boost Classifier
2025-05-26 19:37:37,993:INFO:Total runtime is 0.16643393039703372 minutes
2025-05-26 19:37:37,993:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:37,993:INFO:Initializing create_model()
2025-05-26 19:37:37,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:37,993:INFO:Checking exceptions
2025-05-26 19:37:37,993:INFO:Importing libraries
2025-05-26 19:37:37,993:INFO:Copying training dataset
2025-05-26 19:37:37,996:INFO:Defining folds
2025-05-26 19:37:37,996:INFO:Declaring metric variables
2025-05-26 19:37:37,996:INFO:Importing untrained model
2025-05-26 19:37:37,996:INFO:Ada Boost Classifier Imported successfully
2025-05-26 19:37:37,996:INFO:Starting cross validation
2025-05-26 19:37:37,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:38,064:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-26 19:37:38,064:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-26 19:37:38,064:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-26 19:37:38,064:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-26 19:37:38,067:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-26 19:37:38,067:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-26 19:37:38,067:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-26 19:37:38,068:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-26 19:37:38,226:INFO:Calculating mean and std
2025-05-26 19:37:38,227:INFO:Creating metrics dataframe
2025-05-26 19:37:38,228:INFO:Uploading results into container
2025-05-26 19:37:38,229:INFO:Uploading model into container now
2025-05-26 19:37:38,229:INFO:_master_model_container: 9
2025-05-26 19:37:38,229:INFO:_display_container: 2
2025-05-26 19:37:38,229:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=989)
2025-05-26 19:37:38,229:INFO:create_model() successfully completed......................................
2025-05-26 19:37:38,367:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:38,367:INFO:Creating metrics dataframe
2025-05-26 19:37:38,369:INFO:Initializing Gradient Boosting Classifier
2025-05-26 19:37:38,369:INFO:Total runtime is 0.17269545793533328 minutes
2025-05-26 19:37:38,369:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:38,369:INFO:Initializing create_model()
2025-05-26 19:37:38,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:38,370:INFO:Checking exceptions
2025-05-26 19:37:38,370:INFO:Importing libraries
2025-05-26 19:37:38,370:INFO:Copying training dataset
2025-05-26 19:37:38,372:INFO:Defining folds
2025-05-26 19:37:38,372:INFO:Declaring metric variables
2025-05-26 19:37:38,373:INFO:Importing untrained model
2025-05-26 19:37:38,373:INFO:Gradient Boosting Classifier Imported successfully
2025-05-26 19:37:38,373:INFO:Starting cross validation
2025-05-26 19:37:38,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:38,652:INFO:Calculating mean and std
2025-05-26 19:37:38,652:INFO:Creating metrics dataframe
2025-05-26 19:37:38,655:INFO:Uploading results into container
2025-05-26 19:37:38,655:INFO:Uploading model into container now
2025-05-26 19:37:38,655:INFO:_master_model_container: 10
2025-05-26 19:37:38,655:INFO:_display_container: 2
2025-05-26 19:37:38,655:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=989, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-26 19:37:38,655:INFO:create_model() successfully completed......................................
2025-05-26 19:37:38,791:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:38,791:INFO:Creating metrics dataframe
2025-05-26 19:37:38,793:INFO:Initializing Linear Discriminant Analysis
2025-05-26 19:37:38,793:INFO:Total runtime is 0.17977670828501385 minutes
2025-05-26 19:37:38,793:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:38,793:INFO:Initializing create_model()
2025-05-26 19:37:38,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:38,793:INFO:Checking exceptions
2025-05-26 19:37:38,793:INFO:Importing libraries
2025-05-26 19:37:38,793:INFO:Copying training dataset
2025-05-26 19:37:38,796:INFO:Defining folds
2025-05-26 19:37:38,796:INFO:Declaring metric variables
2025-05-26 19:37:38,796:INFO:Importing untrained model
2025-05-26 19:37:38,797:INFO:Linear Discriminant Analysis Imported successfully
2025-05-26 19:37:38,797:INFO:Starting cross validation
2025-05-26 19:37:38,798:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:38,892:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:38,893:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:38,894:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:38,896:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:38,898:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:38,899:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:38,900:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:38,901:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:38,903:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:38,912:INFO:Calculating mean and std
2025-05-26 19:37:38,913:INFO:Creating metrics dataframe
2025-05-26 19:37:38,915:INFO:Uploading results into container
2025-05-26 19:37:38,915:INFO:Uploading model into container now
2025-05-26 19:37:38,915:INFO:_master_model_container: 11
2025-05-26 19:37:38,915:INFO:_display_container: 2
2025-05-26 19:37:38,916:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-26 19:37:38,916:INFO:create_model() successfully completed......................................
2025-05-26 19:37:39,051:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:39,051:INFO:Creating metrics dataframe
2025-05-26 19:37:39,054:INFO:Initializing Extra Trees Classifier
2025-05-26 19:37:39,054:INFO:Total runtime is 0.1841116031010946 minutes
2025-05-26 19:37:39,054:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:39,054:INFO:Initializing create_model()
2025-05-26 19:37:39,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:39,054:INFO:Checking exceptions
2025-05-26 19:37:39,054:INFO:Importing libraries
2025-05-26 19:37:39,054:INFO:Copying training dataset
2025-05-26 19:37:39,057:INFO:Defining folds
2025-05-26 19:37:39,057:INFO:Declaring metric variables
2025-05-26 19:37:39,057:INFO:Importing untrained model
2025-05-26 19:37:39,057:INFO:Extra Trees Classifier Imported successfully
2025-05-26 19:37:39,057:INFO:Starting cross validation
2025-05-26 19:37:39,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:39,454:INFO:Calculating mean and std
2025-05-26 19:37:39,454:INFO:Creating metrics dataframe
2025-05-26 19:37:39,457:INFO:Uploading results into container
2025-05-26 19:37:39,457:INFO:Uploading model into container now
2025-05-26 19:37:39,457:INFO:_master_model_container: 12
2025-05-26 19:37:39,457:INFO:_display_container: 2
2025-05-26 19:37:39,458:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=989, verbose=0,
                     warm_start=False)
2025-05-26 19:37:39,458:INFO:create_model() successfully completed......................................
2025-05-26 19:37:39,599:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:39,600:INFO:Creating metrics dataframe
2025-05-26 19:37:39,601:INFO:Initializing Light Gradient Boosting Machine
2025-05-26 19:37:39,601:INFO:Total runtime is 0.19324054320653283 minutes
2025-05-26 19:37:39,601:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:39,603:INFO:Initializing create_model()
2025-05-26 19:37:39,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:39,603:INFO:Checking exceptions
2025-05-26 19:37:39,603:INFO:Importing libraries
2025-05-26 19:37:39,603:INFO:Copying training dataset
2025-05-26 19:37:39,606:INFO:Defining folds
2025-05-26 19:37:39,606:INFO:Declaring metric variables
2025-05-26 19:37:39,606:INFO:Importing untrained model
2025-05-26 19:37:39,606:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-26 19:37:39,606:INFO:Starting cross validation
2025-05-26 19:37:39,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:40,492:INFO:Calculating mean and std
2025-05-26 19:37:40,493:INFO:Creating metrics dataframe
2025-05-26 19:37:40,494:INFO:Uploading results into container
2025-05-26 19:37:40,495:INFO:Uploading model into container now
2025-05-26 19:37:40,495:INFO:_master_model_container: 13
2025-05-26 19:37:40,495:INFO:_display_container: 2
2025-05-26 19:37:40,496:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=989, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-05-26 19:37:40,496:INFO:create_model() successfully completed......................................
2025-05-26 19:37:40,661:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:40,661:INFO:Creating metrics dataframe
2025-05-26 19:37:40,663:INFO:Initializing Dummy Classifier
2025-05-26 19:37:40,663:INFO:Total runtime is 0.21093014081319178 minutes
2025-05-26 19:37:40,664:INFO:SubProcess create_model() called ==================================
2025-05-26 19:37:40,664:INFO:Initializing create_model()
2025-05-26 19:37:40,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000142D2D25C50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:40,664:INFO:Checking exceptions
2025-05-26 19:37:40,664:INFO:Importing libraries
2025-05-26 19:37:40,664:INFO:Copying training dataset
2025-05-26 19:37:40,666:INFO:Defining folds
2025-05-26 19:37:40,666:INFO:Declaring metric variables
2025-05-26 19:37:40,666:INFO:Importing untrained model
2025-05-26 19:37:40,667:INFO:Dummy Classifier Imported successfully
2025-05-26 19:37:40,667:INFO:Starting cross validation
2025-05-26 19:37:40,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-26 19:37:40,761:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:40,762:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:40,764:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:40,766:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:40,767:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:40,768:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:40,770:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:40,774:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:40,775:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:40,777:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-26 19:37:40,786:INFO:Calculating mean and std
2025-05-26 19:37:40,786:INFO:Creating metrics dataframe
2025-05-26 19:37:40,788:INFO:Uploading results into container
2025-05-26 19:37:40,789:INFO:Uploading model into container now
2025-05-26 19:37:40,789:INFO:_master_model_container: 14
2025-05-26 19:37:40,789:INFO:_display_container: 2
2025-05-26 19:37:40,789:INFO:DummyClassifier(constant=None, random_state=989, strategy='prior')
2025-05-26 19:37:40,789:INFO:create_model() successfully completed......................................
2025-05-26 19:37:40,933:INFO:SubProcess create_model() end ==================================
2025-05-26 19:37:40,933:INFO:Creating metrics dataframe
2025-05-26 19:37:40,937:INFO:Initializing create_model()
2025-05-26 19:37:40,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=DummyClassifier(constant=None, random_state=989, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-26 19:37:40,937:INFO:Checking exceptions
2025-05-26 19:37:40,938:INFO:Importing libraries
2025-05-26 19:37:40,938:INFO:Copying training dataset
2025-05-26 19:37:40,941:INFO:Defining folds
2025-05-26 19:37:40,941:INFO:Declaring metric variables
2025-05-26 19:37:40,941:INFO:Importing untrained model
2025-05-26 19:37:40,941:INFO:Declaring custom model
2025-05-26 19:37:40,941:INFO:Dummy Classifier Imported successfully
2025-05-26 19:37:40,942:INFO:Cross validation set to False
2025-05-26 19:37:40,942:INFO:Fitting Model
2025-05-26 19:37:40,974:INFO:DummyClassifier(constant=None, random_state=989, strategy='prior')
2025-05-26 19:37:40,974:INFO:create_model() successfully completed......................................
2025-05-26 19:37:41,129:INFO:_master_model_container: 14
2025-05-26 19:37:41,129:INFO:_display_container: 2
2025-05-26 19:37:41,129:INFO:DummyClassifier(constant=None, random_state=989, strategy='prior')
2025-05-26 19:37:41,129:INFO:compare_models() successfully completed......................................
2025-05-26 19:37:41,130:INFO:Initializing evaluate_model()
2025-05-26 19:37:41,130:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=DummyClassifier(constant=None, random_state=989, strategy='prior'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-05-26 19:37:41,282:INFO:Initializing plot_model()
2025-05-26 19:37:41,282:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000142D2BC1290>, estimator=DummyClassifier(constant=None, random_state=989, strategy='prior'), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-05-26 19:37:41,282:INFO:Checking exceptions
2025-05-26 19:37:41,285:INFO:Preloading libraries
2025-05-26 19:37:41,285:INFO:Copying training dataset
2025-05-26 19:37:41,285:INFO:Plot type: pipeline
2025-05-26 21:08:10,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 21:08:10,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 21:08:10,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 21:08:10,199:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 21:09:30,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 21:09:30,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 21:09:30,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-26 21:09:30,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:19:19,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:19:19,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:19:19,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:19:19,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:38:31,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:38:31,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:38:31,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:38:31,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:41:55,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:41:55,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:41:55,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:41:55,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:42:47,415:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:42:47,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:42:47,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:42:47,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:42:52,786:INFO:PyCaret ClassificationExperiment
2025-06-02 19:42:52,786:INFO:Logging name: banking-autoML
2025-06-02 19:42:52,786:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-02 19:42:52,786:INFO:version 3.3.2
2025-06-02 19:42:52,786:INFO:Initializing setup()
2025-06-02 19:42:52,786:INFO:self.USI: 11f0
2025-06-02 19:42:52,787:INFO:self._variable_keys: {'_ml_usecase', 'exp_name_log', 'n_jobs_param', 'logging_param', 'X_test', 'fold_generator', 'data', 'fold_groups_param', 'idx', 'X', 'memory', 'USI', 'exp_id', 'log_plots_param', 'seed', 'y', 'html_param', 'gpu_param', 'target_param', 'fix_imbalance', '_available_plots', 'gpu_n_jobs_param', 'y_test', 'y_train', 'pipeline', 'is_multiclass', 'fold_shuffle_param', 'X_train'}
2025-06-02 19:42:52,787:INFO:Checking environment
2025-06-02 19:42:52,787:INFO:python_version: 3.11.9
2025-06-02 19:42:52,787:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-02 19:42:52,787:INFO:machine: AMD64
2025-06-02 19:42:52,806:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-02 19:42:52,816:INFO:Memory: svmem(total=33554628608, available=17947013120, percent=46.5, used=15607615488, free=17947013120)
2025-06-02 19:42:52,816:INFO:Physical Core: 6
2025-06-02 19:42:52,816:INFO:Logical Core: 12
2025-06-02 19:42:52,816:INFO:Checking libraries
2025-06-02 19:42:52,816:INFO:System:
2025-06-02 19:42:52,816:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-02 19:42:52,816:INFO:executable: C:\Users\amonreal\Documents\amlbash\.venv\Scripts\python.exe
2025-06-02 19:42:52,817:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-02 19:42:52,817:INFO:PyCaret required dependencies:
2025-06-02 19:42:53,021:INFO:                 pip: 24.0
2025-06-02 19:42:53,021:INFO:          setuptools: 65.5.0
2025-06-02 19:42:53,021:INFO:             pycaret: 3.3.2
2025-06-02 19:42:53,021:INFO:             IPython: 9.2.0
2025-06-02 19:42:53,021:INFO:          ipywidgets: 8.1.7
2025-06-02 19:42:53,021:INFO:                tqdm: 4.67.1
2025-06-02 19:42:53,022:INFO:               numpy: 1.26.4
2025-06-02 19:42:53,022:INFO:              pandas: 2.1.4
2025-06-02 19:42:53,022:INFO:              jinja2: 3.1.6
2025-06-02 19:42:53,022:INFO:               scipy: 1.11.4
2025-06-02 19:42:53,022:INFO:              joblib: 1.3.2
2025-06-02 19:42:53,022:INFO:             sklearn: 1.4.2
2025-06-02 19:42:53,022:INFO:                pyod: 2.0.5
2025-06-02 19:42:53,022:INFO:            imblearn: 0.13.0
2025-06-02 19:42:53,022:INFO:   category_encoders: 2.7.0
2025-06-02 19:42:53,022:INFO:            lightgbm: 4.6.0
2025-06-02 19:42:53,022:INFO:               numba: 0.61.2
2025-06-02 19:42:53,022:INFO:            requests: 2.32.3
2025-06-02 19:42:53,022:INFO:          matplotlib: 3.7.5
2025-06-02 19:42:53,022:INFO:          scikitplot: 0.3.7
2025-06-02 19:42:53,022:INFO:         yellowbrick: 1.5
2025-06-02 19:42:53,022:INFO:              plotly: 5.24.1
2025-06-02 19:42:53,022:INFO:    plotly-resampler: Not installed
2025-06-02 19:42:53,022:INFO:             kaleido: 0.2.1
2025-06-02 19:42:53,022:INFO:           schemdraw: 0.15
2025-06-02 19:42:53,022:INFO:         statsmodels: 0.14.4
2025-06-02 19:42:53,022:INFO:              sktime: 0.26.0
2025-06-02 19:42:53,022:INFO:               tbats: 1.1.3
2025-06-02 19:42:53,022:INFO:            pmdarima: 2.0.4
2025-06-02 19:42:53,022:INFO:              psutil: 7.0.0
2025-06-02 19:42:53,022:INFO:          markupsafe: 3.0.2
2025-06-02 19:42:53,022:INFO:             pickle5: Not installed
2025-06-02 19:42:53,022:INFO:         cloudpickle: 3.1.1
2025-06-02 19:42:53,022:INFO:         deprecation: 2.1.0
2025-06-02 19:42:53,022:INFO:              xxhash: 3.5.0
2025-06-02 19:42:53,022:INFO:           wurlitzer: Not installed
2025-06-02 19:42:53,022:INFO:PyCaret optional dependencies:
2025-06-02 19:42:53,606:INFO:                shap: Not installed
2025-06-02 19:42:53,607:INFO:           interpret: Not installed
2025-06-02 19:42:53,607:INFO:                umap: Not installed
2025-06-02 19:42:53,607:INFO:     ydata_profiling: Not installed
2025-06-02 19:42:53,607:INFO:  explainerdashboard: Not installed
2025-06-02 19:42:53,607:INFO:             autoviz: Not installed
2025-06-02 19:42:53,607:INFO:           fairlearn: Not installed
2025-06-02 19:42:53,607:INFO:          deepchecks: Not installed
2025-06-02 19:42:53,607:INFO:             xgboost: Not installed
2025-06-02 19:42:53,607:INFO:            catboost: Not installed
2025-06-02 19:42:53,607:INFO:              kmodes: Not installed
2025-06-02 19:42:53,607:INFO:             mlxtend: Not installed
2025-06-02 19:42:53,607:INFO:       statsforecast: Not installed
2025-06-02 19:42:53,607:INFO:        tune_sklearn: Not installed
2025-06-02 19:42:53,607:INFO:                 ray: Not installed
2025-06-02 19:42:53,607:INFO:            hyperopt: Not installed
2025-06-02 19:42:53,607:INFO:              optuna: Not installed
2025-06-02 19:42:53,607:INFO:               skopt: Not installed
2025-06-02 19:42:53,607:INFO:              mlflow: 2.22.0
2025-06-02 19:42:53,607:INFO:              gradio: Not installed
2025-06-02 19:42:53,607:INFO:             fastapi: 0.115.12
2025-06-02 19:42:53,607:INFO:             uvicorn: 0.34.2
2025-06-02 19:42:53,607:INFO:              m2cgen: Not installed
2025-06-02 19:42:53,607:INFO:           evidently: Not installed
2025-06-02 19:42:53,607:INFO:               fugue: Not installed
2025-06-02 19:42:53,607:INFO:           streamlit: Not installed
2025-06-02 19:42:53,607:INFO:             prophet: Not installed
2025-06-02 19:42:53,607:INFO:None
2025-06-02 19:42:53,607:INFO:Set up data.
2025-06-02 19:42:53,627:INFO:Set up folding strategy.
2025-06-02 19:42:53,627:INFO:Set up train/test split.
2025-06-02 19:42:53,644:INFO:Set up index.
2025-06-02 19:42:53,645:INFO:Assigning column types.
2025-06-02 19:42:53,648:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 19:42:53,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:42:53,699:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:42:53,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:53,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:53,815:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:42:53,816:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:42:53,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:53,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:53,838:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 19:42:53,872:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:42:53,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:53,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:53,935:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:42:53,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:53,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:53,958:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-02 19:42:54,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:54,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:54,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:54,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:54,073:INFO:Preparing preprocessing pipeline...
2025-06-02 19:42:54,078:INFO:Set up simple imputation.
2025-06-02 19:42:54,080:INFO:Set up encoding of categorical features.
2025-06-02 19:42:54,146:INFO:Finished creating preprocessing pipeline.
2025-06-02 19:42:54,155:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['segmento', 'rango_ingresos',
                                             'region'],
                                    transformer=OneHotEncoder(cols=['segmento',
                                                                    'rango_ingresos',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-06-02 19:42:54,156:INFO:Creating final display dataframe.
2025-06-02 19:42:54,325:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target   cerrara_cuenta
2                   Target type           Binary
3           Original data shape       (2000, 13)
4        Transformed data shape       (2000, 20)
5   Transformed train set shape       (1400, 20)
6    Transformed test set shape        (600, 20)
7              Numeric features                9
8          Categorical features                3
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name   banking-autoML
21                          USI             11f0
2025-06-02 19:42:54,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:54,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:54,485:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:54,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:42:54,486:INFO:Logging experiment in loggers
2025-06-02 19:45:14,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:45:14,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:45:14,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:45:14,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:45:19,754:INFO:PyCaret ClassificationExperiment
2025-06-02 19:45:19,755:INFO:Logging name: banking-autoML
2025-06-02 19:45:19,755:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-02 19:45:19,755:INFO:version 3.3.2
2025-06-02 19:45:19,755:INFO:Initializing setup()
2025-06-02 19:45:19,755:INFO:self.USI: 98ca
2025-06-02 19:45:19,755:INFO:self._variable_keys: {'exp_name_log', 'logging_param', 'fold_groups_param', 'USI', 'fold_generator', 'memory', 'y_test', 'idx', 'html_param', 'n_jobs_param', 'X', 'y_train', 'X_test', 'pipeline', 'exp_id', 'log_plots_param', '_available_plots', 'y', 'data', 'X_train', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'is_multiclass', 'gpu_n_jobs_param', 'seed', 'target_param', 'gpu_param'}
2025-06-02 19:45:19,755:INFO:Checking environment
2025-06-02 19:45:19,755:INFO:python_version: 3.11.9
2025-06-02 19:45:19,755:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-02 19:45:19,755:INFO:machine: AMD64
2025-06-02 19:45:19,776:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-02 19:45:19,784:INFO:Memory: svmem(total=33554628608, available=17879011328, percent=46.7, used=15675617280, free=17879011328)
2025-06-02 19:45:19,784:INFO:Physical Core: 6
2025-06-02 19:45:19,784:INFO:Logical Core: 12
2025-06-02 19:45:19,785:INFO:Checking libraries
2025-06-02 19:45:19,785:INFO:System:
2025-06-02 19:45:19,785:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-02 19:45:19,785:INFO:executable: C:\Users\amonreal\Documents\amlbash\.venv\Scripts\python.exe
2025-06-02 19:45:19,785:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-02 19:45:19,785:INFO:PyCaret required dependencies:
2025-06-02 19:45:19,854:INFO:                 pip: 24.0
2025-06-02 19:45:19,855:INFO:          setuptools: 65.5.0
2025-06-02 19:45:19,855:INFO:             pycaret: 3.3.2
2025-06-02 19:45:19,855:INFO:             IPython: 9.2.0
2025-06-02 19:45:19,855:INFO:          ipywidgets: 8.1.7
2025-06-02 19:45:19,855:INFO:                tqdm: 4.67.1
2025-06-02 19:45:19,855:INFO:               numpy: 1.26.4
2025-06-02 19:45:19,855:INFO:              pandas: 2.1.4
2025-06-02 19:45:19,855:INFO:              jinja2: 3.1.6
2025-06-02 19:45:19,855:INFO:               scipy: 1.11.4
2025-06-02 19:45:19,855:INFO:              joblib: 1.3.2
2025-06-02 19:45:19,855:INFO:             sklearn: 1.4.2
2025-06-02 19:45:19,855:INFO:                pyod: 2.0.5
2025-06-02 19:45:19,855:INFO:            imblearn: 0.13.0
2025-06-02 19:45:19,855:INFO:   category_encoders: 2.7.0
2025-06-02 19:45:19,855:INFO:            lightgbm: 4.6.0
2025-06-02 19:45:19,855:INFO:               numba: 0.61.2
2025-06-02 19:45:19,855:INFO:            requests: 2.32.3
2025-06-02 19:45:19,855:INFO:          matplotlib: 3.7.5
2025-06-02 19:45:19,855:INFO:          scikitplot: 0.3.7
2025-06-02 19:45:19,855:INFO:         yellowbrick: 1.5
2025-06-02 19:45:19,855:INFO:              plotly: 5.24.1
2025-06-02 19:45:19,855:INFO:    plotly-resampler: Not installed
2025-06-02 19:45:19,855:INFO:             kaleido: 0.2.1
2025-06-02 19:45:19,855:INFO:           schemdraw: 0.15
2025-06-02 19:45:19,855:INFO:         statsmodels: 0.14.4
2025-06-02 19:45:19,855:INFO:              sktime: 0.26.0
2025-06-02 19:45:19,855:INFO:               tbats: 1.1.3
2025-06-02 19:45:19,855:INFO:            pmdarima: 2.0.4
2025-06-02 19:45:19,855:INFO:              psutil: 7.0.0
2025-06-02 19:45:19,855:INFO:          markupsafe: 3.0.2
2025-06-02 19:45:19,855:INFO:             pickle5: Not installed
2025-06-02 19:45:19,855:INFO:         cloudpickle: 3.1.1
2025-06-02 19:45:19,855:INFO:         deprecation: 2.1.0
2025-06-02 19:45:19,855:INFO:              xxhash: 3.5.0
2025-06-02 19:45:19,855:INFO:           wurlitzer: Not installed
2025-06-02 19:45:19,856:INFO:PyCaret optional dependencies:
2025-06-02 19:45:20,161:INFO:                shap: Not installed
2025-06-02 19:45:20,161:INFO:           interpret: Not installed
2025-06-02 19:45:20,161:INFO:                umap: Not installed
2025-06-02 19:45:20,161:INFO:     ydata_profiling: Not installed
2025-06-02 19:45:20,161:INFO:  explainerdashboard: Not installed
2025-06-02 19:45:20,161:INFO:             autoviz: Not installed
2025-06-02 19:45:20,161:INFO:           fairlearn: Not installed
2025-06-02 19:45:20,161:INFO:          deepchecks: Not installed
2025-06-02 19:45:20,161:INFO:             xgboost: Not installed
2025-06-02 19:45:20,161:INFO:            catboost: Not installed
2025-06-02 19:45:20,161:INFO:              kmodes: Not installed
2025-06-02 19:45:20,161:INFO:             mlxtend: Not installed
2025-06-02 19:45:20,161:INFO:       statsforecast: Not installed
2025-06-02 19:45:20,162:INFO:        tune_sklearn: Not installed
2025-06-02 19:45:20,162:INFO:                 ray: Not installed
2025-06-02 19:45:20,162:INFO:            hyperopt: Not installed
2025-06-02 19:45:20,162:INFO:              optuna: Not installed
2025-06-02 19:45:20,162:INFO:               skopt: Not installed
2025-06-02 19:45:20,162:INFO:              mlflow: 2.22.0
2025-06-02 19:45:20,162:INFO:              gradio: Not installed
2025-06-02 19:45:20,162:INFO:             fastapi: 0.115.12
2025-06-02 19:45:20,162:INFO:             uvicorn: 0.34.2
2025-06-02 19:45:20,162:INFO:              m2cgen: Not installed
2025-06-02 19:45:20,162:INFO:           evidently: Not installed
2025-06-02 19:45:20,162:INFO:               fugue: Not installed
2025-06-02 19:45:20,162:INFO:           streamlit: Not installed
2025-06-02 19:45:20,162:INFO:             prophet: Not installed
2025-06-02 19:45:20,162:INFO:None
2025-06-02 19:45:20,162:INFO:Set up data.
2025-06-02 19:45:20,170:INFO:Set up folding strategy.
2025-06-02 19:45:20,170:INFO:Set up train/test split.
2025-06-02 19:45:20,178:INFO:Set up index.
2025-06-02 19:45:20,178:INFO:Assigning column types.
2025-06-02 19:45:20,181:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 19:45:20,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:45:20,222:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:45:20,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,289:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:45:20,290:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:45:20,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,314:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 19:45:20,348:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:45:20,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,406:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:45:20,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,434:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-02 19:45:20,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,552:INFO:Preparing preprocessing pipeline...
2025-06-02 19:45:20,552:INFO:Set up simple imputation.
2025-06-02 19:45:20,556:INFO:Set up encoding of categorical features.
2025-06-02 19:45:20,609:INFO:Finished creating preprocessing pipeline.
2025-06-02 19:45:20,614:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['segmento', 'rango_ingresos',
                                             'region'],
                                    transformer=OneHotEncoder(cols=['segmento',
                                                                    'rango_ingresos',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-06-02 19:45:20,614:INFO:Creating final display dataframe.
2025-06-02 19:45:20,796:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target   cerrara_cuenta
2                   Target type           Binary
3           Original data shape       (2000, 13)
4        Transformed data shape       (2000, 20)
5   Transformed train set shape       (1400, 20)
6    Transformed test set shape        (600, 20)
7              Numeric features                9
8          Categorical features                3
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment     MlflowLogger
20              Experiment Name   banking-autoML
21                          USI             98ca
2025-06-02 19:45:20,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:20,944:INFO:Logging experiment in loggers
2025-06-02 19:45:40,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:45:40,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:45:40,539:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:45:40,539:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:45:45,689:INFO:PyCaret ClassificationExperiment
2025-06-02 19:45:45,689:INFO:Logging name: banking-autoML
2025-06-02 19:45:45,689:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-02 19:45:45,689:INFO:version 3.3.2
2025-06-02 19:45:45,689:INFO:Initializing setup()
2025-06-02 19:45:45,689:INFO:self.USI: a781
2025-06-02 19:45:45,689:INFO:self._variable_keys: {'gpu_param', 'X', 'pipeline', 'y_test', 'seed', 'data', 'fold_shuffle_param', '_available_plots', 'log_plots_param', 'idx', 'exp_name_log', 'fix_imbalance', 'memory', 'X_test', 'y_train', 'gpu_n_jobs_param', 'fold_generator', 'logging_param', 'html_param', 'target_param', 'USI', 'X_train', '_ml_usecase', 'y', 'is_multiclass', 'fold_groups_param', 'exp_id', 'n_jobs_param'}
2025-06-02 19:45:45,689:INFO:Checking environment
2025-06-02 19:45:45,689:INFO:python_version: 3.11.9
2025-06-02 19:45:45,689:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-02 19:45:45,689:INFO:machine: AMD64
2025-06-02 19:45:45,707:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-02 19:45:45,714:INFO:Memory: svmem(total=33554628608, available=17914224640, percent=46.6, used=15640403968, free=17914224640)
2025-06-02 19:45:45,714:INFO:Physical Core: 6
2025-06-02 19:45:45,714:INFO:Logical Core: 12
2025-06-02 19:45:45,714:INFO:Checking libraries
2025-06-02 19:45:45,714:INFO:System:
2025-06-02 19:45:45,714:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-02 19:45:45,714:INFO:executable: C:\Users\amonreal\Documents\amlbash\.venv\Scripts\python.exe
2025-06-02 19:45:45,714:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-02 19:45:45,714:INFO:PyCaret required dependencies:
2025-06-02 19:45:45,771:INFO:                 pip: 24.0
2025-06-02 19:45:45,771:INFO:          setuptools: 65.5.0
2025-06-02 19:45:45,771:INFO:             pycaret: 3.3.2
2025-06-02 19:45:45,771:INFO:             IPython: 9.2.0
2025-06-02 19:45:45,771:INFO:          ipywidgets: 8.1.7
2025-06-02 19:45:45,771:INFO:                tqdm: 4.67.1
2025-06-02 19:45:45,771:INFO:               numpy: 1.26.4
2025-06-02 19:45:45,771:INFO:              pandas: 2.1.4
2025-06-02 19:45:45,771:INFO:              jinja2: 3.1.6
2025-06-02 19:45:45,771:INFO:               scipy: 1.11.4
2025-06-02 19:45:45,771:INFO:              joblib: 1.3.2
2025-06-02 19:45:45,771:INFO:             sklearn: 1.4.2
2025-06-02 19:45:45,771:INFO:                pyod: 2.0.5
2025-06-02 19:45:45,771:INFO:            imblearn: 0.13.0
2025-06-02 19:45:45,771:INFO:   category_encoders: 2.7.0
2025-06-02 19:45:45,771:INFO:            lightgbm: 4.6.0
2025-06-02 19:45:45,771:INFO:               numba: 0.61.2
2025-06-02 19:45:45,771:INFO:            requests: 2.32.3
2025-06-02 19:45:45,771:INFO:          matplotlib: 3.7.5
2025-06-02 19:45:45,771:INFO:          scikitplot: 0.3.7
2025-06-02 19:45:45,771:INFO:         yellowbrick: 1.5
2025-06-02 19:45:45,771:INFO:              plotly: 5.24.1
2025-06-02 19:45:45,771:INFO:    plotly-resampler: Not installed
2025-06-02 19:45:45,771:INFO:             kaleido: 0.2.1
2025-06-02 19:45:45,771:INFO:           schemdraw: 0.15
2025-06-02 19:45:45,771:INFO:         statsmodels: 0.14.4
2025-06-02 19:45:45,771:INFO:              sktime: 0.26.0
2025-06-02 19:45:45,771:INFO:               tbats: 1.1.3
2025-06-02 19:45:45,771:INFO:            pmdarima: 2.0.4
2025-06-02 19:45:45,771:INFO:              psutil: 7.0.0
2025-06-02 19:45:45,771:INFO:          markupsafe: 3.0.2
2025-06-02 19:45:45,771:INFO:             pickle5: Not installed
2025-06-02 19:45:45,771:INFO:         cloudpickle: 3.1.1
2025-06-02 19:45:45,771:INFO:         deprecation: 2.1.0
2025-06-02 19:45:45,771:INFO:              xxhash: 3.5.0
2025-06-02 19:45:45,771:INFO:           wurlitzer: Not installed
2025-06-02 19:45:45,771:INFO:PyCaret optional dependencies:
2025-06-02 19:45:46,044:INFO:                shap: Not installed
2025-06-02 19:45:46,044:INFO:           interpret: Not installed
2025-06-02 19:45:46,044:INFO:                umap: Not installed
2025-06-02 19:45:46,044:INFO:     ydata_profiling: Not installed
2025-06-02 19:45:46,044:INFO:  explainerdashboard: Not installed
2025-06-02 19:45:46,044:INFO:             autoviz: Not installed
2025-06-02 19:45:46,044:INFO:           fairlearn: Not installed
2025-06-02 19:45:46,044:INFO:          deepchecks: Not installed
2025-06-02 19:45:46,044:INFO:             xgboost: Not installed
2025-06-02 19:45:46,044:INFO:            catboost: Not installed
2025-06-02 19:45:46,044:INFO:              kmodes: Not installed
2025-06-02 19:45:46,044:INFO:             mlxtend: Not installed
2025-06-02 19:45:46,044:INFO:       statsforecast: Not installed
2025-06-02 19:45:46,044:INFO:        tune_sklearn: Not installed
2025-06-02 19:45:46,045:INFO:                 ray: Not installed
2025-06-02 19:45:46,045:INFO:            hyperopt: Not installed
2025-06-02 19:45:46,045:INFO:              optuna: Not installed
2025-06-02 19:45:46,045:INFO:               skopt: Not installed
2025-06-02 19:45:46,045:INFO:              mlflow: 2.22.0
2025-06-02 19:45:46,045:INFO:              gradio: Not installed
2025-06-02 19:45:46,045:INFO:             fastapi: 0.115.12
2025-06-02 19:45:46,045:INFO:             uvicorn: 0.34.2
2025-06-02 19:45:46,045:INFO:              m2cgen: Not installed
2025-06-02 19:45:46,045:INFO:           evidently: Not installed
2025-06-02 19:45:46,045:INFO:               fugue: Not installed
2025-06-02 19:45:46,045:INFO:           streamlit: Not installed
2025-06-02 19:45:46,045:INFO:             prophet: Not installed
2025-06-02 19:45:46,045:INFO:None
2025-06-02 19:45:46,045:INFO:Set up data.
2025-06-02 19:45:46,051:INFO:Set up folding strategy.
2025-06-02 19:45:46,052:INFO:Set up train/test split.
2025-06-02 19:45:46,057:INFO:Set up index.
2025-06-02 19:45:46,057:INFO:Assigning column types.
2025-06-02 19:45:46,061:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 19:45:46,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:45:46,099:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:45:46,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,128:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,161:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:45:46,162:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:45:46,209:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,209:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,209:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 19:45:46,245:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:45:46,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,267:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,320:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:45:46,349:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,350:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-02 19:45:46,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,465:INFO:Preparing preprocessing pipeline...
2025-06-02 19:45:46,466:INFO:Set up simple imputation.
2025-06-02 19:45:46,469:INFO:Set up encoding of categorical features.
2025-06-02 19:45:46,516:INFO:Finished creating preprocessing pipeline.
2025-06-02 19:45:46,521:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['segmento', 'rango_ingresos',
                                             'region'],
                                    transformer=OneHotEncoder(cols=['segmento',
                                                                    'rango_ingresos',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-06-02 19:45:46,521:INFO:Creating final display dataframe.
2025-06-02 19:45:46,743:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target   cerrara_cuenta
2                   Target type           Binary
3           Original data shape       (2000, 13)
4        Transformed data shape       (2000, 20)
5   Transformed train set shape       (1400, 20)
6    Transformed test set shape        (600, 20)
7              Numeric features                9
8          Categorical features                3
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment            False
20              Experiment Name   banking-autoML
21                          USI             a781
2025-06-02 19:45:46,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,919:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:45:46,921:INFO:setup() successfully completed in 1.24s...............
2025-06-02 19:45:46,921:INFO:Initializing compare_models()
2025-06-02 19:45:46,921:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-02 19:45:46,921:INFO:Checking exceptions
2025-06-02 19:45:46,925:INFO:Preparing display monitor
2025-06-02 19:45:46,929:INFO:Initializing Logistic Regression
2025-06-02 19:45:46,929:INFO:Total runtime is 0.0 minutes
2025-06-02 19:45:46,929:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:46,930:INFO:Initializing create_model()
2025-06-02 19:45:46,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:46,930:INFO:Checking exceptions
2025-06-02 19:45:46,930:INFO:Importing libraries
2025-06-02 19:45:46,930:INFO:Copying training dataset
2025-06-02 19:45:46,935:INFO:Defining folds
2025-06-02 19:45:46,935:INFO:Declaring metric variables
2025-06-02 19:45:46,936:INFO:Importing untrained model
2025-06-02 19:45:46,936:INFO:Logistic Regression Imported successfully
2025-06-02 19:45:46,936:INFO:Starting cross validation
2025-06-02 19:45:46,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:51,744:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:45:51,771:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:45:51,785:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:51,806:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:45:51,806:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:51,832:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:45:51,840:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:51,866:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:45:51,870:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:51,902:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:45:51,905:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:51,906:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:45:51,937:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:51,938:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:45:51,938:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:51,962:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:45:51,970:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:51,994:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:52,032:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:45:52,058:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:52,071:INFO:Calculating mean and std
2025-06-02 19:45:52,072:INFO:Creating metrics dataframe
2025-06-02 19:45:52,075:INFO:Uploading results into container
2025-06-02 19:45:52,075:INFO:Uploading model into container now
2025-06-02 19:45:52,076:INFO:_master_model_container: 1
2025-06-02 19:45:52,076:INFO:_display_container: 2
2025-06-02 19:45:52,076:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:45:52,076:INFO:create_model() successfully completed......................................
2025-06-02 19:45:52,222:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:52,222:INFO:Creating metrics dataframe
2025-06-02 19:45:52,223:INFO:Initializing K Neighbors Classifier
2025-06-02 19:45:52,223:INFO:Total runtime is 0.08823755582173666 minutes
2025-06-02 19:45:52,223:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:52,223:INFO:Initializing create_model()
2025-06-02 19:45:52,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:52,224:INFO:Checking exceptions
2025-06-02 19:45:52,224:INFO:Importing libraries
2025-06-02 19:45:52,224:INFO:Copying training dataset
2025-06-02 19:45:52,227:INFO:Defining folds
2025-06-02 19:45:52,227:INFO:Declaring metric variables
2025-06-02 19:45:52,227:INFO:Importing untrained model
2025-06-02 19:45:52,229:INFO:K Neighbors Classifier Imported successfully
2025-06-02 19:45:52,230:INFO:Starting cross validation
2025-06-02 19:45:52,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:55,124:INFO:Calculating mean and std
2025-06-02 19:45:55,124:INFO:Creating metrics dataframe
2025-06-02 19:45:55,126:INFO:Uploading results into container
2025-06-02 19:45:55,127:INFO:Uploading model into container now
2025-06-02 19:45:55,127:INFO:_master_model_container: 2
2025-06-02 19:45:55,127:INFO:_display_container: 2
2025-06-02 19:45:55,128:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-02 19:45:55,128:INFO:create_model() successfully completed......................................
2025-06-02 19:45:55,268:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:55,268:INFO:Creating metrics dataframe
2025-06-02 19:45:55,271:INFO:Initializing Naive Bayes
2025-06-02 19:45:55,271:INFO:Total runtime is 0.1390394965807597 minutes
2025-06-02 19:45:55,271:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:55,272:INFO:Initializing create_model()
2025-06-02 19:45:55,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:55,272:INFO:Checking exceptions
2025-06-02 19:45:55,272:INFO:Importing libraries
2025-06-02 19:45:55,272:INFO:Copying training dataset
2025-06-02 19:45:55,277:INFO:Defining folds
2025-06-02 19:45:55,277:INFO:Declaring metric variables
2025-06-02 19:45:55,277:INFO:Importing untrained model
2025-06-02 19:45:55,277:INFO:Naive Bayes Imported successfully
2025-06-02 19:45:55,277:INFO:Starting cross validation
2025-06-02 19:45:55,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:55,392:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:55,392:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:55,394:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:55,402:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:55,403:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:55,406:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:55,409:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:55,410:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:55,410:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:55,413:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:55,423:INFO:Calculating mean and std
2025-06-02 19:45:55,423:INFO:Creating metrics dataframe
2025-06-02 19:45:55,425:INFO:Uploading results into container
2025-06-02 19:45:55,425:INFO:Uploading model into container now
2025-06-02 19:45:55,425:INFO:_master_model_container: 3
2025-06-02 19:45:55,425:INFO:_display_container: 2
2025-06-02 19:45:55,426:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-02 19:45:55,426:INFO:create_model() successfully completed......................................
2025-06-02 19:45:55,569:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:55,569:INFO:Creating metrics dataframe
2025-06-02 19:45:55,571:INFO:Initializing Decision Tree Classifier
2025-06-02 19:45:55,571:INFO:Total runtime is 0.14403425852457685 minutes
2025-06-02 19:45:55,571:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:55,571:INFO:Initializing create_model()
2025-06-02 19:45:55,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:55,571:INFO:Checking exceptions
2025-06-02 19:45:55,571:INFO:Importing libraries
2025-06-02 19:45:55,571:INFO:Copying training dataset
2025-06-02 19:45:55,575:INFO:Defining folds
2025-06-02 19:45:55,575:INFO:Declaring metric variables
2025-06-02 19:45:55,576:INFO:Importing untrained model
2025-06-02 19:45:55,577:INFO:Decision Tree Classifier Imported successfully
2025-06-02 19:45:55,577:INFO:Starting cross validation
2025-06-02 19:45:55,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:55,717:INFO:Calculating mean and std
2025-06-02 19:45:55,718:INFO:Creating metrics dataframe
2025-06-02 19:45:55,719:INFO:Uploading results into container
2025-06-02 19:45:55,720:INFO:Uploading model into container now
2025-06-02 19:45:55,720:INFO:_master_model_container: 4
2025-06-02 19:45:55,720:INFO:_display_container: 2
2025-06-02 19:45:55,720:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-06-02 19:45:55,721:INFO:create_model() successfully completed......................................
2025-06-02 19:45:55,861:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:55,861:INFO:Creating metrics dataframe
2025-06-02 19:45:55,864:INFO:Initializing SVM - Linear Kernel
2025-06-02 19:45:55,864:INFO:Total runtime is 0.14890783230463667 minutes
2025-06-02 19:45:55,864:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:55,864:INFO:Initializing create_model()
2025-06-02 19:45:55,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:55,864:INFO:Checking exceptions
2025-06-02 19:45:55,864:INFO:Importing libraries
2025-06-02 19:45:55,864:INFO:Copying training dataset
2025-06-02 19:45:55,868:INFO:Defining folds
2025-06-02 19:45:55,868:INFO:Declaring metric variables
2025-06-02 19:45:55,869:INFO:Importing untrained model
2025-06-02 19:45:55,870:INFO:SVM - Linear Kernel Imported successfully
2025-06-02 19:45:55,870:INFO:Starting cross validation
2025-06-02 19:45:55,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:56,006:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,009:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,031:INFO:Calculating mean and std
2025-06-02 19:45:56,032:INFO:Creating metrics dataframe
2025-06-02 19:45:56,034:INFO:Uploading results into container
2025-06-02 19:45:56,034:INFO:Uploading model into container now
2025-06-02 19:45:56,035:INFO:_master_model_container: 5
2025-06-02 19:45:56,035:INFO:_display_container: 2
2025-06-02 19:45:56,035:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-02 19:45:56,035:INFO:create_model() successfully completed......................................
2025-06-02 19:45:56,178:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:56,178:INFO:Creating metrics dataframe
2025-06-02 19:45:56,180:INFO:Initializing Ridge Classifier
2025-06-02 19:45:56,180:INFO:Total runtime is 0.15418447653452558 minutes
2025-06-02 19:45:56,180:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:56,180:INFO:Initializing create_model()
2025-06-02 19:45:56,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:56,180:INFO:Checking exceptions
2025-06-02 19:45:56,180:INFO:Importing libraries
2025-06-02 19:45:56,180:INFO:Copying training dataset
2025-06-02 19:45:56,185:INFO:Defining folds
2025-06-02 19:45:56,185:INFO:Declaring metric variables
2025-06-02 19:45:56,185:INFO:Importing untrained model
2025-06-02 19:45:56,186:INFO:Ridge Classifier Imported successfully
2025-06-02 19:45:56,187:INFO:Starting cross validation
2025-06-02 19:45:56,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:56,308:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,308:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,314:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,316:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,317:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,318:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,319:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,319:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,324:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,328:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,339:INFO:Calculating mean and std
2025-06-02 19:45:56,340:INFO:Creating metrics dataframe
2025-06-02 19:45:56,342:INFO:Uploading results into container
2025-06-02 19:45:56,342:INFO:Uploading model into container now
2025-06-02 19:45:56,342:INFO:_master_model_container: 6
2025-06-02 19:45:56,342:INFO:_display_container: 2
2025-06-02 19:45:56,343:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-06-02 19:45:56,343:INFO:create_model() successfully completed......................................
2025-06-02 19:45:56,494:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:56,494:INFO:Creating metrics dataframe
2025-06-02 19:45:56,498:INFO:Initializing Random Forest Classifier
2025-06-02 19:45:56,498:INFO:Total runtime is 0.1594874461491903 minutes
2025-06-02 19:45:56,498:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:56,498:INFO:Initializing create_model()
2025-06-02 19:45:56,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:56,498:INFO:Checking exceptions
2025-06-02 19:45:56,499:INFO:Importing libraries
2025-06-02 19:45:56,499:INFO:Copying training dataset
2025-06-02 19:45:56,502:INFO:Defining folds
2025-06-02 19:45:56,502:INFO:Declaring metric variables
2025-06-02 19:45:56,503:INFO:Importing untrained model
2025-06-02 19:45:56,505:INFO:Random Forest Classifier Imported successfully
2025-06-02 19:45:56,505:INFO:Starting cross validation
2025-06-02 19:45:56,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:56,979:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:56,982:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:57,008:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:57,020:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:57,040:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:57,040:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:57,139:INFO:Calculating mean and std
2025-06-02 19:45:57,140:INFO:Creating metrics dataframe
2025-06-02 19:45:57,142:INFO:Uploading results into container
2025-06-02 19:45:57,142:INFO:Uploading model into container now
2025-06-02 19:45:57,142:INFO:_master_model_container: 7
2025-06-02 19:45:57,142:INFO:_display_container: 2
2025-06-02 19:45:57,143:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-06-02 19:45:57,143:INFO:create_model() successfully completed......................................
2025-06-02 19:45:57,297:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:57,298:INFO:Creating metrics dataframe
2025-06-02 19:45:57,299:INFO:Initializing Quadratic Discriminant Analysis
2025-06-02 19:45:57,300:INFO:Total runtime is 0.1728492657343547 minutes
2025-06-02 19:45:57,300:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:57,300:INFO:Initializing create_model()
2025-06-02 19:45:57,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:57,300:INFO:Checking exceptions
2025-06-02 19:45:57,300:INFO:Importing libraries
2025-06-02 19:45:57,300:INFO:Copying training dataset
2025-06-02 19:45:57,304:INFO:Defining folds
2025-06-02 19:45:57,304:INFO:Declaring metric variables
2025-06-02 19:45:57,305:INFO:Importing untrained model
2025-06-02 19:45:57,306:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-02 19:45:57,306:INFO:Starting cross validation
2025-06-02 19:45:57,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:57,404:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:45:57,405:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:45:57,405:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:45:57,407:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:45:57,408:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:45:57,409:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:45:57,411:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:45:57,413:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:45:57,416:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:45:57,418:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:45:57,440:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:57,459:INFO:Calculating mean and std
2025-06-02 19:45:57,460:INFO:Creating metrics dataframe
2025-06-02 19:45:57,461:INFO:Uploading results into container
2025-06-02 19:45:57,462:INFO:Uploading model into container now
2025-06-02 19:45:57,462:INFO:_master_model_container: 8
2025-06-02 19:45:57,462:INFO:_display_container: 2
2025-06-02 19:45:57,462:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-02 19:45:57,463:INFO:create_model() successfully completed......................................
2025-06-02 19:45:57,608:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:57,608:INFO:Creating metrics dataframe
2025-06-02 19:45:57,611:INFO:Initializing Ada Boost Classifier
2025-06-02 19:45:57,611:INFO:Total runtime is 0.17803230285644533 minutes
2025-06-02 19:45:57,612:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:57,612:INFO:Initializing create_model()
2025-06-02 19:45:57,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:57,612:INFO:Checking exceptions
2025-06-02 19:45:57,612:INFO:Importing libraries
2025-06-02 19:45:57,612:INFO:Copying training dataset
2025-06-02 19:45:57,616:INFO:Defining folds
2025-06-02 19:45:57,617:INFO:Declaring metric variables
2025-06-02 19:45:57,617:INFO:Importing untrained model
2025-06-02 19:45:57,618:INFO:Ada Boost Classifier Imported successfully
2025-06-02 19:45:57,618:INFO:Starting cross validation
2025-06-02 19:45:57,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:57,698:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-02 19:45:57,698:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-02 19:45:57,699:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-02 19:45:57,700:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-02 19:45:57,704:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-02 19:45:57,704:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-02 19:45:57,706:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-02 19:45:57,706:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-02 19:45:57,707:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-02 19:45:57,713:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-02 19:45:57,892:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:57,902:INFO:Calculating mean and std
2025-06-02 19:45:57,902:INFO:Creating metrics dataframe
2025-06-02 19:45:57,904:INFO:Uploading results into container
2025-06-02 19:45:57,904:INFO:Uploading model into container now
2025-06-02 19:45:57,904:INFO:_master_model_container: 9
2025-06-02 19:45:57,904:INFO:_display_container: 2
2025-06-02 19:45:57,905:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-06-02 19:45:57,905:INFO:create_model() successfully completed......................................
2025-06-02 19:45:58,045:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:58,045:INFO:Creating metrics dataframe
2025-06-02 19:45:58,051:INFO:Initializing Gradient Boosting Classifier
2025-06-02 19:45:58,051:INFO:Total runtime is 0.18537027835845948 minutes
2025-06-02 19:45:58,051:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:58,052:INFO:Initializing create_model()
2025-06-02 19:45:58,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:58,052:INFO:Checking exceptions
2025-06-02 19:45:58,052:INFO:Importing libraries
2025-06-02 19:45:58,052:INFO:Copying training dataset
2025-06-02 19:45:58,058:INFO:Defining folds
2025-06-02 19:45:58,058:INFO:Declaring metric variables
2025-06-02 19:45:58,059:INFO:Importing untrained model
2025-06-02 19:45:58,059:INFO:Gradient Boosting Classifier Imported successfully
2025-06-02 19:45:58,059:INFO:Starting cross validation
2025-06-02 19:45:58,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:58,511:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,522:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,537:INFO:Calculating mean and std
2025-06-02 19:45:58,537:INFO:Creating metrics dataframe
2025-06-02 19:45:58,538:INFO:Uploading results into container
2025-06-02 19:45:58,539:INFO:Uploading model into container now
2025-06-02 19:45:58,539:INFO:_master_model_container: 10
2025-06-02 19:45:58,539:INFO:_display_container: 2
2025-06-02 19:45:58,539:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-02 19:45:58,539:INFO:create_model() successfully completed......................................
2025-06-02 19:45:58,678:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:58,678:INFO:Creating metrics dataframe
2025-06-02 19:45:58,680:INFO:Initializing Linear Discriminant Analysis
2025-06-02 19:45:58,680:INFO:Total runtime is 0.1958515803019206 minutes
2025-06-02 19:45:58,680:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:58,680:INFO:Initializing create_model()
2025-06-02 19:45:58,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:58,680:INFO:Checking exceptions
2025-06-02 19:45:58,680:INFO:Importing libraries
2025-06-02 19:45:58,680:INFO:Copying training dataset
2025-06-02 19:45:58,684:INFO:Defining folds
2025-06-02 19:45:58,684:INFO:Declaring metric variables
2025-06-02 19:45:58,684:INFO:Importing untrained model
2025-06-02 19:45:58,685:INFO:Linear Discriminant Analysis Imported successfully
2025-06-02 19:45:58,685:INFO:Starting cross validation
2025-06-02 19:45:58,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:58,797:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,798:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,800:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,803:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,804:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,804:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,805:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,807:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,808:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:58,820:INFO:Calculating mean and std
2025-06-02 19:45:58,821:INFO:Creating metrics dataframe
2025-06-02 19:45:58,823:INFO:Uploading results into container
2025-06-02 19:45:58,823:INFO:Uploading model into container now
2025-06-02 19:45:58,823:INFO:_master_model_container: 11
2025-06-02 19:45:58,823:INFO:_display_container: 2
2025-06-02 19:45:58,823:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-02 19:45:58,824:INFO:create_model() successfully completed......................................
2025-06-02 19:45:58,961:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:58,961:INFO:Creating metrics dataframe
2025-06-02 19:45:58,962:INFO:Initializing Extra Trees Classifier
2025-06-02 19:45:58,964:INFO:Total runtime is 0.20057599941889448 minutes
2025-06-02 19:45:58,964:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:58,964:INFO:Initializing create_model()
2025-06-02 19:45:58,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:58,964:INFO:Checking exceptions
2025-06-02 19:45:58,964:INFO:Importing libraries
2025-06-02 19:45:58,964:INFO:Copying training dataset
2025-06-02 19:45:58,967:INFO:Defining folds
2025-06-02 19:45:58,967:INFO:Declaring metric variables
2025-06-02 19:45:58,968:INFO:Importing untrained model
2025-06-02 19:45:58,968:INFO:Extra Trees Classifier Imported successfully
2025-06-02 19:45:58,969:INFO:Starting cross validation
2025-06-02 19:45:58,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:45:59,406:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:45:59,451:INFO:Calculating mean and std
2025-06-02 19:45:59,452:INFO:Creating metrics dataframe
2025-06-02 19:45:59,453:INFO:Uploading results into container
2025-06-02 19:45:59,453:INFO:Uploading model into container now
2025-06-02 19:45:59,454:INFO:_master_model_container: 12
2025-06-02 19:45:59,454:INFO:_display_container: 2
2025-06-02 19:45:59,454:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-06-02 19:45:59,454:INFO:create_model() successfully completed......................................
2025-06-02 19:45:59,592:INFO:SubProcess create_model() end ==================================
2025-06-02 19:45:59,592:INFO:Creating metrics dataframe
2025-06-02 19:45:59,594:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 19:45:59,594:INFO:Total runtime is 0.21107345422108972 minutes
2025-06-02 19:45:59,594:INFO:SubProcess create_model() called ==================================
2025-06-02 19:45:59,594:INFO:Initializing create_model()
2025-06-02 19:45:59,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:45:59,594:INFO:Checking exceptions
2025-06-02 19:45:59,594:INFO:Importing libraries
2025-06-02 19:45:59,594:INFO:Copying training dataset
2025-06-02 19:45:59,597:INFO:Defining folds
2025-06-02 19:45:59,598:INFO:Declaring metric variables
2025-06-02 19:45:59,598:INFO:Importing untrained model
2025-06-02 19:45:59,600:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 19:45:59,601:INFO:Starting cross validation
2025-06-02 19:45:59,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:46:01,050:INFO:Calculating mean and std
2025-06-02 19:46:01,051:INFO:Creating metrics dataframe
2025-06-02 19:46:01,052:INFO:Uploading results into container
2025-06-02 19:46:01,054:INFO:Uploading model into container now
2025-06-02 19:46:01,054:INFO:_master_model_container: 13
2025-06-02 19:46:01,054:INFO:_display_container: 2
2025-06-02 19:46:01,055:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-02 19:46:01,055:INFO:create_model() successfully completed......................................
2025-06-02 19:46:01,216:INFO:SubProcess create_model() end ==================================
2025-06-02 19:46:01,216:INFO:Creating metrics dataframe
2025-06-02 19:46:01,218:INFO:Initializing Dummy Classifier
2025-06-02 19:46:01,218:INFO:Total runtime is 0.2381421327590943 minutes
2025-06-02 19:46:01,218:INFO:SubProcess create_model() called ==================================
2025-06-02 19:46:01,218:INFO:Initializing create_model()
2025-06-02 19:46:01,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002268A0C2690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:46:01,218:INFO:Checking exceptions
2025-06-02 19:46:01,218:INFO:Importing libraries
2025-06-02 19:46:01,218:INFO:Copying training dataset
2025-06-02 19:46:01,222:INFO:Defining folds
2025-06-02 19:46:01,222:INFO:Declaring metric variables
2025-06-02 19:46:01,222:INFO:Importing untrained model
2025-06-02 19:46:01,222:INFO:Dummy Classifier Imported successfully
2025-06-02 19:46:01,222:INFO:Starting cross validation
2025-06-02 19:46:01,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:46:01,322:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:01,323:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:01,325:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:01,326:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:01,329:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:01,329:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:01,331:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:01,332:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:01,332:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:01,334:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:01,349:INFO:Calculating mean and std
2025-06-02 19:46:01,350:INFO:Creating metrics dataframe
2025-06-02 19:46:01,351:INFO:Uploading results into container
2025-06-02 19:46:01,352:INFO:Uploading model into container now
2025-06-02 19:46:01,352:INFO:_master_model_container: 14
2025-06-02 19:46:01,352:INFO:_display_container: 2
2025-06-02 19:46:01,352:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-06-02 19:46:01,352:INFO:create_model() successfully completed......................................
2025-06-02 19:46:01,500:INFO:SubProcess create_model() end ==================================
2025-06-02 19:46:01,500:INFO:Creating metrics dataframe
2025-06-02 19:46:01,504:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-06-02 19:46:01,506:INFO:Initializing create_model()
2025-06-02 19:46:01,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:46:01,506:INFO:Checking exceptions
2025-06-02 19:46:01,506:INFO:Importing libraries
2025-06-02 19:46:01,506:INFO:Copying training dataset
2025-06-02 19:46:01,510:INFO:Defining folds
2025-06-02 19:46:01,510:INFO:Declaring metric variables
2025-06-02 19:46:01,510:INFO:Importing untrained model
2025-06-02 19:46:01,510:INFO:Declaring custom model
2025-06-02 19:46:01,510:INFO:Logistic Regression Imported successfully
2025-06-02 19:46:01,512:INFO:Cross validation set to False
2025-06-02 19:46:01,512:INFO:Fitting Model
2025-06-02 19:46:02,195:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,196:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:46:02,196:INFO:create_model() successfully completed......................................
2025-06-02 19:46:02,366:INFO:_master_model_container: 14
2025-06-02 19:46:02,367:INFO:_display_container: 2
2025-06-02 19:46:02,367:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:46:02,367:INFO:compare_models() successfully completed......................................
2025-06-02 19:46:02,368:INFO:Initializing tune_model()
2025-06-02 19:46:02,368:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-06-02 19:46:02,368:INFO:Checking exceptions
2025-06-02 19:46:02,370:INFO:Copying training dataset
2025-06-02 19:46:02,374:INFO:Checking base model
2025-06-02 19:46:02,374:INFO:Base model : Logistic Regression
2025-06-02 19:46:02,374:INFO:Declaring metric variables
2025-06-02 19:46:02,374:INFO:Defining Hyperparameters
2025-06-02 19:46:02,525:INFO:Tuning with n_jobs=-1
2025-06-02 19:46:02,525:INFO:Initializing RandomizedSearchCV
2025-06-02 19:46:02,819:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,821:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,822:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,830:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,834:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,835:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,844:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,849:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,859:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,871:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,873:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:02,893:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,113:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,124:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,138:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,138:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,138:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,154:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,177:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,181:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,181:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,186:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,188:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,252:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,402:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,417:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,438:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,454:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,483:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,486:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,486:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,486:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,534:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,537:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,546:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,569:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,714:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,734:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,768:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,777:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,779:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,787:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,791:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,792:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,851:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,863:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,885:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:03,907:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,000:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,025:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,049:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,063:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,073:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,090:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,102:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,102:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,158:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,187:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,222:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,248:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,295:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,317:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,349:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,360:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,376:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,396:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,402:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,416:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,474:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,497:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,537:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,591:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,606:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,644:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,653:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,673:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,682:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,705:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,706:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,775:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,792:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,832:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,832:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,894:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,911:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,935:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,937:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,966:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:04,978:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,005:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,010:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,055:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,077:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,092:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,101:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,134:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,149:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,160:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,179:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,199:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.056}
2025-06-02 19:46:05,200:INFO:Hyperparameter search completed
2025-06-02 19:46:05,200:INFO:SubProcess create_model() called ==================================
2025-06-02 19:46:05,200:INFO:Initializing create_model()
2025-06-02 19:46:05,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022689774690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 0.056})
2025-06-02 19:46:05,200:INFO:Checking exceptions
2025-06-02 19:46:05,201:INFO:Importing libraries
2025-06-02 19:46:05,201:INFO:Copying training dataset
2025-06-02 19:46:05,204:INFO:Defining folds
2025-06-02 19:46:05,204:INFO:Declaring metric variables
2025-06-02 19:46:05,205:INFO:Importing untrained model
2025-06-02 19:46:05,205:INFO:Declaring custom model
2025-06-02 19:46:05,205:INFO:Logistic Regression Imported successfully
2025-06-02 19:46:05,205:INFO:Starting cross validation
2025-06-02 19:46:05,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:46:05,431:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,441:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,447:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,449:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,454:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,455:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,458:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:05,458:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,462:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,466:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,468:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:05,474:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:05,475:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:05,479:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:05,483:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:05,484:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:05,488:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:05,488:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:05,489:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:05,496:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:05,507:INFO:Calculating mean and std
2025-06-02 19:46:05,507:INFO:Creating metrics dataframe
2025-06-02 19:46:05,509:INFO:Finalizing model
2025-06-02 19:46:06,149:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:06,150:INFO:Uploading results into container
2025-06-02 19:46:06,151:INFO:Uploading model into container now
2025-06-02 19:46:06,151:INFO:_master_model_container: 15
2025-06-02 19:46:06,151:INFO:_display_container: 3
2025-06-02 19:46:06,151:INFO:LogisticRegression(C=0.056, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:46:06,151:INFO:create_model() successfully completed......................................
2025-06-02 19:46:06,294:INFO:SubProcess create_model() end ==================================
2025-06-02 19:46:06,294:INFO:choose_better activated
2025-06-02 19:46:06,294:INFO:SubProcess create_model() called ==================================
2025-06-02 19:46:06,294:INFO:Initializing create_model()
2025-06-02 19:46:06,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022659BFEB50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:46:06,294:INFO:Checking exceptions
2025-06-02 19:46:06,295:INFO:Importing libraries
2025-06-02 19:46:06,295:INFO:Copying training dataset
2025-06-02 19:46:06,298:INFO:Defining folds
2025-06-02 19:46:06,298:INFO:Declaring metric variables
2025-06-02 19:46:06,298:INFO:Importing untrained model
2025-06-02 19:46:06,298:INFO:Declaring custom model
2025-06-02 19:46:06,299:INFO:Logistic Regression Imported successfully
2025-06-02 19:46:06,299:INFO:Starting cross validation
2025-06-02 19:46:06,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:46:06,558:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:06,570:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:06,573:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:06,573:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:06,576:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:06,584:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:06,589:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:06,591:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:06,592:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:06,598:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:06,605:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:06,607:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:06,608:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:06,614:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:06,615:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:06,615:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:06,618:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:06,621:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:06,624:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-02 19:46:06,636:INFO:Calculating mean and std
2025-06-02 19:46:06,636:INFO:Creating metrics dataframe
2025-06-02 19:46:06,638:INFO:Finalizing model
2025-06-02 19:46:07,240:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-02 19:46:07,241:INFO:Uploading results into container
2025-06-02 19:46:07,242:INFO:Uploading model into container now
2025-06-02 19:46:07,242:INFO:_master_model_container: 16
2025-06-02 19:46:07,242:INFO:_display_container: 4
2025-06-02 19:46:07,242:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:46:07,242:INFO:create_model() successfully completed......................................
2025-06-02 19:46:07,382:INFO:SubProcess create_model() end ==================================
2025-06-02 19:46:07,383:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8457
2025-06-02 19:46:07,384:INFO:LogisticRegression(C=0.056, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8457
2025-06-02 19:46:07,384:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-06-02 19:46:07,384:INFO:choose_better completed
2025-06-02 19:46:07,384:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 19:46:07,392:INFO:_master_model_container: 16
2025-06-02 19:46:07,392:INFO:_display_container: 3
2025-06-02 19:46:07,392:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:46:07,392:INFO:tune_model() successfully completed......................................
2025-06-02 19:46:07,536:INFO:Initializing save_model()
2025-06-02 19:46:07,536:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=modelo_bank_mlflow, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['segmento', 'rango_ingresos',
                                             'region'],
                                    transformer=OneHotEncoder(cols=['segmento',
                                                                    'rango_ingresos',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-02 19:46:07,536:INFO:Adding model into prep_pipe
2025-06-02 19:46:07,541:INFO:modelo_bank_mlflow.pkl saved in current working directory
2025-06-02 19:46:07,554:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-06-02 19:46:07,554:INFO:save_model() successfully completed......................................
2025-06-02 19:54:34,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:54:34,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:54:34,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:54:34,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 19:54:36,078:INFO:PyCaret ClassificationExperiment
2025-06-02 19:54:36,078:INFO:Logging name: banking-autoML
2025-06-02 19:54:36,078:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-02 19:54:36,078:INFO:version 3.2.0
2025-06-02 19:54:36,078:INFO:Initializing setup()
2025-06-02 19:54:36,078:INFO:self.USI: 7308
2025-06-02 19:54:36,078:INFO:self._variable_keys: {'logging_param', 'fold_generator', 'target_param', 'memory', 'fold_groups_param', 'y_test', 'html_param', 'n_jobs_param', 'exp_id', '_ml_usecase', 'y_train', 'fold_shuffle_param', 'is_multiclass', '_available_plots', 'X', 'y', 'X_test', 'X_train', 'log_plots_param', 'gpu_param', 'fix_imbalance', 'seed', 'pipeline', 'gpu_n_jobs_param', 'data', 'idx', 'exp_name_log', 'USI'}
2025-06-02 19:54:36,079:INFO:Checking environment
2025-06-02 19:54:36,079:INFO:python_version: 3.11.9
2025-06-02 19:54:36,079:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-02 19:54:36,079:INFO:machine: AMD64
2025-06-02 19:54:36,098:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-02 19:54:36,105:INFO:Memory: svmem(total=33554628608, available=17397678080, percent=48.2, used=16156950528, free=17397678080)
2025-06-02 19:54:36,105:INFO:Physical Core: 6
2025-06-02 19:54:36,105:INFO:Logical Core: 12
2025-06-02 19:54:36,105:INFO:Checking libraries
2025-06-02 19:54:36,105:INFO:System:
2025-06-02 19:54:36,105:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-02 19:54:36,105:INFO:executable: C:\Users\amonreal\Documents\amlbash\.venv\Scripts\python.exe
2025-06-02 19:54:36,105:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-02 19:54:36,105:INFO:PyCaret required dependencies:
2025-06-02 19:54:36,161:INFO:                 pip: 24.0
2025-06-02 19:54:36,161:INFO:          setuptools: 65.5.0
2025-06-02 19:54:36,161:INFO:             pycaret: 3.2.0
2025-06-02 19:54:36,161:INFO:             IPython: 9.2.0
2025-06-02 19:54:36,161:INFO:          ipywidgets: 8.1.7
2025-06-02 19:54:36,161:INFO:                tqdm: 4.67.1
2025-06-02 19:54:36,161:INFO:               numpy: 1.25.2
2025-06-02 19:54:36,161:INFO:              pandas: 1.5.3
2025-06-02 19:54:36,161:INFO:              jinja2: 3.1.6
2025-06-02 19:54:36,161:INFO:               scipy: 1.10.1
2025-06-02 19:54:36,161:INFO:              joblib: 1.3.2
2025-06-02 19:54:36,161:INFO:             sklearn: 1.2.2
2025-06-02 19:54:36,161:INFO:                pyod: 2.0.5
2025-06-02 19:54:36,161:INFO:            imblearn: 0.12.4
2025-06-02 19:54:36,161:INFO:   category_encoders: 2.7.0
2025-06-02 19:54:36,161:INFO:            lightgbm: 4.6.0
2025-06-02 19:54:36,161:INFO:               numba: 0.61.2
2025-06-02 19:54:36,161:INFO:            requests: 2.32.3
2025-06-02 19:54:36,161:INFO:          matplotlib: 3.6.0
2025-06-02 19:54:36,161:INFO:          scikitplot: 0.3.7
2025-06-02 19:54:36,161:INFO:         yellowbrick: 1.5
2025-06-02 19:54:36,161:INFO:              plotly: 5.24.1
2025-06-02 19:54:36,161:INFO:    plotly-resampler: Not installed
2025-06-02 19:54:36,161:INFO:             kaleido: 0.2.1
2025-06-02 19:54:36,161:INFO:           schemdraw: 0.15
2025-06-02 19:54:36,161:INFO:         statsmodels: 0.14.4
2025-06-02 19:54:36,161:INFO:              sktime: 0.21.1
2025-06-02 19:54:36,161:INFO:               tbats: 1.1.3
2025-06-02 19:54:36,161:INFO:            pmdarima: 2.0.4
2025-06-02 19:54:36,161:INFO:              psutil: 7.0.0
2025-06-02 19:54:36,161:INFO:          markupsafe: 3.0.2
2025-06-02 19:54:36,161:INFO:             pickle5: Not installed
2025-06-02 19:54:36,161:INFO:         cloudpickle: 2.2.1
2025-06-02 19:54:36,162:INFO:         deprecation: 2.1.0
2025-06-02 19:54:36,162:INFO:              xxhash: 3.5.0
2025-06-02 19:54:36,162:INFO:           wurlitzer: Not installed
2025-06-02 19:54:36,162:INFO:PyCaret optional dependencies:
2025-06-02 19:54:36,671:INFO:                shap: Not installed
2025-06-02 19:54:36,671:INFO:           interpret: Not installed
2025-06-02 19:54:36,671:INFO:                umap: Not installed
2025-06-02 19:54:36,671:INFO:     ydata_profiling: Not installed
2025-06-02 19:54:36,671:INFO:  explainerdashboard: Not installed
2025-06-02 19:54:36,671:INFO:             autoviz: Not installed
2025-06-02 19:54:36,672:INFO:           fairlearn: Not installed
2025-06-02 19:54:36,672:INFO:          deepchecks: Not installed
2025-06-02 19:54:36,672:INFO:             xgboost: Not installed
2025-06-02 19:54:36,672:INFO:            catboost: Not installed
2025-06-02 19:54:36,672:INFO:              kmodes: Not installed
2025-06-02 19:54:36,672:INFO:             mlxtend: Not installed
2025-06-02 19:54:36,672:INFO:       statsforecast: Not installed
2025-06-02 19:54:36,672:INFO:        tune_sklearn: Not installed
2025-06-02 19:54:36,672:INFO:                 ray: Not installed
2025-06-02 19:54:36,672:INFO:            hyperopt: Not installed
2025-06-02 19:54:36,672:INFO:              optuna: Not installed
2025-06-02 19:54:36,672:INFO:               skopt: Not installed
2025-06-02 19:54:36,672:INFO:              mlflow: 2.22.0
2025-06-02 19:54:36,672:INFO:              gradio: Not installed
2025-06-02 19:54:36,672:INFO:             fastapi: 0.115.12
2025-06-02 19:54:36,672:INFO:             uvicorn: 0.34.2
2025-06-02 19:54:36,672:INFO:              m2cgen: Not installed
2025-06-02 19:54:36,672:INFO:           evidently: Not installed
2025-06-02 19:54:36,672:INFO:               fugue: Not installed
2025-06-02 19:54:36,672:INFO:           streamlit: Not installed
2025-06-02 19:54:36,672:INFO:             prophet: Not installed
2025-06-02 19:54:36,672:INFO:None
2025-06-02 19:54:36,672:INFO:Set up data.
2025-06-02 19:54:36,678:INFO:Set up folding strategy.
2025-06-02 19:54:36,678:INFO:Set up train/test split.
2025-06-02 19:54:36,684:INFO:Set up index.
2025-06-02 19:54:36,684:INFO:Assigning column types.
2025-06-02 19:54:36,687:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 19:54:36,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:54:36,722:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:54:36,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:36,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:36,793:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 19:54:36,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:54:36,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:36,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:36,813:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 19:54:36,847:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:54:36,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:36,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:36,923:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 19:54:36,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:36,944:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:36,944:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-02 19:54:37,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:37,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:37,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:37,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:37,058:INFO:Preparing preprocessing pipeline...
2025-06-02 19:54:37,060:INFO:Set up simple imputation.
2025-06-02 19:54:37,062:INFO:Set up encoding of categorical features.
2025-06-02 19:54:37,148:INFO:Finished creating preprocessing pipeline.
2025-06-02 19:54:37,153:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['segmento', 'rango_ingresos',
                                             'region'],
                                    transformer=OneHotEncoder(cols=['segmento',
                                                                    'rango_ingresos',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-06-02 19:54:37,153:INFO:Creating final display dataframe.
2025-06-02 19:54:37,325:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target   cerrara_cuenta
2                   Target type           Binary
3           Original data shape       (2000, 13)
4        Transformed data shape       (2000, 20)
5   Transformed train set shape       (1400, 20)
6    Transformed test set shape        (600, 20)
7              Numeric features                9
8          Categorical features                3
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment            False
20              Experiment Name   banking-autoML
21                          USI             7308
2025-06-02 19:54:37,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:37,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:37,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:37,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 19:54:37,470:INFO:setup() successfully completed in 1.4s...............
2025-06-02 19:54:37,470:INFO:Initializing compare_models()
2025-06-02 19:54:37,470:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-02 19:54:37,470:INFO:Checking exceptions
2025-06-02 19:54:37,472:INFO:Preparing display monitor
2025-06-02 19:54:37,477:INFO:Initializing Logistic Regression
2025-06-02 19:54:37,477:INFO:Total runtime is 0.0 minutes
2025-06-02 19:54:37,478:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:37,478:INFO:Initializing create_model()
2025-06-02 19:54:37,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:37,478:INFO:Checking exceptions
2025-06-02 19:54:37,478:INFO:Importing libraries
2025-06-02 19:54:37,478:INFO:Copying training dataset
2025-06-02 19:54:37,483:INFO:Defining folds
2025-06-02 19:54:37,483:INFO:Declaring metric variables
2025-06-02 19:54:37,483:INFO:Importing untrained model
2025-06-02 19:54:37,484:INFO:Logistic Regression Imported successfully
2025-06-02 19:54:37,484:INFO:Starting cross validation
2025-06-02 19:54:37,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:41,925:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:41,963:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:41,980:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:41,991:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:42,040:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:42,071:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:42,073:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:42,132:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:42,157:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:42,210:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:42,218:INFO:Calculating mean and std
2025-06-02 19:54:42,220:INFO:Creating metrics dataframe
2025-06-02 19:54:42,224:INFO:Uploading results into container
2025-06-02 19:54:42,224:INFO:Uploading model into container now
2025-06-02 19:54:42,224:INFO:_master_model_container: 1
2025-06-02 19:54:42,225:INFO:_display_container: 2
2025-06-02 19:54:42,225:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:54:42,225:INFO:create_model() successfully completed......................................
2025-06-02 19:54:42,334:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:42,334:INFO:Creating metrics dataframe
2025-06-02 19:54:42,337:INFO:Initializing K Neighbors Classifier
2025-06-02 19:54:42,337:INFO:Total runtime is 0.08100887934366861 minutes
2025-06-02 19:54:42,337:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:42,337:INFO:Initializing create_model()
2025-06-02 19:54:42,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:42,337:INFO:Checking exceptions
2025-06-02 19:54:42,337:INFO:Importing libraries
2025-06-02 19:54:42,337:INFO:Copying training dataset
2025-06-02 19:54:42,341:INFO:Defining folds
2025-06-02 19:54:42,341:INFO:Declaring metric variables
2025-06-02 19:54:42,341:INFO:Importing untrained model
2025-06-02 19:54:42,341:INFO:K Neighbors Classifier Imported successfully
2025-06-02 19:54:42,341:INFO:Starting cross validation
2025-06-02 19:54:42,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:44,940:INFO:Calculating mean and std
2025-06-02 19:54:44,941:INFO:Creating metrics dataframe
2025-06-02 19:54:44,943:INFO:Uploading results into container
2025-06-02 19:54:44,943:INFO:Uploading model into container now
2025-06-02 19:54:44,944:INFO:_master_model_container: 2
2025-06-02 19:54:44,944:INFO:_display_container: 2
2025-06-02 19:54:44,944:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-02 19:54:44,944:INFO:create_model() successfully completed......................................
2025-06-02 19:54:45,057:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:45,057:INFO:Creating metrics dataframe
2025-06-02 19:54:45,061:INFO:Initializing Naive Bayes
2025-06-02 19:54:45,062:INFO:Total runtime is 0.12641808986663816 minutes
2025-06-02 19:54:45,062:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:45,062:INFO:Initializing create_model()
2025-06-02 19:54:45,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:45,062:INFO:Checking exceptions
2025-06-02 19:54:45,062:INFO:Importing libraries
2025-06-02 19:54:45,062:INFO:Copying training dataset
2025-06-02 19:54:45,064:INFO:Defining folds
2025-06-02 19:54:45,064:INFO:Declaring metric variables
2025-06-02 19:54:45,065:INFO:Importing untrained model
2025-06-02 19:54:45,065:INFO:Naive Bayes Imported successfully
2025-06-02 19:54:45,065:INFO:Starting cross validation
2025-06-02 19:54:45,066:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:45,181:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,186:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,187:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,187:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,188:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,188:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,189:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,190:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,193:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,195:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,202:INFO:Calculating mean and std
2025-06-02 19:54:45,203:INFO:Creating metrics dataframe
2025-06-02 19:54:45,206:INFO:Uploading results into container
2025-06-02 19:54:45,206:INFO:Uploading model into container now
2025-06-02 19:54:45,207:INFO:_master_model_container: 3
2025-06-02 19:54:45,207:INFO:_display_container: 2
2025-06-02 19:54:45,207:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-02 19:54:45,207:INFO:create_model() successfully completed......................................
2025-06-02 19:54:45,313:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:45,313:INFO:Creating metrics dataframe
2025-06-02 19:54:45,316:INFO:Initializing Decision Tree Classifier
2025-06-02 19:54:45,316:INFO:Total runtime is 0.13065804243087767 minutes
2025-06-02 19:54:45,316:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:45,316:INFO:Initializing create_model()
2025-06-02 19:54:45,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:45,316:INFO:Checking exceptions
2025-06-02 19:54:45,316:INFO:Importing libraries
2025-06-02 19:54:45,316:INFO:Copying training dataset
2025-06-02 19:54:45,320:INFO:Defining folds
2025-06-02 19:54:45,320:INFO:Declaring metric variables
2025-06-02 19:54:45,320:INFO:Importing untrained model
2025-06-02 19:54:45,321:INFO:Decision Tree Classifier Imported successfully
2025-06-02 19:54:45,321:INFO:Starting cross validation
2025-06-02 19:54:45,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:45,467:INFO:Calculating mean and std
2025-06-02 19:54:45,468:INFO:Creating metrics dataframe
2025-06-02 19:54:45,470:INFO:Uploading results into container
2025-06-02 19:54:45,470:INFO:Uploading model into container now
2025-06-02 19:54:45,471:INFO:_master_model_container: 4
2025-06-02 19:54:45,471:INFO:_display_container: 2
2025-06-02 19:54:45,471:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2025-06-02 19:54:45,471:INFO:create_model() successfully completed......................................
2025-06-02 19:54:45,572:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:45,572:INFO:Creating metrics dataframe
2025-06-02 19:54:45,575:INFO:Initializing SVM - Linear Kernel
2025-06-02 19:54:45,575:INFO:Total runtime is 0.13497723340988158 minutes
2025-06-02 19:54:45,575:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:45,575:INFO:Initializing create_model()
2025-06-02 19:54:45,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:45,575:INFO:Checking exceptions
2025-06-02 19:54:45,575:INFO:Importing libraries
2025-06-02 19:54:45,575:INFO:Copying training dataset
2025-06-02 19:54:45,578:INFO:Defining folds
2025-06-02 19:54:45,578:INFO:Declaring metric variables
2025-06-02 19:54:45,578:INFO:Importing untrained model
2025-06-02 19:54:45,578:INFO:SVM - Linear Kernel Imported successfully
2025-06-02 19:54:45,578:INFO:Starting cross validation
2025-06-02 19:54:45,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:45,697:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 19:54:45,697:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 19:54:45,698:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 19:54:45,698:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 19:54:45,707:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 19:54:45,707:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 19:54:45,708:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 19:54:45,708:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 19:54:45,711:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,715:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 19:54:45,719:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 19:54:45,720:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,734:INFO:Calculating mean and std
2025-06-02 19:54:45,735:INFO:Creating metrics dataframe
2025-06-02 19:54:45,737:INFO:Uploading results into container
2025-06-02 19:54:45,737:INFO:Uploading model into container now
2025-06-02 19:54:45,738:INFO:_master_model_container: 5
2025-06-02 19:54:45,738:INFO:_display_container: 2
2025-06-02 19:54:45,738:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-02 19:54:45,738:INFO:create_model() successfully completed......................................
2025-06-02 19:54:45,838:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:45,838:INFO:Creating metrics dataframe
2025-06-02 19:54:45,843:INFO:Initializing Ridge Classifier
2025-06-02 19:54:45,843:INFO:Total runtime is 0.13943336804707843 minutes
2025-06-02 19:54:45,843:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:45,843:INFO:Initializing create_model()
2025-06-02 19:54:45,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:45,843:INFO:Checking exceptions
2025-06-02 19:54:45,843:INFO:Importing libraries
2025-06-02 19:54:45,843:INFO:Copying training dataset
2025-06-02 19:54:45,845:INFO:Defining folds
2025-06-02 19:54:45,845:INFO:Declaring metric variables
2025-06-02 19:54:45,845:INFO:Importing untrained model
2025-06-02 19:54:45,846:INFO:Ridge Classifier Imported successfully
2025-06-02 19:54:45,846:INFO:Starting cross validation
2025-06-02 19:54:45,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:45,947:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 19:54:45,951:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 19:54:45,952:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 19:54:45,952:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,954:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 19:54:45,955:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 19:54:45,956:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,956:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,957:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 19:54:45,958:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,959:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,960:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,965:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 19:54:45,965:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 19:54:45,967:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 19:54:45,967:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,969:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,971:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 19:54:45,971:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,974:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:45,987:INFO:Calculating mean and std
2025-06-02 19:54:45,988:INFO:Creating metrics dataframe
2025-06-02 19:54:45,990:INFO:Uploading results into container
2025-06-02 19:54:45,991:INFO:Uploading model into container now
2025-06-02 19:54:45,991:INFO:_master_model_container: 6
2025-06-02 19:54:45,991:INFO:_display_container: 2
2025-06-02 19:54:45,991:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-06-02 19:54:45,991:INFO:create_model() successfully completed......................................
2025-06-02 19:54:46,095:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:46,095:INFO:Creating metrics dataframe
2025-06-02 19:54:46,098:INFO:Initializing Random Forest Classifier
2025-06-02 19:54:46,098:INFO:Total runtime is 0.14368735154469806 minutes
2025-06-02 19:54:46,098:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:46,099:INFO:Initializing create_model()
2025-06-02 19:54:46,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:46,099:INFO:Checking exceptions
2025-06-02 19:54:46,099:INFO:Importing libraries
2025-06-02 19:54:46,099:INFO:Copying training dataset
2025-06-02 19:54:46,102:INFO:Defining folds
2025-06-02 19:54:46,102:INFO:Declaring metric variables
2025-06-02 19:54:46,102:INFO:Importing untrained model
2025-06-02 19:54:46,102:INFO:Random Forest Classifier Imported successfully
2025-06-02 19:54:46,102:INFO:Starting cross validation
2025-06-02 19:54:46,104:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:46,580:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:46,584:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:46,590:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:46,599:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:46,602:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:46,729:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:46,737:INFO:Calculating mean and std
2025-06-02 19:54:46,737:INFO:Creating metrics dataframe
2025-06-02 19:54:46,740:INFO:Uploading results into container
2025-06-02 19:54:46,740:INFO:Uploading model into container now
2025-06-02 19:54:46,741:INFO:_master_model_container: 7
2025-06-02 19:54:46,741:INFO:_display_container: 2
2025-06-02 19:54:46,741:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2025-06-02 19:54:46,741:INFO:create_model() successfully completed......................................
2025-06-02 19:54:46,844:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:46,844:INFO:Creating metrics dataframe
2025-06-02 19:54:46,847:INFO:Initializing Quadratic Discriminant Analysis
2025-06-02 19:54:46,848:INFO:Total runtime is 0.1561933318773905 minutes
2025-06-02 19:54:46,848:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:46,848:INFO:Initializing create_model()
2025-06-02 19:54:46,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:46,848:INFO:Checking exceptions
2025-06-02 19:54:46,848:INFO:Importing libraries
2025-06-02 19:54:46,848:INFO:Copying training dataset
2025-06-02 19:54:46,851:INFO:Defining folds
2025-06-02 19:54:46,852:INFO:Declaring metric variables
2025-06-02 19:54:46,852:INFO:Importing untrained model
2025-06-02 19:54:46,853:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-02 19:54:46,854:INFO:Starting cross validation
2025-06-02 19:54:46,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:46,950:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:54:46,952:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:54:46,956:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:54:46,958:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:54:46,959:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:54:46,959:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:54:46,959:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:54:46,960:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:54:46,961:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:54:46,966:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 19:54:47,001:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:47,012:INFO:Calculating mean and std
2025-06-02 19:54:47,012:INFO:Creating metrics dataframe
2025-06-02 19:54:47,016:INFO:Uploading results into container
2025-06-02 19:54:47,016:INFO:Uploading model into container now
2025-06-02 19:54:47,017:INFO:_master_model_container: 8
2025-06-02 19:54:47,017:INFO:_display_container: 2
2025-06-02 19:54:47,017:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-02 19:54:47,017:INFO:create_model() successfully completed......................................
2025-06-02 19:54:47,120:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:47,120:INFO:Creating metrics dataframe
2025-06-02 19:54:47,123:INFO:Initializing Ada Boost Classifier
2025-06-02 19:54:47,123:INFO:Total runtime is 0.16076923608779903 minutes
2025-06-02 19:54:47,123:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:47,124:INFO:Initializing create_model()
2025-06-02 19:54:47,124:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:47,124:INFO:Checking exceptions
2025-06-02 19:54:47,124:INFO:Importing libraries
2025-06-02 19:54:47,124:INFO:Copying training dataset
2025-06-02 19:54:47,126:INFO:Defining folds
2025-06-02 19:54:47,126:INFO:Declaring metric variables
2025-06-02 19:54:47,126:INFO:Importing untrained model
2025-06-02 19:54:47,127:INFO:Ada Boost Classifier Imported successfully
2025-06-02 19:54:47,127:INFO:Starting cross validation
2025-06-02 19:54:47,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:47,393:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:47,419:INFO:Calculating mean and std
2025-06-02 19:54:47,419:INFO:Creating metrics dataframe
2025-06-02 19:54:47,422:INFO:Uploading results into container
2025-06-02 19:54:47,422:INFO:Uploading model into container now
2025-06-02 19:54:47,423:INFO:_master_model_container: 9
2025-06-02 19:54:47,423:INFO:_display_container: 2
2025-06-02 19:54:47,423:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2025-06-02 19:54:47,423:INFO:create_model() successfully completed......................................
2025-06-02 19:54:47,532:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:47,532:INFO:Creating metrics dataframe
2025-06-02 19:54:47,538:INFO:Initializing Gradient Boosting Classifier
2025-06-02 19:54:47,538:INFO:Total runtime is 0.16768902540206904 minutes
2025-06-02 19:54:47,538:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:47,540:INFO:Initializing create_model()
2025-06-02 19:54:47,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:47,540:INFO:Checking exceptions
2025-06-02 19:54:47,540:INFO:Importing libraries
2025-06-02 19:54:47,540:INFO:Copying training dataset
2025-06-02 19:54:47,543:INFO:Defining folds
2025-06-02 19:54:47,543:INFO:Declaring metric variables
2025-06-02 19:54:47,543:INFO:Importing untrained model
2025-06-02 19:54:47,544:INFO:Gradient Boosting Classifier Imported successfully
2025-06-02 19:54:47,544:INFO:Starting cross validation
2025-06-02 19:54:47,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:48,037:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,049:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,058:INFO:Calculating mean and std
2025-06-02 19:54:48,058:INFO:Creating metrics dataframe
2025-06-02 19:54:48,062:INFO:Uploading results into container
2025-06-02 19:54:48,062:INFO:Uploading model into container now
2025-06-02 19:54:48,062:INFO:_master_model_container: 10
2025-06-02 19:54:48,062:INFO:_display_container: 2
2025-06-02 19:54:48,063:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-02 19:54:48,063:INFO:create_model() successfully completed......................................
2025-06-02 19:54:48,174:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:48,174:INFO:Creating metrics dataframe
2025-06-02 19:54:48,176:INFO:Initializing Linear Discriminant Analysis
2025-06-02 19:54:48,178:INFO:Total runtime is 0.17832952340443922 minutes
2025-06-02 19:54:48,178:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:48,178:INFO:Initializing create_model()
2025-06-02 19:54:48,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:48,178:INFO:Checking exceptions
2025-06-02 19:54:48,178:INFO:Importing libraries
2025-06-02 19:54:48,178:INFO:Copying training dataset
2025-06-02 19:54:48,181:INFO:Defining folds
2025-06-02 19:54:48,181:INFO:Declaring metric variables
2025-06-02 19:54:48,181:INFO:Importing untrained model
2025-06-02 19:54:48,181:INFO:Linear Discriminant Analysis Imported successfully
2025-06-02 19:54:48,181:INFO:Starting cross validation
2025-06-02 19:54:48,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:48,303:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,308:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,308:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,309:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,310:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,310:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,311:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,312:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,319:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,320:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:48,327:INFO:Calculating mean and std
2025-06-02 19:54:48,327:INFO:Creating metrics dataframe
2025-06-02 19:54:48,331:INFO:Uploading results into container
2025-06-02 19:54:48,331:INFO:Uploading model into container now
2025-06-02 19:54:48,331:INFO:_master_model_container: 11
2025-06-02 19:54:48,331:INFO:_display_container: 2
2025-06-02 19:54:48,332:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-02 19:54:48,332:INFO:create_model() successfully completed......................................
2025-06-02 19:54:48,440:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:48,440:INFO:Creating metrics dataframe
2025-06-02 19:54:48,443:INFO:Initializing Extra Trees Classifier
2025-06-02 19:54:48,443:INFO:Total runtime is 0.1827641606330871 minutes
2025-06-02 19:54:48,443:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:48,444:INFO:Initializing create_model()
2025-06-02 19:54:48,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:48,444:INFO:Checking exceptions
2025-06-02 19:54:48,444:INFO:Importing libraries
2025-06-02 19:54:48,444:INFO:Copying training dataset
2025-06-02 19:54:48,447:INFO:Defining folds
2025-06-02 19:54:48,447:INFO:Declaring metric variables
2025-06-02 19:54:48,447:INFO:Importing untrained model
2025-06-02 19:54:48,448:INFO:Extra Trees Classifier Imported successfully
2025-06-02 19:54:48,448:INFO:Starting cross validation
2025-06-02 19:54:48,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:48,906:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:49,015:INFO:Calculating mean and std
2025-06-02 19:54:49,016:INFO:Creating metrics dataframe
2025-06-02 19:54:49,018:INFO:Uploading results into container
2025-06-02 19:54:49,019:INFO:Uploading model into container now
2025-06-02 19:54:49,019:INFO:_master_model_container: 12
2025-06-02 19:54:49,019:INFO:_display_container: 2
2025-06-02 19:54:49,020:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2025-06-02 19:54:49,020:INFO:create_model() successfully completed......................................
2025-06-02 19:54:49,125:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:49,125:INFO:Creating metrics dataframe
2025-06-02 19:54:49,128:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 19:54:49,128:INFO:Total runtime is 0.19419025182723992 minutes
2025-06-02 19:54:49,128:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:49,130:INFO:Initializing create_model()
2025-06-02 19:54:49,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:49,130:INFO:Checking exceptions
2025-06-02 19:54:49,130:INFO:Importing libraries
2025-06-02 19:54:49,130:INFO:Copying training dataset
2025-06-02 19:54:49,133:INFO:Defining folds
2025-06-02 19:54:49,133:INFO:Declaring metric variables
2025-06-02 19:54:49,134:INFO:Importing untrained model
2025-06-02 19:54:49,135:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 19:54:49,136:INFO:Starting cross validation
2025-06-02 19:54:49,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:50,558:INFO:Calculating mean and std
2025-06-02 19:54:50,558:INFO:Creating metrics dataframe
2025-06-02 19:54:50,562:INFO:Uploading results into container
2025-06-02 19:54:50,562:INFO:Uploading model into container now
2025-06-02 19:54:50,563:INFO:_master_model_container: 13
2025-06-02 19:54:50,563:INFO:_display_container: 2
2025-06-02 19:54:50,564:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-02 19:54:50,564:INFO:create_model() successfully completed......................................
2025-06-02 19:54:50,690:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:50,690:INFO:Creating metrics dataframe
2025-06-02 19:54:50,694:INFO:Initializing Dummy Classifier
2025-06-02 19:54:50,694:INFO:Total runtime is 0.22028144200642896 minutes
2025-06-02 19:54:50,694:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:50,694:INFO:Initializing create_model()
2025-06-02 19:54:50,694:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121ADD510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:50,694:INFO:Checking exceptions
2025-06-02 19:54:50,694:INFO:Importing libraries
2025-06-02 19:54:50,694:INFO:Copying training dataset
2025-06-02 19:54:50,696:INFO:Defining folds
2025-06-02 19:54:50,697:INFO:Declaring metric variables
2025-06-02 19:54:50,697:INFO:Importing untrained model
2025-06-02 19:54:50,697:INFO:Dummy Classifier Imported successfully
2025-06-02 19:54:50,697:INFO:Starting cross validation
2025-06-02 19:54:50,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:50,802:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:50,805:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:50,806:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:50,806:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:50,808:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:50,809:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:50,809:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:50,811:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:50,812:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:50,814:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:50,821:INFO:Calculating mean and std
2025-06-02 19:54:50,822:INFO:Creating metrics dataframe
2025-06-02 19:54:50,825:INFO:Uploading results into container
2025-06-02 19:54:50,825:INFO:Uploading model into container now
2025-06-02 19:54:50,826:INFO:_master_model_container: 14
2025-06-02 19:54:50,826:INFO:_display_container: 2
2025-06-02 19:54:50,826:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-06-02 19:54:50,826:INFO:create_model() successfully completed......................................
2025-06-02 19:54:50,932:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:50,932:INFO:Creating metrics dataframe
2025-06-02 19:54:50,940:INFO:Initializing create_model()
2025-06-02 19:54:50,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:50,940:INFO:Checking exceptions
2025-06-02 19:54:50,941:INFO:Importing libraries
2025-06-02 19:54:50,941:INFO:Copying training dataset
2025-06-02 19:54:50,945:INFO:Defining folds
2025-06-02 19:54:50,945:INFO:Declaring metric variables
2025-06-02 19:54:50,946:INFO:Importing untrained model
2025-06-02 19:54:50,946:INFO:Declaring custom model
2025-06-02 19:54:50,946:INFO:Logistic Regression Imported successfully
2025-06-02 19:54:50,948:INFO:Cross validation set to False
2025-06-02 19:54:50,948:INFO:Fitting Model
2025-06-02 19:54:51,021:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:54:51,021:INFO:create_model() successfully completed......................................
2025-06-02 19:54:51,140:INFO:_master_model_container: 14
2025-06-02 19:54:51,140:INFO:_display_container: 2
2025-06-02 19:54:51,140:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:54:51,140:INFO:compare_models() successfully completed......................................
2025-06-02 19:54:51,141:INFO:Initializing tune_model()
2025-06-02 19:54:51,141:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-06-02 19:54:51,141:INFO:Checking exceptions
2025-06-02 19:54:51,143:INFO:Copying training dataset
2025-06-02 19:54:51,145:INFO:Checking base model
2025-06-02 19:54:51,145:INFO:Base model : Logistic Regression
2025-06-02 19:54:51,145:INFO:Declaring metric variables
2025-06-02 19:54:51,145:INFO:Defining Hyperparameters
2025-06-02 19:54:51,260:INFO:Tuning with n_jobs=-1
2025-06-02 19:54:51,260:INFO:Initializing RandomizedSearchCV
2025-06-02 19:54:52,361:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 7.863}
2025-06-02 19:54:52,361:INFO:Hyperparameter search completed
2025-06-02 19:54:52,361:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:52,362:INFO:Initializing create_model()
2025-06-02 19:54:52,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A121961790>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 7.863})
2025-06-02 19:54:52,362:INFO:Checking exceptions
2025-06-02 19:54:52,362:INFO:Importing libraries
2025-06-02 19:54:52,362:INFO:Copying training dataset
2025-06-02 19:54:52,365:INFO:Defining folds
2025-06-02 19:54:52,365:INFO:Declaring metric variables
2025-06-02 19:54:52,366:INFO:Importing untrained model
2025-06-02 19:54:52,366:INFO:Declaring custom model
2025-06-02 19:54:52,366:INFO:Logistic Regression Imported successfully
2025-06-02 19:54:52,366:INFO:Starting cross validation
2025-06-02 19:54:52,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:52,482:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,492:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,494:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,494:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,495:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,495:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,496:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,498:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,500:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,505:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,511:INFO:Calculating mean and std
2025-06-02 19:54:52,512:INFO:Creating metrics dataframe
2025-06-02 19:54:52,514:INFO:Finalizing model
2025-06-02 19:54:52,588:INFO:Uploading results into container
2025-06-02 19:54:52,589:INFO:Uploading model into container now
2025-06-02 19:54:52,589:INFO:_master_model_container: 15
2025-06-02 19:54:52,589:INFO:_display_container: 3
2025-06-02 19:54:52,589:INFO:LogisticRegression(C=7.863, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:54:52,589:INFO:create_model() successfully completed......................................
2025-06-02 19:54:52,695:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:52,695:INFO:choose_better activated
2025-06-02 19:54:52,695:INFO:SubProcess create_model() called ==================================
2025-06-02 19:54:52,696:INFO:Initializing create_model()
2025-06-02 19:54:52,696:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A1682A52D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 19:54:52,696:INFO:Checking exceptions
2025-06-02 19:54:52,696:INFO:Importing libraries
2025-06-02 19:54:52,697:INFO:Copying training dataset
2025-06-02 19:54:52,700:INFO:Defining folds
2025-06-02 19:54:52,700:INFO:Declaring metric variables
2025-06-02 19:54:52,700:INFO:Importing untrained model
2025-06-02 19:54:52,700:INFO:Declaring custom model
2025-06-02 19:54:52,700:INFO:Logistic Regression Imported successfully
2025-06-02 19:54:52,700:INFO:Starting cross validation
2025-06-02 19:54:52,701:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 19:54:52,812:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,825:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,828:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,828:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,830:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,832:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,841:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,842:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,844:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,847:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 19:54:52,855:INFO:Calculating mean and std
2025-06-02 19:54:52,855:INFO:Creating metrics dataframe
2025-06-02 19:54:52,857:INFO:Finalizing model
2025-06-02 19:54:52,921:INFO:Uploading results into container
2025-06-02 19:54:52,922:INFO:Uploading model into container now
2025-06-02 19:54:52,922:INFO:_master_model_container: 16
2025-06-02 19:54:52,922:INFO:_display_container: 4
2025-06-02 19:54:52,922:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:54:52,922:INFO:create_model() successfully completed......................................
2025-06-02 19:54:53,030:INFO:SubProcess create_model() end ==================================
2025-06-02 19:54:53,031:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8457
2025-06-02 19:54:53,031:INFO:LogisticRegression(C=7.863, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8457
2025-06-02 19:54:53,031:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-06-02 19:54:53,031:INFO:choose_better completed
2025-06-02 19:54:53,032:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 19:54:53,040:INFO:_master_model_container: 16
2025-06-02 19:54:53,040:INFO:_display_container: 3
2025-06-02 19:54:53,041:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 19:54:53,041:INFO:tune_model() successfully completed......................................
2025-06-02 19:54:53,148:INFO:Initializing save_model()
2025-06-02 19:54:53,148:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=modelo_bank_mlflow, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['segmento', 'rango_ingresos',
                                             'region'],
                                    transformer=OneHotEncoder(cols=['segmento',
                                                                    'rango_ingresos',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-02 19:54:53,148:INFO:Adding model into prep_pipe
2025-06-02 19:54:53,155:INFO:modelo_bank_mlflow.pkl saved in current working directory
2025-06-02 19:54:53,170:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-06-02 19:54:53,170:INFO:save_model() successfully completed......................................
2025-06-02 20:03:15,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:03:15,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:03:15,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:03:15,353:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:03:17,385:INFO:PyCaret ClassificationExperiment
2025-06-02 20:03:17,387:INFO:Logging name: banking-autoML
2025-06-02 20:03:17,387:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-02 20:03:17,387:INFO:version 3.2.0
2025-06-02 20:03:17,387:INFO:Initializing setup()
2025-06-02 20:03:17,387:INFO:self.USI: e5a0
2025-06-02 20:03:17,387:INFO:self._variable_keys: {'fix_imbalance', 'n_jobs_param', 'pipeline', 'exp_name_log', '_available_plots', 'fold_groups_param', 'gpu_param', 'idx', 'y_train', 'memory', 'data', 'y_test', 'seed', 'USI', 'html_param', 'fold_generator', 'log_plots_param', 'is_multiclass', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'y', 'X_train', 'fold_shuffle_param', 'X_test', 'exp_id', 'logging_param'}
2025-06-02 20:03:17,387:INFO:Checking environment
2025-06-02 20:03:17,388:INFO:python_version: 3.11.9
2025-06-02 20:03:17,388:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-06-02 20:03:17,388:INFO:machine: AMD64
2025-06-02 20:03:17,416:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-02 20:03:17,425:INFO:Memory: svmem(total=33554628608, available=17413943296, percent=48.1, used=16140685312, free=17413943296)
2025-06-02 20:03:17,425:INFO:Physical Core: 6
2025-06-02 20:03:17,425:INFO:Logical Core: 12
2025-06-02 20:03:17,425:INFO:Checking libraries
2025-06-02 20:03:17,425:INFO:System:
2025-06-02 20:03:17,425:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-06-02 20:03:17,425:INFO:executable: C:\Users\amonreal\Documents\amlbash\.venv\Scripts\python.exe
2025-06-02 20:03:17,425:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-02 20:03:17,425:INFO:PyCaret required dependencies:
2025-06-02 20:03:17,490:INFO:                 pip: 24.0
2025-06-02 20:03:17,490:INFO:          setuptools: 65.5.0
2025-06-02 20:03:17,490:INFO:             pycaret: 3.2.0
2025-06-02 20:03:17,490:INFO:             IPython: 9.2.0
2025-06-02 20:03:17,490:INFO:          ipywidgets: 8.1.7
2025-06-02 20:03:17,490:INFO:                tqdm: 4.67.1
2025-06-02 20:03:17,490:INFO:               numpy: 1.25.2
2025-06-02 20:03:17,490:INFO:              pandas: 1.5.3
2025-06-02 20:03:17,490:INFO:              jinja2: 3.1.6
2025-06-02 20:03:17,490:INFO:               scipy: 1.10.1
2025-06-02 20:03:17,490:INFO:              joblib: 1.3.2
2025-06-02 20:03:17,490:INFO:             sklearn: 1.2.2
2025-06-02 20:03:17,490:INFO:                pyod: 2.0.5
2025-06-02 20:03:17,490:INFO:            imblearn: 0.12.4
2025-06-02 20:03:17,490:INFO:   category_encoders: 2.7.0
2025-06-02 20:03:17,490:INFO:            lightgbm: 4.6.0
2025-06-02 20:03:17,490:INFO:               numba: 0.61.2
2025-06-02 20:03:17,490:INFO:            requests: 2.32.3
2025-06-02 20:03:17,490:INFO:          matplotlib: 3.6.0
2025-06-02 20:03:17,490:INFO:          scikitplot: 0.3.7
2025-06-02 20:03:17,490:INFO:         yellowbrick: 1.5
2025-06-02 20:03:17,490:INFO:              plotly: 5.24.1
2025-06-02 20:03:17,490:INFO:    plotly-resampler: Not installed
2025-06-02 20:03:17,490:INFO:             kaleido: 0.2.1
2025-06-02 20:03:17,490:INFO:           schemdraw: 0.15
2025-06-02 20:03:17,491:INFO:         statsmodels: 0.14.4
2025-06-02 20:03:17,491:INFO:              sktime: 0.21.1
2025-06-02 20:03:17,491:INFO:               tbats: 1.1.3
2025-06-02 20:03:17,491:INFO:            pmdarima: 2.0.4
2025-06-02 20:03:17,491:INFO:              psutil: 7.0.0
2025-06-02 20:03:17,491:INFO:          markupsafe: 3.0.2
2025-06-02 20:03:17,491:INFO:             pickle5: Not installed
2025-06-02 20:03:17,491:INFO:         cloudpickle: 2.2.1
2025-06-02 20:03:17,491:INFO:         deprecation: 2.1.0
2025-06-02 20:03:17,491:INFO:              xxhash: 3.5.0
2025-06-02 20:03:17,491:INFO:           wurlitzer: Not installed
2025-06-02 20:03:17,491:INFO:PyCaret optional dependencies:
2025-06-02 20:03:18,103:INFO:                shap: Not installed
2025-06-02 20:03:18,103:INFO:           interpret: Not installed
2025-06-02 20:03:18,103:INFO:                umap: Not installed
2025-06-02 20:03:18,103:INFO:     ydata_profiling: Not installed
2025-06-02 20:03:18,105:INFO:  explainerdashboard: Not installed
2025-06-02 20:03:18,105:INFO:             autoviz: Not installed
2025-06-02 20:03:18,105:INFO:           fairlearn: Not installed
2025-06-02 20:03:18,105:INFO:          deepchecks: Not installed
2025-06-02 20:03:18,105:INFO:             xgboost: Not installed
2025-06-02 20:03:18,105:INFO:            catboost: Not installed
2025-06-02 20:03:18,105:INFO:              kmodes: Not installed
2025-06-02 20:03:18,105:INFO:             mlxtend: Not installed
2025-06-02 20:03:18,105:INFO:       statsforecast: Not installed
2025-06-02 20:03:18,105:INFO:        tune_sklearn: Not installed
2025-06-02 20:03:18,105:INFO:                 ray: Not installed
2025-06-02 20:03:18,105:INFO:            hyperopt: Not installed
2025-06-02 20:03:18,105:INFO:              optuna: Not installed
2025-06-02 20:03:18,105:INFO:               skopt: Not installed
2025-06-02 20:03:18,105:INFO:              mlflow: 2.22.0
2025-06-02 20:03:18,105:INFO:              gradio: Not installed
2025-06-02 20:03:18,105:INFO:             fastapi: 0.115.12
2025-06-02 20:03:18,105:INFO:             uvicorn: 0.34.2
2025-06-02 20:03:18,105:INFO:              m2cgen: Not installed
2025-06-02 20:03:18,105:INFO:           evidently: Not installed
2025-06-02 20:03:18,105:INFO:               fugue: Not installed
2025-06-02 20:03:18,105:INFO:           streamlit: Not installed
2025-06-02 20:03:18,105:INFO:             prophet: Not installed
2025-06-02 20:03:18,105:INFO:None
2025-06-02 20:03:18,105:INFO:Set up data.
2025-06-02 20:03:18,113:INFO:Set up folding strategy.
2025-06-02 20:03:18,113:INFO:Set up train/test split.
2025-06-02 20:03:18,119:INFO:Set up index.
2025-06-02 20:03:18,119:INFO:Assigning column types.
2025-06-02 20:03:18,122:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-02 20:03:18,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:03:18,157:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 20:03:18,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,216:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-02 20:03:18,217:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 20:03:18,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,239:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,239:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-02 20:03:18,273:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 20:03:18,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,329:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-02 20:03:18,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,351:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-02 20:03:18,413:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,471:INFO:Preparing preprocessing pipeline...
2025-06-02 20:03:18,472:INFO:Set up simple imputation.
2025-06-02 20:03:18,473:INFO:Set up encoding of categorical features.
2025-06-02 20:03:18,563:INFO:Finished creating preprocessing pipeline.
2025-06-02 20:03:18,569:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['segmento', 'rango_ingresos',
                                             'region'],
                                    transformer=OneHotEncoder(cols=['segmento',
                                                                    'rango_ingresos',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-06-02 20:03:18,569:INFO:Creating final display dataframe.
2025-06-02 20:03:18,746:INFO:Setup _display_container:                     Description            Value
0                    Session id              123
1                        Target   cerrara_cuenta
2                   Target type           Binary
3           Original data shape       (2000, 13)
4        Transformed data shape       (2000, 20)
5   Transformed train set shape       (1400, 20)
6    Transformed test set shape        (600, 20)
7              Numeric features                9
8          Categorical features                3
9                    Preprocess             True
10              Imputation type           simple
11           Numeric imputation             mean
12       Categorical imputation             mode
13     Maximum one-hot encoding               25
14              Encoding method             None
15               Fold Generator  StratifiedKFold
16                  Fold Number               10
17                     CPU Jobs               -1
18                      Use GPU            False
19               Log Experiment            False
20              Experiment Name   banking-autoML
21                          USI             e5a0
2025-06-02 20:03:18,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-02 20:03:18,868:INFO:setup() successfully completed in 1.49s...............
2025-06-02 20:03:18,870:INFO:Initializing compare_models()
2025-06-02 20:03:18,870:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-02 20:03:18,870:INFO:Checking exceptions
2025-06-02 20:03:18,873:INFO:Preparing display monitor
2025-06-02 20:03:18,879:INFO:Initializing Logistic Regression
2025-06-02 20:03:18,879:INFO:Total runtime is 0.0 minutes
2025-06-02 20:03:18,879:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:18,880:INFO:Initializing create_model()
2025-06-02 20:03:18,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:18,881:INFO:Checking exceptions
2025-06-02 20:03:18,881:INFO:Importing libraries
2025-06-02 20:03:18,881:INFO:Copying training dataset
2025-06-02 20:03:18,890:INFO:Defining folds
2025-06-02 20:03:18,891:INFO:Declaring metric variables
2025-06-02 20:03:18,891:INFO:Importing untrained model
2025-06-02 20:03:18,892:INFO:Logistic Regression Imported successfully
2025-06-02 20:03:18,892:INFO:Starting cross validation
2025-06-02 20:03:18,895:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:23,530:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:23,530:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:23,577:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:23,583:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:23,649:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:23,661:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:23,703:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:23,729:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:23,738:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:23,837:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:23,846:INFO:Calculating mean and std
2025-06-02 20:03:23,847:INFO:Creating metrics dataframe
2025-06-02 20:03:23,850:INFO:Uploading results into container
2025-06-02 20:03:23,851:INFO:Uploading model into container now
2025-06-02 20:03:23,851:INFO:_master_model_container: 1
2025-06-02 20:03:23,851:INFO:_display_container: 2
2025-06-02 20:03:23,851:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 20:03:23,851:INFO:create_model() successfully completed......................................
2025-06-02 20:03:23,961:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:23,962:INFO:Creating metrics dataframe
2025-06-02 20:03:23,965:INFO:Initializing K Neighbors Classifier
2025-06-02 20:03:23,965:INFO:Total runtime is 0.08476794163386027 minutes
2025-06-02 20:03:23,965:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:23,966:INFO:Initializing create_model()
2025-06-02 20:03:23,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:23,966:INFO:Checking exceptions
2025-06-02 20:03:23,966:INFO:Importing libraries
2025-06-02 20:03:23,966:INFO:Copying training dataset
2025-06-02 20:03:23,969:INFO:Defining folds
2025-06-02 20:03:23,969:INFO:Declaring metric variables
2025-06-02 20:03:23,969:INFO:Importing untrained model
2025-06-02 20:03:23,969:INFO:K Neighbors Classifier Imported successfully
2025-06-02 20:03:23,969:INFO:Starting cross validation
2025-06-02 20:03:23,970:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:26,680:INFO:Calculating mean and std
2025-06-02 20:03:26,681:INFO:Creating metrics dataframe
2025-06-02 20:03:26,685:INFO:Uploading results into container
2025-06-02 20:03:26,686:INFO:Uploading model into container now
2025-06-02 20:03:26,686:INFO:_master_model_container: 2
2025-06-02 20:03:26,686:INFO:_display_container: 2
2025-06-02 20:03:26,687:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-02 20:03:26,687:INFO:create_model() successfully completed......................................
2025-06-02 20:03:26,797:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:26,797:INFO:Creating metrics dataframe
2025-06-02 20:03:26,801:INFO:Initializing Naive Bayes
2025-06-02 20:03:26,801:INFO:Total runtime is 0.13204344908396404 minutes
2025-06-02 20:03:26,801:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:26,802:INFO:Initializing create_model()
2025-06-02 20:03:26,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:26,802:INFO:Checking exceptions
2025-06-02 20:03:26,802:INFO:Importing libraries
2025-06-02 20:03:26,802:INFO:Copying training dataset
2025-06-02 20:03:26,806:INFO:Defining folds
2025-06-02 20:03:26,807:INFO:Declaring metric variables
2025-06-02 20:03:26,807:INFO:Importing untrained model
2025-06-02 20:03:26,807:INFO:Naive Bayes Imported successfully
2025-06-02 20:03:26,807:INFO:Starting cross validation
2025-06-02 20:03:26,808:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:26,920:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:26,922:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:26,922:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:26,924:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:26,926:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:26,927:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:26,931:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:26,932:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:26,933:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:26,934:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:26,942:INFO:Calculating mean and std
2025-06-02 20:03:26,943:INFO:Creating metrics dataframe
2025-06-02 20:03:26,945:INFO:Uploading results into container
2025-06-02 20:03:26,945:INFO:Uploading model into container now
2025-06-02 20:03:26,945:INFO:_master_model_container: 3
2025-06-02 20:03:26,946:INFO:_display_container: 2
2025-06-02 20:03:26,946:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-02 20:03:26,946:INFO:create_model() successfully completed......................................
2025-06-02 20:03:27,052:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:27,053:INFO:Creating metrics dataframe
2025-06-02 20:03:27,057:INFO:Initializing Decision Tree Classifier
2025-06-02 20:03:27,057:INFO:Total runtime is 0.13630737066268922 minutes
2025-06-02 20:03:27,057:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:27,057:INFO:Initializing create_model()
2025-06-02 20:03:27,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:27,057:INFO:Checking exceptions
2025-06-02 20:03:27,057:INFO:Importing libraries
2025-06-02 20:03:27,057:INFO:Copying training dataset
2025-06-02 20:03:27,061:INFO:Defining folds
2025-06-02 20:03:27,061:INFO:Declaring metric variables
2025-06-02 20:03:27,062:INFO:Importing untrained model
2025-06-02 20:03:27,062:INFO:Decision Tree Classifier Imported successfully
2025-06-02 20:03:27,063:INFO:Starting cross validation
2025-06-02 20:03:27,065:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:27,218:INFO:Calculating mean and std
2025-06-02 20:03:27,218:INFO:Creating metrics dataframe
2025-06-02 20:03:27,221:INFO:Uploading results into container
2025-06-02 20:03:27,222:INFO:Uploading model into container now
2025-06-02 20:03:27,222:INFO:_master_model_container: 4
2025-06-02 20:03:27,222:INFO:_display_container: 2
2025-06-02 20:03:27,222:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2025-06-02 20:03:27,222:INFO:create_model() successfully completed......................................
2025-06-02 20:03:27,326:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:27,326:INFO:Creating metrics dataframe
2025-06-02 20:03:27,330:INFO:Initializing SVM - Linear Kernel
2025-06-02 20:03:27,330:INFO:Total runtime is 0.14085235595703127 minutes
2025-06-02 20:03:27,330:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:27,330:INFO:Initializing create_model()
2025-06-02 20:03:27,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:27,330:INFO:Checking exceptions
2025-06-02 20:03:27,330:INFO:Importing libraries
2025-06-02 20:03:27,330:INFO:Copying training dataset
2025-06-02 20:03:27,333:INFO:Defining folds
2025-06-02 20:03:27,333:INFO:Declaring metric variables
2025-06-02 20:03:27,333:INFO:Importing untrained model
2025-06-02 20:03:27,335:INFO:SVM - Linear Kernel Imported successfully
2025-06-02 20:03:27,335:INFO:Starting cross validation
2025-06-02 20:03:27,337:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:27,453:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 20:03:27,457:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 20:03:27,457:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 20:03:27,458:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 20:03:27,458:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,458:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 20:03:27,461:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 20:03:27,462:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 20:03:27,462:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 20:03:27,463:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 20:03:27,463:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,463:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2025-06-02 20:03:27,473:INFO:Calculating mean and std
2025-06-02 20:03:27,474:INFO:Creating metrics dataframe
2025-06-02 20:03:27,476:INFO:Uploading results into container
2025-06-02 20:03:27,476:INFO:Uploading model into container now
2025-06-02 20:03:27,476:INFO:_master_model_container: 5
2025-06-02 20:03:27,476:INFO:_display_container: 2
2025-06-02 20:03:27,477:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-02 20:03:27,477:INFO:create_model() successfully completed......................................
2025-06-02 20:03:27,579:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:27,579:INFO:Creating metrics dataframe
2025-06-02 20:03:27,583:INFO:Initializing Ridge Classifier
2025-06-02 20:03:27,583:INFO:Total runtime is 0.14507864316304528 minutes
2025-06-02 20:03:27,583:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:27,583:INFO:Initializing create_model()
2025-06-02 20:03:27,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:27,583:INFO:Checking exceptions
2025-06-02 20:03:27,583:INFO:Importing libraries
2025-06-02 20:03:27,583:INFO:Copying training dataset
2025-06-02 20:03:27,586:INFO:Defining folds
2025-06-02 20:03:27,587:INFO:Declaring metric variables
2025-06-02 20:03:27,587:INFO:Importing untrained model
2025-06-02 20:03:27,587:INFO:Ridge Classifier Imported successfully
2025-06-02 20:03:27,587:INFO:Starting cross validation
2025-06-02 20:03:27,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:27,687:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 20:03:27,691:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,696:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 20:03:27,697:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 20:03:27,698:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 20:03:27,699:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,701:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,702:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,702:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 20:03:27,702:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 20:03:27,706:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,706:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,707:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 20:03:27,708:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 20:03:27,711:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,711:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,712:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 20:03:27,712:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\pycaret\internal\pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2025-06-02 20:03:27,715:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,717:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:27,724:INFO:Calculating mean and std
2025-06-02 20:03:27,725:INFO:Creating metrics dataframe
2025-06-02 20:03:27,728:INFO:Uploading results into container
2025-06-02 20:03:27,728:INFO:Uploading model into container now
2025-06-02 20:03:27,728:INFO:_master_model_container: 6
2025-06-02 20:03:27,728:INFO:_display_container: 2
2025-06-02 20:03:27,728:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-06-02 20:03:27,728:INFO:create_model() successfully completed......................................
2025-06-02 20:03:27,831:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:27,831:INFO:Creating metrics dataframe
2025-06-02 20:03:27,835:INFO:Initializing Random Forest Classifier
2025-06-02 20:03:27,835:INFO:Total runtime is 0.14927150408426923 minutes
2025-06-02 20:03:27,835:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:27,835:INFO:Initializing create_model()
2025-06-02 20:03:27,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:27,835:INFO:Checking exceptions
2025-06-02 20:03:27,835:INFO:Importing libraries
2025-06-02 20:03:27,835:INFO:Copying training dataset
2025-06-02 20:03:27,838:INFO:Defining folds
2025-06-02 20:03:27,838:INFO:Declaring metric variables
2025-06-02 20:03:27,838:INFO:Importing untrained model
2025-06-02 20:03:27,838:INFO:Random Forest Classifier Imported successfully
2025-06-02 20:03:27,838:INFO:Starting cross validation
2025-06-02 20:03:27,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:28,322:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:28,323:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:28,332:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:28,343:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:28,397:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:28,499:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:28,508:INFO:Calculating mean and std
2025-06-02 20:03:28,510:INFO:Creating metrics dataframe
2025-06-02 20:03:28,517:INFO:Uploading results into container
2025-06-02 20:03:28,517:INFO:Uploading model into container now
2025-06-02 20:03:28,518:INFO:_master_model_container: 7
2025-06-02 20:03:28,518:INFO:_display_container: 2
2025-06-02 20:03:28,518:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2025-06-02 20:03:28,518:INFO:create_model() successfully completed......................................
2025-06-02 20:03:28,641:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:28,641:INFO:Creating metrics dataframe
2025-06-02 20:03:28,645:INFO:Initializing Quadratic Discriminant Analysis
2025-06-02 20:03:28,645:INFO:Total runtime is 0.1627667506535848 minutes
2025-06-02 20:03:28,645:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:28,645:INFO:Initializing create_model()
2025-06-02 20:03:28,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:28,645:INFO:Checking exceptions
2025-06-02 20:03:28,645:INFO:Importing libraries
2025-06-02 20:03:28,645:INFO:Copying training dataset
2025-06-02 20:03:28,647:INFO:Defining folds
2025-06-02 20:03:28,648:INFO:Declaring metric variables
2025-06-02 20:03:28,648:INFO:Importing untrained model
2025-06-02 20:03:28,649:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-02 20:03:28,649:INFO:Starting cross validation
2025-06-02 20:03:28,652:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:28,742:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 20:03:28,747:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 20:03:28,748:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 20:03:28,748:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 20:03:28,748:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 20:03:28,750:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 20:03:28,753:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 20:03:28,753:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 20:03:28,753:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 20:03:28,754:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-02 20:03:28,784:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:28,796:INFO:Calculating mean and std
2025-06-02 20:03:28,797:INFO:Creating metrics dataframe
2025-06-02 20:03:28,800:INFO:Uploading results into container
2025-06-02 20:03:28,800:INFO:Uploading model into container now
2025-06-02 20:03:28,800:INFO:_master_model_container: 8
2025-06-02 20:03:28,800:INFO:_display_container: 2
2025-06-02 20:03:28,801:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-02 20:03:28,801:INFO:create_model() successfully completed......................................
2025-06-02 20:03:28,909:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:28,909:INFO:Creating metrics dataframe
2025-06-02 20:03:28,915:INFO:Initializing Ada Boost Classifier
2025-06-02 20:03:28,915:INFO:Total runtime is 0.16726795037587486 minutes
2025-06-02 20:03:28,915:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:28,916:INFO:Initializing create_model()
2025-06-02 20:03:28,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:28,916:INFO:Checking exceptions
2025-06-02 20:03:28,916:INFO:Importing libraries
2025-06-02 20:03:28,916:INFO:Copying training dataset
2025-06-02 20:03:28,919:INFO:Defining folds
2025-06-02 20:03:28,919:INFO:Declaring metric variables
2025-06-02 20:03:28,919:INFO:Importing untrained model
2025-06-02 20:03:28,920:INFO:Ada Boost Classifier Imported successfully
2025-06-02 20:03:28,920:INFO:Starting cross validation
2025-06-02 20:03:28,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:29,202:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:29,215:INFO:Calculating mean and std
2025-06-02 20:03:29,215:INFO:Creating metrics dataframe
2025-06-02 20:03:29,218:INFO:Uploading results into container
2025-06-02 20:03:29,218:INFO:Uploading model into container now
2025-06-02 20:03:29,219:INFO:_master_model_container: 9
2025-06-02 20:03:29,219:INFO:_display_container: 2
2025-06-02 20:03:29,219:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2025-06-02 20:03:29,220:INFO:create_model() successfully completed......................................
2025-06-02 20:03:29,323:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:29,323:INFO:Creating metrics dataframe
2025-06-02 20:03:29,327:INFO:Initializing Gradient Boosting Classifier
2025-06-02 20:03:29,327:INFO:Total runtime is 0.17413600285847983 minutes
2025-06-02 20:03:29,327:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:29,328:INFO:Initializing create_model()
2025-06-02 20:03:29,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:29,328:INFO:Checking exceptions
2025-06-02 20:03:29,328:INFO:Importing libraries
2025-06-02 20:03:29,328:INFO:Copying training dataset
2025-06-02 20:03:29,330:INFO:Defining folds
2025-06-02 20:03:29,331:INFO:Declaring metric variables
2025-06-02 20:03:29,331:INFO:Importing untrained model
2025-06-02 20:03:29,332:INFO:Gradient Boosting Classifier Imported successfully
2025-06-02 20:03:29,333:INFO:Starting cross validation
2025-06-02 20:03:29,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:29,820:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:29,828:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:29,843:INFO:Calculating mean and std
2025-06-02 20:03:29,844:INFO:Creating metrics dataframe
2025-06-02 20:03:29,846:INFO:Uploading results into container
2025-06-02 20:03:29,846:INFO:Uploading model into container now
2025-06-02 20:03:29,847:INFO:_master_model_container: 10
2025-06-02 20:03:29,847:INFO:_display_container: 2
2025-06-02 20:03:29,847:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-02 20:03:29,847:INFO:create_model() successfully completed......................................
2025-06-02 20:03:29,949:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:29,949:INFO:Creating metrics dataframe
2025-06-02 20:03:29,953:INFO:Initializing Linear Discriminant Analysis
2025-06-02 20:03:29,953:INFO:Total runtime is 0.1845725178718567 minutes
2025-06-02 20:03:29,953:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:29,953:INFO:Initializing create_model()
2025-06-02 20:03:29,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:29,953:INFO:Checking exceptions
2025-06-02 20:03:29,953:INFO:Importing libraries
2025-06-02 20:03:29,953:INFO:Copying training dataset
2025-06-02 20:03:29,956:INFO:Defining folds
2025-06-02 20:03:29,956:INFO:Declaring metric variables
2025-06-02 20:03:29,956:INFO:Importing untrained model
2025-06-02 20:03:29,956:INFO:Linear Discriminant Analysis Imported successfully
2025-06-02 20:03:29,956:INFO:Starting cross validation
2025-06-02 20:03:29,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:30,107:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,110:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,115:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,122:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,123:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,127:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,132:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,135:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,135:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,141:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,153:INFO:Calculating mean and std
2025-06-02 20:03:30,153:INFO:Creating metrics dataframe
2025-06-02 20:03:30,156:INFO:Uploading results into container
2025-06-02 20:03:30,157:INFO:Uploading model into container now
2025-06-02 20:03:30,157:INFO:_master_model_container: 11
2025-06-02 20:03:30,157:INFO:_display_container: 2
2025-06-02 20:03:30,157:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-02 20:03:30,157:INFO:create_model() successfully completed......................................
2025-06-02 20:03:30,277:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:30,277:INFO:Creating metrics dataframe
2025-06-02 20:03:30,281:INFO:Initializing Extra Trees Classifier
2025-06-02 20:03:30,281:INFO:Total runtime is 0.19004019498825073 minutes
2025-06-02 20:03:30,281:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:30,281:INFO:Initializing create_model()
2025-06-02 20:03:30,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:30,282:INFO:Checking exceptions
2025-06-02 20:03:30,282:INFO:Importing libraries
2025-06-02 20:03:30,282:INFO:Copying training dataset
2025-06-02 20:03:30,284:INFO:Defining folds
2025-06-02 20:03:30,284:INFO:Declaring metric variables
2025-06-02 20:03:30,284:INFO:Importing untrained model
2025-06-02 20:03:30,284:INFO:Extra Trees Classifier Imported successfully
2025-06-02 20:03:30,286:INFO:Starting cross validation
2025-06-02 20:03:30,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:30,846:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:30,985:INFO:Calculating mean and std
2025-06-02 20:03:30,986:INFO:Creating metrics dataframe
2025-06-02 20:03:30,990:INFO:Uploading results into container
2025-06-02 20:03:30,991:INFO:Uploading model into container now
2025-06-02 20:03:30,991:INFO:_master_model_container: 12
2025-06-02 20:03:30,991:INFO:_display_container: 2
2025-06-02 20:03:30,992:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2025-06-02 20:03:30,992:INFO:create_model() successfully completed......................................
2025-06-02 20:03:31,099:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:31,099:INFO:Creating metrics dataframe
2025-06-02 20:03:31,102:INFO:Initializing Light Gradient Boosting Machine
2025-06-02 20:03:31,102:INFO:Total runtime is 0.20373029311498006 minutes
2025-06-02 20:03:31,102:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:31,102:INFO:Initializing create_model()
2025-06-02 20:03:31,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:31,102:INFO:Checking exceptions
2025-06-02 20:03:31,102:INFO:Importing libraries
2025-06-02 20:03:31,102:INFO:Copying training dataset
2025-06-02 20:03:31,106:INFO:Defining folds
2025-06-02 20:03:31,106:INFO:Declaring metric variables
2025-06-02 20:03:31,106:INFO:Importing untrained model
2025-06-02 20:03:31,108:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-02 20:03:31,109:INFO:Starting cross validation
2025-06-02 20:03:31,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:32,580:INFO:Calculating mean and std
2025-06-02 20:03:32,581:INFO:Creating metrics dataframe
2025-06-02 20:03:32,585:INFO:Uploading results into container
2025-06-02 20:03:32,586:INFO:Uploading model into container now
2025-06-02 20:03:32,586:INFO:_master_model_container: 13
2025-06-02 20:03:32,586:INFO:_display_container: 2
2025-06-02 20:03:32,587:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-02 20:03:32,587:INFO:create_model() successfully completed......................................
2025-06-02 20:03:32,713:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:32,713:INFO:Creating metrics dataframe
2025-06-02 20:03:32,717:INFO:Initializing Dummy Classifier
2025-06-02 20:03:32,717:INFO:Total runtime is 0.23063997824986776 minutes
2025-06-02 20:03:32,717:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:32,718:INFO:Initializing create_model()
2025-06-02 20:03:32,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024362887510>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:32,718:INFO:Checking exceptions
2025-06-02 20:03:32,718:INFO:Importing libraries
2025-06-02 20:03:32,718:INFO:Copying training dataset
2025-06-02 20:03:32,720:INFO:Defining folds
2025-06-02 20:03:32,720:INFO:Declaring metric variables
2025-06-02 20:03:32,720:INFO:Importing untrained model
2025-06-02 20:03:32,721:INFO:Dummy Classifier Imported successfully
2025-06-02 20:03:32,721:INFO:Starting cross validation
2025-06-02 20:03:32,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:32,831:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:32,832:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:32,837:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:32,837:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:32,840:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:32,841:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:32,843:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:32,843:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:32,845:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:32,845:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:32,857:INFO:Calculating mean and std
2025-06-02 20:03:32,858:INFO:Creating metrics dataframe
2025-06-02 20:03:32,861:INFO:Uploading results into container
2025-06-02 20:03:32,861:INFO:Uploading model into container now
2025-06-02 20:03:32,862:INFO:_master_model_container: 14
2025-06-02 20:03:32,862:INFO:_display_container: 2
2025-06-02 20:03:32,862:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-06-02 20:03:32,862:INFO:create_model() successfully completed......................................
2025-06-02 20:03:32,968:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:32,968:INFO:Creating metrics dataframe
2025-06-02 20:03:32,973:INFO:Initializing create_model()
2025-06-02 20:03:32,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:32,973:INFO:Checking exceptions
2025-06-02 20:03:32,975:INFO:Importing libraries
2025-06-02 20:03:32,975:INFO:Copying training dataset
2025-06-02 20:03:32,978:INFO:Defining folds
2025-06-02 20:03:32,978:INFO:Declaring metric variables
2025-06-02 20:03:32,978:INFO:Importing untrained model
2025-06-02 20:03:32,978:INFO:Declaring custom model
2025-06-02 20:03:32,978:INFO:Logistic Regression Imported successfully
2025-06-02 20:03:32,979:INFO:Cross validation set to False
2025-06-02 20:03:32,979:INFO:Fitting Model
2025-06-02 20:03:33,045:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 20:03:33,045:INFO:create_model() successfully completed......................................
2025-06-02 20:03:33,161:INFO:_master_model_container: 14
2025-06-02 20:03:33,161:INFO:_display_container: 2
2025-06-02 20:03:33,162:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 20:03:33,162:INFO:compare_models() successfully completed......................................
2025-06-02 20:03:33,162:INFO:Initializing tune_model()
2025-06-02 20:03:33,162:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-06-02 20:03:33,162:INFO:Checking exceptions
2025-06-02 20:03:33,165:INFO:Copying training dataset
2025-06-02 20:03:33,167:INFO:Checking base model
2025-06-02 20:03:33,167:INFO:Base model : Logistic Regression
2025-06-02 20:03:33,168:INFO:Declaring metric variables
2025-06-02 20:03:33,168:INFO:Defining Hyperparameters
2025-06-02 20:03:33,276:INFO:Tuning with n_jobs=-1
2025-06-02 20:03:33,277:INFO:Initializing RandomizedSearchCV
2025-06-02 20:03:34,373:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 7.863}
2025-06-02 20:03:34,375:INFO:Hyperparameter search completed
2025-06-02 20:03:34,375:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:34,375:INFO:Initializing create_model()
2025-06-02 20:03:34,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002435F634310>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 7.863})
2025-06-02 20:03:34,375:INFO:Checking exceptions
2025-06-02 20:03:34,375:INFO:Importing libraries
2025-06-02 20:03:34,375:INFO:Copying training dataset
2025-06-02 20:03:34,378:INFO:Defining folds
2025-06-02 20:03:34,378:INFO:Declaring metric variables
2025-06-02 20:03:34,378:INFO:Importing untrained model
2025-06-02 20:03:34,378:INFO:Declaring custom model
2025-06-02 20:03:34,379:INFO:Logistic Regression Imported successfully
2025-06-02 20:03:34,379:INFO:Starting cross validation
2025-06-02 20:03:34,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:34,493:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,503:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,505:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,506:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,507:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,509:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,511:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,514:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,522:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,527:INFO:Calculating mean and std
2025-06-02 20:03:34,528:INFO:Creating metrics dataframe
2025-06-02 20:03:34,529:INFO:Finalizing model
2025-06-02 20:03:34,605:INFO:Uploading results into container
2025-06-02 20:03:34,605:INFO:Uploading model into container now
2025-06-02 20:03:34,605:INFO:_master_model_container: 15
2025-06-02 20:03:34,606:INFO:_display_container: 3
2025-06-02 20:03:34,606:INFO:LogisticRegression(C=7.863, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 20:03:34,606:INFO:create_model() successfully completed......................................
2025-06-02 20:03:34,714:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:34,714:INFO:choose_better activated
2025-06-02 20:03:34,714:INFO:SubProcess create_model() called ==================================
2025-06-02 20:03:34,715:INFO:Initializing create_model()
2025-06-02 20:03:34,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024360925B90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-02 20:03:34,715:INFO:Checking exceptions
2025-06-02 20:03:34,716:INFO:Importing libraries
2025-06-02 20:03:34,716:INFO:Copying training dataset
2025-06-02 20:03:34,718:INFO:Defining folds
2025-06-02 20:03:34,718:INFO:Declaring metric variables
2025-06-02 20:03:34,718:INFO:Importing untrained model
2025-06-02 20:03:34,718:INFO:Declaring custom model
2025-06-02 20:03:34,719:INFO:Logistic Regression Imported successfully
2025-06-02 20:03:34,719:INFO:Starting cross validation
2025-06-02 20:03:34,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-02 20:03:34,841:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,846:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,847:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,849:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,849:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,852:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,858:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,858:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,859:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,864:WARNING:C:\Users\amonreal\Documents\amlbash\.venv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2025-06-02 20:03:34,870:INFO:Calculating mean and std
2025-06-02 20:03:34,870:INFO:Creating metrics dataframe
2025-06-02 20:03:34,872:INFO:Finalizing model
2025-06-02 20:03:34,938:INFO:Uploading results into container
2025-06-02 20:03:34,938:INFO:Uploading model into container now
2025-06-02 20:03:34,938:INFO:_master_model_container: 16
2025-06-02 20:03:34,938:INFO:_display_container: 4
2025-06-02 20:03:34,939:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 20:03:34,939:INFO:create_model() successfully completed......................................
2025-06-02 20:03:35,045:INFO:SubProcess create_model() end ==================================
2025-06-02 20:03:35,045:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8457
2025-06-02 20:03:35,045:INFO:LogisticRegression(C=7.863, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8457
2025-06-02 20:03:35,046:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-06-02 20:03:35,046:INFO:choose_better completed
2025-06-02 20:03:35,046:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-02 20:03:35,057:INFO:_master_model_container: 16
2025-06-02 20:03:35,057:INFO:_display_container: 3
2025-06-02 20:03:35,057:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-02 20:03:35,057:INFO:tune_model() successfully completed......................................
2025-06-02 20:03:35,176:INFO:Initializing save_model()
2025-06-02 20:03:35,177:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=modelo_bank_mlflow, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\amonreal\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              c...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['segmento', 'rango_ingresos',
                                             'region'],
                                    transformer=OneHotEncoder(cols=['segmento',
                                                                    'rango_ingresos',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-02 20:03:35,177:INFO:Adding model into prep_pipe
2025-06-02 20:03:35,183:INFO:modelo_bank_mlflow.pkl saved in current working directory
2025-06-02 20:03:35,194:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'saldo_total',
                                             'numero_productos',
                                             'visitas_app_mes', 'usa_web',
                                             'usa_tarjeta_credito',
                                             'reclamos_6m',
                                             'satisfaccion_encuesta',
                                             'tasa_credito_personal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=123,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-06-02 20:03:35,194:INFO:save_model() successfully completed......................................
2025-06-02 20:09:15,781:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:09:15,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:09:15,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:09:15,782:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:09:17,654:INFO:Initializing load_model()
2025-06-02 20:09:17,654:INFO:load_model(model_name=modelo_bank_mlflow, platform=None, authentication=None, verbose=True)
2025-06-02 20:34:07,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:34:07,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:34:07,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:34:07,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:34:09,069:INFO:Initializing load_model()
2025-06-02 20:34:09,069:INFO:load_model(model_name=modelo_bank_mlflow, platform=None, authentication=None, verbose=True)
2025-06-02 20:44:41,613:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:44:41,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:44:41,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:44:41,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:44:43,710:INFO:Initializing load_model()
2025-06-02 20:44:43,710:INFO:load_model(model_name=modelo_bank_mlflow, platform=None, authentication=None, verbose=True)
2025-06-02 20:55:26,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:55:26,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:55:26,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:55:26,791:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 20:55:28,822:INFO:Initializing load_model()
2025-06-02 20:55:28,823:INFO:load_model(model_name=modelo_bank_mlflow, platform=None, authentication=None, verbose=True)
2025-06-02 21:13:52,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:13:52,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:13:52,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:13:52,567:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:15:25,302:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:15:25,303:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:15:25,303:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:15:25,303:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:29:00,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:29:00,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:29:00,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:29:00,893:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:29:02,291:INFO:Initializing load_model()
2025-06-02 21:29:02,291:INFO:load_model(model_name=cluster_model_clientes, platform=None, authentication=None, verbose=True)
2025-06-02 21:39:34,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:39:34,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:39:34,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:39:34,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-02 21:39:35,838:INFO:Initializing load_model()
2025-06-02 21:39:35,840:INFO:load_model(model_name=cluster_model_clientes, platform=None, authentication=None, verbose=True)
2025-06-05 19:30:42,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-05 19:30:42,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-05 19:30:42,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-05 19:30:42,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
